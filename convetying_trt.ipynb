{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d716b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc099a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.105 ðŸš€ Python-3.12.3 torch-2.8.0.dev20250408+cu128 CUDA:1 (NVIDIA GeForce RTX 4090, 24082MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-seg summary (fused): 85 layers, 3,258,259 parameters, 0 gradients, 12.0 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'Models/model_seg_fp16_1/best_yoloseg.pt' with input shape (20, 3, 160, 160) BCHW and output shape(s) ((20, 37, 525), (20, 32, 40, 40)) (12.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.52...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 4.2s, saved as 'Models/model_seg_fp16_1/best_yoloseg.onnx' (12.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.10.0.31...\n",
      "[05/12/2025-17:24:47] [TRT] [I] [MemUsageChange] Init CUDA: CPU -2, GPU +0, now: CPU 902, GPU 632 (MiB)\n",
      "[05/12/2025-17:24:49] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1745, GPU +6, now: CPU 2786, GPU 638 (MiB)\n",
      "[05/12/2025-17:24:49] [TRT] [I] ----------------------------------------------------------------\n",
      "[05/12/2025-17:24:49] [TRT] [I] Input filename:   Models/model_seg_fp16_1/best_yoloseg.onnx\n",
      "[05/12/2025-17:24:49] [TRT] [I] ONNX IR version:  0.0.9\n",
      "[05/12/2025-17:24:49] [TRT] [I] Opset version:    19\n",
      "[05/12/2025-17:24:49] [TRT] [I] Producer name:    pytorch\n",
      "[05/12/2025-17:24:49] [TRT] [I] Producer version: 2.8.0\n",
      "[05/12/2025-17:24:49] [TRT] [I] Domain:           \n",
      "[05/12/2025-17:24:49] [TRT] [I] Model version:    0\n",
      "[05/12/2025-17:24:49] [TRT] [I] Doc string:       \n",
      "[05/12/2025-17:24:49] [TRT] [I] ----------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(-1, 3, -1, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(-1, 37, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output1\" with shape(-1, 32, -1, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as Models/model_seg_fp16_1/best_yoloseg.engine\n",
      "[05/12/2025-17:24:52] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[05/12/2025-17:30:30] [TRT] [I] Detected 1 inputs and 5 output network tensors.\n",
      "[05/12/2025-17:30:33] [TRT] [I] Total Host Persistent Memory: 434592 bytes\n",
      "[05/12/2025-17:30:33] [TRT] [I] Total Device Persistent Memory: 11264 bytes\n",
      "[05/12/2025-17:30:33] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[05/12/2025-17:30:33] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 163 steps to complete.\n",
      "[05/12/2025-17:30:33] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 11.6798ms to assign 11 blocks to 163 nodes requiring 20362752 bytes.\n",
      "[05/12/2025-17:30:33] [TRT] [I] Total Activation Memory: 20361728 bytes\n",
      "[05/12/2025-17:30:33] [TRT] [I] Total Weights Memory: 6551556 bytes\n",
      "[05/12/2025-17:30:33] [TRT] [I] Engine generation completed in 341.131 seconds.\n",
      "[05/12/2025-17:30:33] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 32 MiB\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success âœ… 351.0s, saved as 'Models/model_seg_fp16_1/best_yoloseg.engine' (10.2 MB)\n",
      "\n",
      "Export complete (351.9s)\n",
      "Results saved to \u001b[1m/workspace/project_conveyer/Models/model_seg_fp16_1\u001b[0m\n",
      "Predict:         yolo predict task=segment model=Models/model_seg_fp16_1/best_yoloseg.engine imgsz=160 half \n",
      "Validate:        yolo val task=segment model=Models/model_seg_fp16_1/best_yoloseg.engine imgsz=160 data=C:\\Users\\Asus Rog Strix\\Desktop\\Multimodal\\Dataset\\data.yaml half \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Models/model_seg_fp16_1/best_yoloseg.engine'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"Models/model_seg_fp16_1/best_yoloseg.pt\")\n",
    "model.export(\n",
    "    format=\"engine\",\n",
    "    dynamic=True,  \n",
    "    imgsz=160,\n",
    "    batch=20,\n",
    "    half=True, \n",
    "    device=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7450c3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.105 ðŸš€ Python-3.12.3 torch-2.8.0.dev20250408+cu128 CUDA:0 (NVIDIA GeForce RTX 4090, 24082MiB)\n",
      "YOLOv8n-seg summary (fused): 85 layers, 3,258,259 parameters, 0 gradients, 12.0 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'Models/model_seg_fp16_0/best_yoloseg.pt' with input shape (20, 3, 160, 160) BCHW and output shape(s) ((20, 37, 525), (20, 32, 40, 40)) (12.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.52...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 4.3s, saved as 'Models/model_seg_fp16_0/best_yoloseg.onnx' (12.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.10.0.31...\n",
      "[05/12/2025-17:33:26] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU -1726, GPU +0, now: CPU 6219, GPU 730 (MiB)\n",
      "[05/12/2025-17:33:26] [TRT] [I] ----------------------------------------------------------------\n",
      "[05/12/2025-17:33:26] [TRT] [I] Input filename:   Models/model_seg_fp16_0/best_yoloseg.onnx\n",
      "[05/12/2025-17:33:26] [TRT] [I] ONNX IR version:  0.0.9\n",
      "[05/12/2025-17:33:26] [TRT] [I] Opset version:    19\n",
      "[05/12/2025-17:33:26] [TRT] [I] Producer name:    pytorch\n",
      "[05/12/2025-17:33:26] [TRT] [I] Producer version: 2.8.0\n",
      "[05/12/2025-17:33:26] [TRT] [I] Domain:           \n",
      "[05/12/2025-17:33:26] [TRT] [I] Model version:    0\n",
      "[05/12/2025-17:33:26] [TRT] [I] Doc string:       \n",
      "[05/12/2025-17:33:26] [TRT] [I] ----------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(-1, 3, -1, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(-1, 37, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output1\" with shape(-1, 32, -1, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as Models/model_seg_fp16_0/best_yoloseg.engine\n",
      "[05/12/2025-17:33:29] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[05/12/2025-17:38:48] [TRT] [I] Detected 1 inputs and 5 output network tensors.\n",
      "[05/12/2025-17:38:51] [TRT] [I] Total Host Persistent Memory: 432304 bytes\n",
      "[05/12/2025-17:38:51] [TRT] [I] Total Device Persistent Memory: 11264 bytes\n",
      "[05/12/2025-17:38:51] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[05/12/2025-17:38:51] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 158 steps to complete.\n",
      "[05/12/2025-17:38:52] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 13.8494ms to assign 13 blocks to 158 nodes requiring 20901376 bytes.\n",
      "[05/12/2025-17:38:52] [TRT] [I] Total Activation Memory: 20899328 bytes\n",
      "[05/12/2025-17:38:52] [TRT] [I] Total Weights Memory: 6552068 bytes\n",
      "[05/12/2025-17:38:52] [TRT] [I] Engine generation completed in 322.967 seconds.\n",
      "[05/12/2025-17:38:52] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 32 MiB\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success âœ… 333.0s, saved as 'Models/model_seg_fp16_0/best_yoloseg.engine' (10.0 MB)\n",
      "\n",
      "Export complete (333.1s)\n",
      "Results saved to \u001b[1m/workspace/project_conveyer/Models/model_seg_fp16_0\u001b[0m\n",
      "Predict:         yolo predict task=segment model=Models/model_seg_fp16_0/best_yoloseg.engine imgsz=160 half \n",
      "Validate:        yolo val task=segment model=Models/model_seg_fp16_0/best_yoloseg.engine imgsz=160 data=C:\\Users\\Asus Rog Strix\\Desktop\\Multimodal\\Dataset\\data.yaml half \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Models/model_seg_fp16_0/best_yoloseg.engine'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"Models/model_seg_fp16_0/best_yoloseg.pt\")\n",
    "model.export(\n",
    "    format=\"engine\",\n",
    "    dynamic=True,  \n",
    "    imgsz=160,\n",
    "    batch=20,\n",
    "    half=True, \n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ffbe4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.105 ðŸš€ Python-3.12.3 torch-2.8.0.dev20250408+cu128 CUDA:1 (NVIDIA GeForce RTX 4090, 24082MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'Models/model_det_fp16_1/best.pt' with input shape (20, 3, 640, 640) BCHW and output shape(s) (20, 5, 8400) (6.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.52...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 3.0s, saved as 'Models/model_det_fp16_1/best.onnx' (11.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.10.0.31...\n",
      "[05/12/2025-17:41:58] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU -1726, GPU +0, now: CPU 6261, GPU 1208 (MiB)\n",
      "[05/12/2025-17:41:58] [TRT] [I] ----------------------------------------------------------------\n",
      "[05/12/2025-17:41:58] [TRT] [I] Input filename:   Models/model_det_fp16_1/best.onnx\n",
      "[05/12/2025-17:41:58] [TRT] [I] ONNX IR version:  0.0.9\n",
      "[05/12/2025-17:41:58] [TRT] [I] Opset version:    19\n",
      "[05/12/2025-17:41:58] [TRT] [I] Producer name:    pytorch\n",
      "[05/12/2025-17:41:58] [TRT] [I] Producer version: 2.8.0\n",
      "[05/12/2025-17:41:58] [TRT] [I] Domain:           \n",
      "[05/12/2025-17:41:58] [TRT] [I] Model version:    0\n",
      "[05/12/2025-17:41:58] [TRT] [I] Doc string:       \n",
      "[05/12/2025-17:41:58] [TRT] [I] ----------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(-1, 3, -1, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(-1, 5, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as Models/model_det_fp16_1/best.engine\n",
      "[05/12/2025-17:42:01] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[05/12/2025-17:45:01] [TRT] [I] Detected 1 inputs and 3 output network tensors.\n",
      "[05/12/2025-17:45:04] [TRT] [I] Total Host Persistent Memory: 385904 bytes\n",
      "[05/12/2025-17:45:04] [TRT] [I] Total Device Persistent Memory: 1024 bytes\n",
      "[05/12/2025-17:45:04] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[05/12/2025-17:45:04] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 146 steps to complete.\n",
      "[05/12/2025-17:45:04] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 9.99773ms to assign 9 blocks to 146 nodes requiring 181477888 bytes.\n",
      "[05/12/2025-17:45:04] [TRT] [I] Total Activation Memory: 181477376 bytes\n",
      "[05/12/2025-17:45:04] [TRT] [I] Total Weights Memory: 6039808 bytes\n",
      "[05/12/2025-17:45:04] [TRT] [I] Engine generation completed in 182.841 seconds.\n",
      "[05/12/2025-17:45:04] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 500 MiB\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success âœ… 191.8s, saved as 'Models/model_det_fp16_1/best.engine' (9.5 MB)\n",
      "\n",
      "Export complete (192.0s)\n",
      "Results saved to \u001b[1m/workspace/project_conveyer/Models/model_det_fp16_1\u001b[0m\n",
      "Predict:         yolo predict task=detect model=Models/model_det_fp16_1/best.engine imgsz=640 half \n",
      "Validate:        yolo val task=detect model=Models/model_det_fp16_1/best.engine imgsz=640 data=C:\\Users\\Asus Rog Strix\\Desktop\\Multimodal\\potato check.v4i.yolov8\\data.yaml half \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Models/model_det_fp16_1/best.engine'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"Models/model_det_fp16_1/best.pt\")\n",
    "model.export(\n",
    "    format=\"engine\",\n",
    "    dynamic=True,  \n",
    "    imgsz=(640, 640),\n",
    "    batch=20,  \n",
    "    half=True,\n",
    "    device=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6307f7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.105 ðŸš€ Python-3.12.3 torch-2.8.0.dev20250408+cu128 CUDA:0 (NVIDIA GeForce RTX 4090, 24082MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'Models/model_det_fp16_0/best.pt' with input shape (20, 3, 640, 640) BCHW and output shape(s) (20, 5, 8400) (6.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.52...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 3.1s, saved as 'Models/model_det_fp16_0/best.onnx' (11.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.10.0.31...\n",
      "[05/12/2025-17:45:38] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU -1727, GPU +0, now: CPU 6248, GPU 1216 (MiB)\n",
      "[05/12/2025-17:45:38] [TRT] [I] ----------------------------------------------------------------\n",
      "[05/12/2025-17:45:38] [TRT] [I] Input filename:   Models/model_det_fp16_0/best.onnx\n",
      "[05/12/2025-17:45:38] [TRT] [I] ONNX IR version:  0.0.9\n",
      "[05/12/2025-17:45:38] [TRT] [I] Opset version:    19\n",
      "[05/12/2025-17:45:38] [TRT] [I] Producer name:    pytorch\n",
      "[05/12/2025-17:45:38] [TRT] [I] Producer version: 2.8.0\n",
      "[05/12/2025-17:45:38] [TRT] [I] Domain:           \n",
      "[05/12/2025-17:45:38] [TRT] [I] Model version:    0\n",
      "[05/12/2025-17:45:38] [TRT] [I] Doc string:       \n",
      "[05/12/2025-17:45:38] [TRT] [I] ----------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(-1, 3, -1, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(-1, 5, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as Models/model_det_fp16_0/best.engine\n",
      "[05/12/2025-17:45:41] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[05/12/2025-17:49:34] [TRT] [I] Detected 1 inputs and 3 output network tensors.\n",
      "[05/12/2025-17:49:36] [TRT] [I] Total Host Persistent Memory: 383008 bytes\n",
      "[05/12/2025-17:49:36] [TRT] [I] Total Device Persistent Memory: 1024 bytes\n",
      "[05/12/2025-17:49:36] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[05/12/2025-17:49:36] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 145 steps to complete.\n",
      "[05/12/2025-17:49:36] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 10.03ms to assign 9 blocks to 145 nodes requiring 181349888 bytes.\n",
      "[05/12/2025-17:49:36] [TRT] [I] Total Activation Memory: 181349376 bytes\n",
      "[05/12/2025-17:49:36] [TRT] [I] Total Weights Memory: 6039808 bytes\n",
      "[05/12/2025-17:49:37] [TRT] [I] Engine generation completed in 235.902 seconds.\n",
      "[05/12/2025-17:49:37] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 500 MiB\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success âœ… 244.9s, saved as 'Models/model_det_fp16_0/best.engine' (9.5 MB)\n",
      "\n",
      "Export complete (245.1s)\n",
      "Results saved to \u001b[1m/workspace/project_conveyer/Models/model_det_fp16_0\u001b[0m\n",
      "Predict:         yolo predict task=detect model=Models/model_det_fp16_0/best.engine imgsz=640 half \n",
      "Validate:        yolo val task=detect model=Models/model_det_fp16_0/best.engine imgsz=640 data=C:\\Users\\Asus Rog Strix\\Desktop\\Multimodal\\potato check.v4i.yolov8\\data.yaml half \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Models/model_det_fp16_0/best.engine'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"Models/model_det_fp16_0/best.pt\")\n",
    "model.export(\n",
    "    format=\"engine\",\n",
    "    dynamic=True,  \n",
    "    imgsz=(640, 640),\n",
    "    batch=20,  \n",
    "    half=True,\n",
    "    device=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66106851",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo val task=detect model=Models/model_det_int8/best.engine imgsz=640 data=/home/paperspace/datasets/Datasets/data.yaml int8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca323e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
