{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d716b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ba8b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.105 🚀 Python-3.12.3 torch-2.8.0.dev20250408+cu128 CUDA:1 (NVIDIA GeForce RTX 4090, 24092MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-seg summary (fused): 85 layers, 3,258,259 parameters, 0 gradients, 12.0 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'Models/model_seg_fp16_0/best_yoloseg.pt' with input shape (10, 3, 160, 160) BCHW and output shape(s) ((10, 37, 525), (10, 32, 40, 40)) (12.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.18.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.52...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 2.9s, saved as 'Models/model_seg_fp16_0/best_yoloseg.onnx' (12.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.9.0.34...\n",
      "[05/13/2025-18:35:09] [TRT] [I] The logger passed into createInferBuilder differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "[05/13/2025-18:35:09] [TRT] [I] ----------------------------------------------------------------\n",
      "[05/13/2025-18:35:09] [TRT] [I] Input filename:   Models/model_seg_fp16_0/best_yoloseg.onnx\n",
      "[05/13/2025-18:35:09] [TRT] [I] ONNX IR version:  0.0.9\n",
      "[05/13/2025-18:35:09] [TRT] [I] Opset version:    19\n",
      "[05/13/2025-18:35:09] [TRT] [I] Producer name:    pytorch\n",
      "[05/13/2025-18:35:09] [TRT] [I] Producer version: 2.8.0\n",
      "[05/13/2025-18:35:09] [TRT] [I] Domain:           \n",
      "[05/13/2025-18:35:09] [TRT] [I] Model version:    0\n",
      "[05/13/2025-18:35:09] [TRT] [I] Doc string:       \n",
      "[05/13/2025-18:35:09] [TRT] [I] ----------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(-1, 3, -1, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(-1, 37, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output1\" with shape(-1, 32, -1, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as Models/model_seg_fp16_0/best_yoloseg.engine\n",
      "[05/13/2025-18:35:10] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[05/13/2025-18:39:25] [TRT] [I] Detected 1 inputs and 5 output network tensors.\n",
      "[05/13/2025-18:39:27] [TRT] [I] Total Host Persistent Memory: 443072 bytes\n",
      "[05/13/2025-18:39:27] [TRT] [I] Total Device Persistent Memory: 7168 bytes\n",
      "[05/13/2025-18:39:27] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[05/13/2025-18:39:27] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 167 steps to complete.\n",
      "[05/13/2025-18:39:27] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 10.2192ms to assign 14 blocks to 167 nodes requiring 10313728 bytes.\n",
      "[05/13/2025-18:39:27] [TRT] [I] Total Activation Memory: 10312192 bytes\n",
      "[05/13/2025-18:39:27] [TRT] [I] Total Weights Memory: 6551564 bytes\n",
      "[05/13/2025-18:39:27] [TRT] [I] Engine generation completed in 257.665 seconds.\n",
      "[05/13/2025-18:39:27] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 125 MiB, GPU 625 MiB\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 261.3s, saved as 'Models/model_seg_fp16_0/best_yoloseg.engine' (9.2 MB)\n",
      "\n",
      "Export complete (261.5s)\n",
      "Results saved to \u001b[1m/workspace/project_conveyer/Models/model_seg_fp16_0\u001b[0m\n",
      "Predict:         yolo predict task=segment model=Models/model_seg_fp16_0/best_yoloseg.engine imgsz=160 half \n",
      "Validate:        yolo val task=segment model=Models/model_seg_fp16_0/best_yoloseg.engine imgsz=160 data=C:\\Users\\Asus Rog Strix\\Desktop\\Multimodal\\Dataset\\data.yaml half \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Models/model_seg_fp16_0/best_yoloseg.engine'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"Models/model_seg_fp16_0/best_yoloseg.pt\")\n",
    "model.export(\n",
    "    format=\"engine\",\n",
    "    dynamic=True,  \n",
    "    imgsz=160,\n",
    "    batch=10,\n",
    "    half=True, \n",
    "    device=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc099a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.105 🚀 Python-3.12.3 torch-2.8.0.dev20250408+cu128 CUDA:1 (NVIDIA GeForce RTX 4090, 24092MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-seg summary (fused): 85 layers, 3,258,259 parameters, 0 gradients, 12.0 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'Models/model_seg_fp16_1/best_yoloseg.pt' with input shape (10, 3, 160, 160) BCHW and output shape(s) ((10, 37, 525), (10, 32, 40, 40)) (12.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.18.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.52...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 3.3s, saved as 'Models/model_seg_fp16_1/best_yoloseg.onnx' (12.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.9.0.34...\n",
      "[05/13/2025-18:42:06] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU -2762, GPU +422, now: CPU 6063, GPU 4812 (MiB)\n",
      "[05/13/2025-18:42:06] [TRT] [I] ----------------------------------------------------------------\n",
      "[05/13/2025-18:42:06] [TRT] [I] Input filename:   Models/model_seg_fp16_1/best_yoloseg.onnx\n",
      "[05/13/2025-18:42:06] [TRT] [I] ONNX IR version:  0.0.9\n",
      "[05/13/2025-18:42:06] [TRT] [I] Opset version:    19\n",
      "[05/13/2025-18:42:06] [TRT] [I] Producer name:    pytorch\n",
      "[05/13/2025-18:42:06] [TRT] [I] Producer version: 2.8.0\n",
      "[05/13/2025-18:42:06] [TRT] [I] Domain:           \n",
      "[05/13/2025-18:42:06] [TRT] [I] Model version:    0\n",
      "[05/13/2025-18:42:06] [TRT] [I] Doc string:       \n",
      "[05/13/2025-18:42:06] [TRT] [I] ----------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(-1, 3, -1, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(-1, 37, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output1\" with shape(-1, 32, -1, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as Models/model_seg_fp16_1/best_yoloseg.engine\n",
      "[05/13/2025-18:42:06] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[05/13/2025-18:46:14] [TRT] [I] Detected 1 inputs and 5 output network tensors.\n",
      "[05/13/2025-18:46:16] [TRT] [I] Total Host Persistent Memory: 438976 bytes\n",
      "[05/13/2025-18:46:16] [TRT] [I] Total Device Persistent Memory: 7168 bytes\n",
      "[05/13/2025-18:46:16] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[05/13/2025-18:46:16] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 167 steps to complete.\n",
      "[05/13/2025-18:46:16] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 11.3163ms to assign 14 blocks to 167 nodes requiring 10365440 bytes.\n",
      "[05/13/2025-18:46:16] [TRT] [I] Total Activation Memory: 10363904 bytes\n",
      "[05/13/2025-18:46:16] [TRT] [I] Total Weights Memory: 6553094 bytes\n",
      "[05/13/2025-18:46:16] [TRT] [I] Engine generation completed in 250.158 seconds.\n",
      "[05/13/2025-18:46:16] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 125 MiB, GPU 625 MiB\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 257.0s, saved as 'Models/model_seg_fp16_1/best_yoloseg.engine' (9.3 MB)\n",
      "\n",
      "Export complete (257.1s)\n",
      "Results saved to \u001b[1m/workspace/project_conveyer/Models/model_seg_fp16_1\u001b[0m\n",
      "Predict:         yolo predict task=segment model=Models/model_seg_fp16_1/best_yoloseg.engine imgsz=160 half \n",
      "Validate:        yolo val task=segment model=Models/model_seg_fp16_1/best_yoloseg.engine imgsz=160 data=C:\\Users\\Asus Rog Strix\\Desktop\\Multimodal\\Dataset\\data.yaml half \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Models/model_seg_fp16_1/best_yoloseg.engine'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"Models/model_seg_fp16_1/best_yoloseg.pt\")\n",
    "model.export(\n",
    "    format=\"engine\",\n",
    "    dynamic=True,  \n",
    "    imgsz=160,\n",
    "    batch=10,\n",
    "    half=True, \n",
    "    device=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7450c3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.105 🚀 Python-3.12.3 torch-2.8.0.dev20250408+cu128 CUDA:0 (NVIDIA GeForce RTX 4090, 24092MiB)\n",
      "YOLOv8n-seg summary (fused): 85 layers, 3,258,259 parameters, 0 gradients, 12.0 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'Models/model_seg_fp16_0_20/best_yoloseg.pt' with input shape (400, 3, 160, 160) BCHW and output shape(s) ((400, 37, 525), (400, 32, 40, 40)) (12.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.18.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.52...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 2.9s, saved as 'Models/model_seg_fp16_0_20/best_yoloseg.onnx' (12.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.9.0.34...\n",
      "[05/13/2025-16:56:00] [TRT] [I] [MemUsageChange] Init CUDA: CPU -2, GPU +0, now: CPU 984, GPU 1793 (MiB)\n",
      "[05/13/2025-16:56:02] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +2772, GPU +446, now: CPU 3893, GPU 2239 (MiB)\n",
      "[05/13/2025-16:56:02] [TRT] [I] ----------------------------------------------------------------\n",
      "[05/13/2025-16:56:02] [TRT] [I] Input filename:   Models/model_seg_fp16_0_20/best_yoloseg.onnx\n",
      "[05/13/2025-16:56:02] [TRT] [I] ONNX IR version:  0.0.9\n",
      "[05/13/2025-16:56:02] [TRT] [I] Opset version:    19\n",
      "[05/13/2025-16:56:02] [TRT] [I] Producer name:    pytorch\n",
      "[05/13/2025-16:56:02] [TRT] [I] Producer version: 2.8.0\n",
      "[05/13/2025-16:56:02] [TRT] [I] Domain:           \n",
      "[05/13/2025-16:56:02] [TRT] [I] Model version:    0\n",
      "[05/13/2025-16:56:02] [TRT] [I] Doc string:       \n",
      "[05/13/2025-16:56:02] [TRT] [I] ----------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(-1, 3, -1, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(-1, 37, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output1\" with shape(-1, 32, -1, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as Models/model_seg_fp16_0_20/best_yoloseg.engine\n",
      "[05/13/2025-16:56:02] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[05/13/2025-16:59:37] [TRT] [I] Detected 1 inputs and 5 output network tensors.\n",
      "[05/13/2025-16:59:39] [TRT] [I] Total Host Persistent Memory: 433440 bytes\n",
      "[05/13/2025-16:59:39] [TRT] [I] Total Device Persistent Memory: 7168 bytes\n",
      "[05/13/2025-16:59:39] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[05/13/2025-16:59:39] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 169 steps to complete.\n",
      "[05/13/2025-16:59:39] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 9.90429ms to assign 12 blocks to 169 nodes requiring 300029440 bytes.\n",
      "[05/13/2025-16:59:39] [TRT] [I] Total Activation Memory: 300027904 bytes\n",
      "[05/13/2025-16:59:39] [TRT] [I] Total Weights Memory: 6551296 bytes\n",
      "[05/13/2025-16:59:39] [TRT] [I] Engine generation completed in 216.852 seconds.\n",
      "[05/13/2025-16:59:39] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 625 MiB\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 222.5s, saved as 'Models/model_seg_fp16_0_20/best_yoloseg.engine' (10.2 MB)\n",
      "\n",
      "Export complete (223.2s)\n",
      "Results saved to \u001b[1m/workspace/project_conveyer/Models/model_seg_fp16_0_20\u001b[0m\n",
      "Predict:         yolo predict task=segment model=Models/model_seg_fp16_0_20/best_yoloseg.engine imgsz=160 half \n",
      "Validate:        yolo val task=segment model=Models/model_seg_fp16_0_20/best_yoloseg.engine imgsz=160 data=C:\\Users\\Asus Rog Strix\\Desktop\\Multimodal\\Dataset\\data.yaml half \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Models/model_seg_fp16_0_20/best_yoloseg.engine'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"Models/model_seg_fp16_0_20/best_yoloseg.pt\")\n",
    "model.export(\n",
    "    format=\"engine\",\n",
    "    dynamic=True,  \n",
    "    imgsz=160,\n",
    "    batch=400,\n",
    "    half=True, \n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ffbe4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.105 🚀 Python-3.12.3 torch-2.8.0.dev20250408+cu128 CUDA:0 (NVIDIA GeForce RTX 4090, 24092MiB)\n",
      "WARNING ⚠️ half=True and int8=True are mutually exclusive, setting half=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'Models/model_det_int8_0_20/best.pt' with input shape (20, 3, 640, 640) BCHW and output shape(s) (20, 5, 8400) (6.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.18.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.52...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.7s, saved as 'Models/model_det_int8_0_20/best.onnx' (11.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.9.0.34...\n",
      "[05/13/2025-18:26:01] [TRT] [I] The logger passed into createInferBuilder differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "[05/13/2025-18:26:01] [TRT] [I] ----------------------------------------------------------------\n",
      "[05/13/2025-18:26:01] [TRT] [I] Input filename:   Models/model_det_int8_0_20/best.onnx\n",
      "[05/13/2025-18:26:01] [TRT] [I] ONNX IR version:  0.0.9\n",
      "[05/13/2025-18:26:01] [TRT] [I] Opset version:    19\n",
      "[05/13/2025-18:26:01] [TRT] [I] Producer name:    pytorch\n",
      "[05/13/2025-18:26:01] [TRT] [I] Producer version: 2.8.0\n",
      "[05/13/2025-18:26:01] [TRT] [I] Domain:           \n",
      "[05/13/2025-18:26:01] [TRT] [I] Model version:    0\n",
      "[05/13/2025-18:26:01] [TRT] [I] Doc string:       \n",
      "[05/13/2025-18:26:01] [TRT] [I] ----------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(-1, 3, -1, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(-1, 5, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building INT8 engine as Models/model_det_int8_0_20/best.engine\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m collecting INT8 calibration images from 'data=/workspace/datasets/Dataset/data.yaml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning /workspace/datasets/Dataset/valid/labels... 221 images, 0 backgrounds, 0 corrupt: 100%|██████████| 221/221 [00:00<00:00, 932.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New cache created: /workspace/datasets/Dataset/valid/labels.cache\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m WARNING ⚠️ >300 images recommended for INT8 calibration, found 221 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/13/2025-18:26:02] [TRT] [I] Perform graph optimization on calibration graph.\n",
      "[05/13/2025-18:26:02] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[05/13/2025-18:26:02] [TRT] [I] Compiler backend is used during engine build.\n",
      "[05/13/2025-18:26:04] [TRT] [I] Detected 1 inputs and 3 output network tensors.\n",
      "[05/13/2025-18:26:05] [TRT] [I] Total Host Persistent Memory: 281168 bytes\n",
      "[05/13/2025-18:26:05] [TRT] [I] Total Device Persistent Memory: 907776 bytes\n",
      "[05/13/2025-18:26:05] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[05/13/2025-18:26:05] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 315 steps to complete.\n",
      "[05/13/2025-18:26:05] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 55.7549ms to assign 28 blocks to 315 nodes requiring 507976192 bytes.\n",
      "[05/13/2025-18:26:05] [TRT] [I] Total Activation Memory: 507976192 bytes\n",
      "[05/13/2025-18:26:05] [TRT] [I] Total Weights Memory: 17309760 bytes\n",
      "[05/13/2025-18:26:05] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[05/13/2025-18:26:05] [TRT] [I] Engine generation completed in 3.62971 seconds.\n",
      "[05/13/2025-18:26:06] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +486, now: CPU 0, GPU 503 (MiB)\n",
      "[05/13/2025-18:26:06] [TRT] [I] Starting Calibration.\n",
      "[05/13/2025-18:26:07] [TRT] [I]   Calibrated batch 0 in 1.07551 seconds.\n",
      "[05/13/2025-18:26:08] [TRT] [I]   Calibrated batch 1 in 1.06721 seconds.\n",
      "[05/13/2025-18:26:10] [TRT] [I]   Calibrated batch 2 in 1.03241 seconds.\n",
      "[05/13/2025-18:26:11] [TRT] [I]   Calibrated batch 3 in 1.06349 seconds.\n",
      "[05/13/2025-18:26:12] [TRT] [I]   Calibrated batch 4 in 1.05301 seconds.\n",
      "[05/13/2025-18:26:14] [TRT] [I]   Calibrated batch 5 in 1.04546 seconds.\n",
      "[05/13/2025-18:26:31] [TRT] [I]   Post Processing Calibration data in 17.2092 seconds.\n",
      "[05/13/2025-18:26:31] [TRT] [I] Calibration completed in 29.045 seconds.\n",
      "[05/13/2025-18:26:31] [TRT] [I] Writing Calibration Cache for calibrator: TRT-100900-EntropyCalibration2\n",
      "[05/13/2025-18:26:31] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[05/13/2025-18:28:34] [TRT] [I] Detected 1 inputs and 3 output network tensors.\n",
      "[05/13/2025-18:28:39] [TRT] [I] Total Host Persistent Memory: 357904 bytes\n",
      "[05/13/2025-18:28:39] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[05/13/2025-18:28:39] [TRT] [I] Max Scratch Memory: 43008000 bytes\n",
      "[05/13/2025-18:28:39] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 147 steps to complete.\n",
      "[05/13/2025-18:28:39] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 6.15846ms to assign 12 blocks to 147 nodes requiring 178186752 bytes.\n",
      "[05/13/2025-18:28:39] [TRT] [I] Total Activation Memory: 178185216 bytes\n",
      "[05/13/2025-18:28:39] [TRT] [I] Total Weights Memory: 3185668 bytes\n",
      "[05/13/2025-18:28:39] [TRT] [I] Engine generation completed in 128.188 seconds.\n",
      "[05/13/2025-18:28:39] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 125 MiB, GPU 625 MiB\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 159.5s, saved as 'Models/model_det_int8_0_20/best.engine' (8.0 MB)\n",
      "\n",
      "Export complete (159.7s)\n",
      "Results saved to \u001b[1m/workspace/project_conveyer/Models/model_det_int8_0_20\u001b[0m\n",
      "Predict:         yolo predict task=detect model=Models/model_det_int8_0_20/best.engine imgsz=640 int8 \n",
      "Validate:        yolo val task=detect model=Models/model_det_int8_0_20/best.engine imgsz=640 data=C:\\Users\\Asus Rog Strix\\Desktop\\Multimodal\\potato check.v4i.yolov8\\data.yaml int8 \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Models/model_det_int8_0_20/best.engine'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"Models/model_det_int8_0_20/best.pt\")\n",
    "model.export(\n",
    "    format=\"engine\",\n",
    "    dynamic=True,  \n",
    "    imgsz=(640, 640),\n",
    "    batch=20,  \n",
    "    half=True,\n",
    "    workspace=True,\n",
    "    int8=True,\n",
    "    data='/workspace/datasets/Dataset/data.yaml',\n",
    "    device=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6307f7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.105 🚀 Python-3.12.3 torch-2.8.0.dev20250408+cu128 CUDA:1 (NVIDIA GeForce RTX 4090, 24092MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'Models/model_det_fp16_1/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (6.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.18.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.52...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 2.3s, saved as 'Models/model_det_fp16_1/best.onnx' (11.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.9.0.34...\n",
      "[05/13/2025-18:52:04] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU -2762, GPU +420, now: CPU 7145, GPU 4824 (MiB)\n",
      "[05/13/2025-18:52:04] [TRT] [I] ----------------------------------------------------------------\n",
      "[05/13/2025-18:52:04] [TRT] [I] Input filename:   Models/model_det_fp16_1/best.onnx\n",
      "[05/13/2025-18:52:04] [TRT] [I] ONNX IR version:  0.0.9\n",
      "[05/13/2025-18:52:04] [TRT] [I] Opset version:    19\n",
      "[05/13/2025-18:52:04] [TRT] [I] Producer name:    pytorch\n",
      "[05/13/2025-18:52:04] [TRT] [I] Producer version: 2.8.0\n",
      "[05/13/2025-18:52:04] [TRT] [I] Domain:           \n",
      "[05/13/2025-18:52:04] [TRT] [I] Model version:    0\n",
      "[05/13/2025-18:52:04] [TRT] [I] Doc string:       \n",
      "[05/13/2025-18:52:04] [TRT] [I] ----------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(-1, 3, -1, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(-1, 5, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m WARNING ⚠️ 'dynamic=True' model requires max batch size, i.e. 'batch=16'\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as Models/model_det_fp16_1/best.engine\n",
      "[05/13/2025-18:52:04] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[05/13/2025-18:54:21] [TRT] [I] Detected 1 inputs and 3 output network tensors.\n",
      "[05/13/2025-18:54:22] [TRT] [I] Total Host Persistent Memory: 384896 bytes\n",
      "[05/13/2025-18:54:22] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[05/13/2025-18:54:22] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[05/13/2025-18:54:22] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 169 steps to complete.\n",
      "[05/13/2025-18:54:22] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 8.49813ms to assign 12 blocks to 169 nodes requiring 13322752 bytes.\n",
      "[05/13/2025-18:54:22] [TRT] [I] Total Activation Memory: 13321216 bytes\n",
      "[05/13/2025-18:54:22] [TRT] [I] Total Weights Memory: 6042636 bytes\n",
      "[05/13/2025-18:54:22] [TRT] [I] Engine generation completed in 137.891 seconds.\n",
      "[05/13/2025-18:54:22] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 125 MiB, GPU 625 MiB\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 143.6s, saved as 'Models/model_det_fp16_1/best.engine' (8.5 MB)\n",
      "\n",
      "Export complete (143.8s)\n",
      "Results saved to \u001b[1m/workspace/project_conveyer/Models/model_det_fp16_1\u001b[0m\n",
      "Predict:         yolo predict task=detect model=Models/model_det_fp16_1/best.engine imgsz=640 half \n",
      "Validate:        yolo val task=detect model=Models/model_det_fp16_1/best.engine imgsz=640 data=C:\\Users\\Asus Rog Strix\\Desktop\\Multimodal\\potato check.v4i.yolov8\\data.yaml half \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Models/model_det_fp16_1/best.engine'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"Models/model_det_fp16_1/best.pt\")\n",
    "model.export(\n",
    "    format=\"engine\",\n",
    "    dynamic=True,  \n",
    "    imgsz=(640, 640),\n",
    "    batch=1,  \n",
    "    half=True,\n",
    "    device=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66106851",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo val task=detect model=Models/model_det_int8/best.engine imgsz=640 data=/home/paperspace/datasets/Datasets/data.yaml int8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca323e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
