{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Initialize a YOLO-World model\n",
    "model = YOLO(\"best (2).pt\")  # or choose yolov8m/l-world.pt\n",
    "model_seg = YOLO(\"best_yoloseg.pt\")\n",
    "\n",
    "import glob\n",
    "videos = sorted(glob.glob('vides/*'))\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vides/Дизайн без названия (1) 2.mp4', 'vides/Дизайн без названия (2) 2.mp4', 'vides/Дизайн без названия (3) 2.mp4', 'vides/Дизайн без названия.mp4', 'vides/Дизайн без названия (1).mp4', 'vides/Дизайн без названия (10).mp4', 'vides/Дизайн без названия (11).mp4', 'vides/Дизайн без названия (12).mp4', 'vides/Дизайн без названия (13).mp4', 'vides/Дизайн без названия (14).mp4', 'vides/Дизайн без названия (15).mp4', 'vides/Дизайн без названия (16).mp4', 'vides/Дизайн без названия (17).mp4', 'vides/Дизайн без названия (18).mp4', 'vides/Дизайн без названия (2).mp4', 'vides/Дизайн без названия (20).mp4', 'vides/Дизайн без названия (21).mp4', 'vides/Дизайн без названия (22).mp4', 'vides/Дизайн без названия (23).mp4', 'vides/Дизайн без названия (24).mp4', 'vides/Дизайн без названия (25).mp4', 'vides/Дизайн без названия (26).mp4', 'vides/Дизайн без названия (27).mp4', 'vides/Дизайн без названия (28).mp4', 'vides/Дизайн без названия (29).mp4', 'vides/Дизайн без названия (3).mp4', 'vides/Дизайн без названия (30).mp4', 'vides/Дизайн без названия (31).mp4', 'vides/Дизайн без названия (32).mp4', 'vides/Дизайн без названия (33).mp4', 'vides/Дизайн без названия (34).mp4', 'vides/Дизайн без названия (4).mp4', 'vides/Дизайн без названия (5).mp4', 'vides/Дизайн без названия (6).mp4', 'vides/Дизайн без названия (7).mp4', 'vides/Дизайн без названия (8).mp4', 'vides/Дизайн без названия (9).mp4']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "videos = sorted(glob.glob('vides/*'))\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x320 1 potato, 51.4ms\n",
      "1: 320x320 1 potato, 51.4ms\n",
      "2: 320x320 1 potato, 51.4ms\n",
      "3: 320x320 2 potatos, 51.4ms\n",
      "4: 320x320 2 potatos, 51.4ms\n",
      "5: 320x320 2 potatos, 51.4ms\n",
      "6: 320x320 5 potatos, 51.4ms\n",
      "7: 320x320 4 potatos, 51.4ms\n",
      "8: 320x320 4 potatos, 51.4ms\n",
      "9: 320x320 4 potatos, 51.4ms\n",
      "10: 320x320 2 potatos, 51.4ms\n",
      "11: 320x320 3 potatos, 51.4ms\n",
      "12: 320x320 5 potatos, 51.4ms\n",
      "13: 320x320 1 potato, 51.4ms\n",
      "14: 320x320 4 potatos, 51.4ms\n",
      "15: 320x320 5 potatos, 51.4ms\n",
      "16: 320x320 1 potato, 51.4ms\n",
      "17: 320x320 6 potatos, 51.4ms\n",
      "18: 320x320 1 potato, 51.4ms\n",
      "19: 320x320 3 potatos, 51.4ms\n",
      "20: 320x320 3 potatos, 51.4ms\n",
      "21: 320x320 6 potatos, 51.4ms\n",
      "22: 320x320 3 potatos, 51.4ms\n",
      "23: 320x320 6 potatos, 51.4ms\n",
      "24: 320x320 3 potatos, 51.4ms\n",
      "25: 320x320 8 potatos, 51.4ms\n",
      "26: 320x320 5 potatos, 51.4ms\n",
      "27: 320x320 1 potato, 51.4ms\n",
      "28: 320x320 2 potatos, 51.4ms\n",
      "29: 320x320 5 potatos, 51.4ms\n",
      "Speed: 0.8ms preprocess, 51.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 320)\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [141, 148, 140],\n",
      "        ...,\n",
      "        [105, 124, 101],\n",
      "        [105, 124, 101],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [130, 133, 109],\n",
      "        ...,\n",
      "        [157, 181, 147],\n",
      "        [159, 183, 150],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [130, 133, 109],\n",
      "        ...,\n",
      "        [157, 181, 147],\n",
      "        [159, 183, 150],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (202, 234)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 62,  91,  44],\n",
      "        ...,\n",
      "        [ 46,  72,  97],\n",
      "        [ 47,  73,  98],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 69,  73,  55],\n",
      "        ...,\n",
      "        [102, 139,  84],\n",
      "        [103, 140,  86],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 69,  73,  55],\n",
      "        ...,\n",
      "        [103, 140,  86],\n",
      "        [103, 140,  86],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (232, 225)\n",
      "path: 'image1.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [125, 138, 112],\n",
      "        ...,\n",
      "        [140, 150, 136],\n",
      "        [140, 150, 136],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [111, 113,  88],\n",
      "        ...,\n",
      "        [104, 120,  86],\n",
      "        [104, 120,  86],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [113, 112,  89],\n",
      "        ...,\n",
      "        [104, 120,  86],\n",
      "        [104, 120,  86],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (374, 385)\n",
      "path: 'image2.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 97, 164, 230],\n",
      "        ...,\n",
      "        [ 89, 140, 197],\n",
      "        [ 88, 139, 196],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 72,  93,  51],\n",
      "        ...,\n",
      "        [ 53,  63,  32],\n",
      "        [ 52,  62,  31],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 73,  94,  52],\n",
      "        ...,\n",
      "        [ 54,  65,  35],\n",
      "        [ 53,  63,  32],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (205, 200)\n",
      "path: 'image3.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 40,  80, 113],\n",
      "        ...,\n",
      "        [ 47, 116, 190],\n",
      "        [ 42, 118, 192],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [123, 127, 107],\n",
      "        ...,\n",
      "        [103, 124, 101],\n",
      "        [105, 126, 103],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [120, 125, 104],\n",
      "        ...,\n",
      "        [103, 124, 101],\n",
      "        [105, 126, 103],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (235, 261)\n",
      "path: 'image4.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 38,  37,  20],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [122, 125, 108],\n",
      "        ...,\n",
      "        [ 68,  76,  45],\n",
      "        [ 67,  75,  44],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [122, 125, 108],\n",
      "        ...,\n",
      "        [ 69,  77,  46],\n",
      "        [ 68,  76,  45],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (209, 207)\n",
      "path: 'image5.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [203, 210, 196],\n",
      "        ...,\n",
      "        [195, 195, 188],\n",
      "        [195, 195, 188],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [140, 133, 122],\n",
      "        ...,\n",
      "        [123, 173, 230],\n",
      "        [123, 173, 230],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [140, 133, 122],\n",
      "        ...,\n",
      "        [124, 174, 231],\n",
      "        [124, 174, 231],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (151, 152)\n",
      "path: 'image6.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [159, 222, 252],\n",
      "        ...,\n",
      "        [ 74, 160, 230],\n",
      "        [ 75, 161, 231],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 23,  20,   1],\n",
      "        ...,\n",
      "        [102, 171, 229],\n",
      "        [102, 171, 229],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 24,  22,   2],\n",
      "        ...,\n",
      "        [103, 172, 230],\n",
      "        [103, 172, 230],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (197, 176)\n",
      "path: 'image7.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [101, 179, 233],\n",
      "        [100, 178, 232],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [112, 171, 231],\n",
      "        ...,\n",
      "        [100, 118,  95],\n",
      "        [100, 118,  95],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [112, 171, 231],\n",
      "        ...,\n",
      "        [100, 118,  95],\n",
      "        [100, 118,  95],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (255, 246)\n",
      "path: 'image8.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [117, 181, 243],\n",
      "        ...,\n",
      "        [109, 175, 243],\n",
      "        [111, 178, 245],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [111, 190, 245],\n",
      "        ...,\n",
      "        [ 76,  93,  77],\n",
      "        [ 77,  94,  79],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [110, 189, 244],\n",
      "        ...,\n",
      "        [ 76,  93,  77],\n",
      "        [ 77,  94,  79],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (173, 175)\n",
      "path: 'image9.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [195, 207, 179],\n",
      "        ...,\n",
      "        [193, 204, 183],\n",
      "        [193, 204, 183],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [108, 172, 239],\n",
      "        ...,\n",
      "        [ 91, 137, 190],\n",
      "        [ 91, 137, 190],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [110, 174, 242],\n",
      "        ...,\n",
      "        [ 88, 132, 186],\n",
      "        [ 88, 132, 186],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (261, 204)\n",
      "path: 'image10.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 93, 164, 222],\n",
      "        ...,\n",
      "        [108, 117, 145],\n",
      "        [112, 122, 152],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 53,  48,  28],\n",
      "        ...,\n",
      "        [179, 175, 152],\n",
      "        [180, 176, 153],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 51,  48,  30],\n",
      "        ...,\n",
      "        [176, 175, 152],\n",
      "        [178, 176, 153],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (196, 182)\n",
      "path: 'image11.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [108, 188, 236],\n",
      "        ...,\n",
      "        [ 90, 159, 219],\n",
      "        [ 93, 161, 222],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 89,  95, 132],\n",
      "        ...,\n",
      "        [115, 198, 246],\n",
      "        [115, 198, 246],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [120, 131, 169],\n",
      "        ...,\n",
      "        [113, 197, 245],\n",
      "        [113, 197, 245],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (161, 155)\n",
      "path: 'image12.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [212, 219, 218],\n",
      "        ...,\n",
      "        [215, 221, 224],\n",
      "        [215, 221, 224],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [166, 164, 152],\n",
      "        ...,\n",
      "        [173, 168, 168],\n",
      "        [174, 167, 168],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [167, 165, 153],\n",
      "        ...,\n",
      "        [173, 168, 168],\n",
      "        [174, 167, 168],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (125, 106)\n",
      "path: 'image13.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 53, 126, 198],\n",
      "        ...,\n",
      "        [ 94, 160, 228],\n",
      "        [ 93, 157, 225],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 93, 168, 233],\n",
      "        ...,\n",
      "        [ 58, 122, 195],\n",
      "        [ 58, 124, 197],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 95, 171, 236],\n",
      "        ...,\n",
      "        [ 60, 124, 197],\n",
      "        [ 60, 126, 200],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (173, 179)\n",
      "path: 'image14.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 44,  81, 119],\n",
      "        ...,\n",
      "        [102, 167, 231],\n",
      "        [ 98, 164, 228],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 76, 155, 230],\n",
      "        ...,\n",
      "        [103,  96,  74],\n",
      "        [103,  96,  74],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 74, 153, 228],\n",
      "        ...,\n",
      "        [103,  96,  74],\n",
      "        [103,  96,  74],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (195, 203)\n",
      "path: 'image15.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [173, 193, 194],\n",
      "        ...,\n",
      "        [159, 178, 192],\n",
      "        [158, 176, 190],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [165, 162, 155],\n",
      "        ...,\n",
      "        [190, 194, 195],\n",
      "        [189, 193, 194],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [165, 162, 155],\n",
      "        ...,\n",
      "        [190, 194, 195],\n",
      "        [189, 193, 194],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (132, 122)\n",
      "path: 'image16.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [126, 197, 245],\n",
      "        ...,\n",
      "        [105, 186, 243],\n",
      "        [105, 186, 243],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [122, 164, 208],\n",
      "        ...,\n",
      "        [152, 209, 247],\n",
      "        [152, 209, 247],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [122, 164, 208],\n",
      "        ...,\n",
      "        [154, 211, 250],\n",
      "        [155, 212, 251],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (152, 163)\n",
      "path: 'image17.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 44,  73, 100],\n",
      "        ...,\n",
      "        [ 69,  65,  46],\n",
      "        [ 69,  65,  46],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 62,  94,  49],\n",
      "        ...,\n",
      "        [ 75,  87,  72],\n",
      "        [ 75,  87,  72],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 63,  94,  52],\n",
      "        ...,\n",
      "        [ 76,  89,  70],\n",
      "        [ 76,  89,  70],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (238, 255)\n",
      "path: 'image18.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [197, 207, 186],\n",
      "        ...,\n",
      "        [ 84,  86,  83],\n",
      "        [ 77,  79,  76],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [101, 171, 226],\n",
      "        ...,\n",
      "        [ 88, 166, 232],\n",
      "        [ 88, 166, 232],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [100, 169, 225],\n",
      "        ...,\n",
      "        [ 89, 167, 233],\n",
      "        [ 89, 167, 233],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (158, 176)\n",
      "path: 'image19.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [188, 209, 178],\n",
      "        ...,\n",
      "        [192, 201, 180],\n",
      "        [193, 202, 181],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 79,  70,  53],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [145, 195, 243],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 77,  69,  52],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [145, 195, 243],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (190, 232)\n",
      "path: 'image20.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 65,  59,  42],\n",
      "        ...,\n",
      "        [111, 196, 250],\n",
      "        [116, 200, 247],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 59,  49,  34],\n",
      "        ...,\n",
      "        [ 40,  39,  16],\n",
      "        [ 39,  37,  17],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 59,  49,  34],\n",
      "        ...,\n",
      "        [ 40,  39,  16],\n",
      "        [ 40,  38,  18],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (181, 90)\n",
      "path: 'image21.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [107, 178, 231],\n",
      "        ...,\n",
      "        [189, 196, 189],\n",
      "        [190, 197, 190],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (178, 181)\n",
      "path: 'image22.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [103, 188, 244],\n",
      "        ...,\n",
      "        [ 95, 172, 229],\n",
      "        [ 95, 172, 229],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 96, 155, 224],\n",
      "        ...,\n",
      "        [ 74,  81,  60],\n",
      "        [ 74,  81,  60],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 97, 157, 225],\n",
      "        ...,\n",
      "        [ 74,  81,  60],\n",
      "        [ 74,  81,  60],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (147, 154)\n",
      "path: 'image23.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [192, 192, 186],\n",
      "        ...,\n",
      "        [112, 183, 237],\n",
      "        [112, 183, 237],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 97, 150, 209],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [ 48,  45,  22],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [101, 153, 212],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [ 48,  45,  22],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (167, 139)\n",
      "path: 'image24.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 97, 155, 218],\n",
      "        ...,\n",
      "        [147, 143, 137],\n",
      "        [147, 143, 137],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 90, 175, 239],\n",
      "        ...,\n",
      "        [ 32,  47,  76],\n",
      "        [ 32,  46,  73],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 90, 175, 239],\n",
      "        ...,\n",
      "        [ 28,  44,  73],\n",
      "        [ 30,  44,  70],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (164, 160)\n",
      "path: 'image25.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 69, 129, 196],\n",
      "        ...,\n",
      "        [ 83, 165, 230],\n",
      "        [ 83, 165, 230],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 83, 161, 226],\n",
      "        ...,\n",
      "        [ 91, 154, 218],\n",
      "        [ 93, 155, 219],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 87, 165, 230],\n",
      "        ...,\n",
      "        [ 89, 152, 216],\n",
      "        [ 91, 154, 218],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (170, 156)\n",
      "path: 'image26.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [160, 178, 112],\n",
      "        ...,\n",
      "        [115, 119,  98],\n",
      "        [115, 119,  98],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [100, 122, 150],\n",
      "        ...,\n",
      "        [124, 155, 101],\n",
      "        [129, 157, 102],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 98, 120, 148],\n",
      "        ...,\n",
      "        [126, 158, 103],\n",
      "        [132, 160, 105],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (184, 632)\n",
      "path: 'image27.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [252, 255, 252],\n",
      "        ...,\n",
      "        [151, 179, 110],\n",
      "        [148, 179, 110],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [255, 252, 254],\n",
      "        ...,\n",
      "        [ 83, 115, 154],\n",
      "        [ 83, 115, 164],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [255, 252, 254],\n",
      "        ...,\n",
      "        [ 82, 113, 153],\n",
      "        [ 82, 113, 162],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (269, 214)\n",
      "path: 'image28.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [102, 181, 236],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 98, 182, 243],\n",
      "        ...,\n",
      "        [132, 139, 125],\n",
      "        [132, 139, 124],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [100, 183, 244],\n",
      "        ...,\n",
      "        [132, 139, 125],\n",
      "        [131, 138, 123],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (168, 188)\n",
      "path: 'image29.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.7662583331693895, 'inference': 51.435387499805074, 'postprocess': 1.3283666664695677}]\n",
      "\n",
      "0: 320x320 1 potato, 54.2ms\n",
      "1: 320x320 2 potatos, 54.2ms\n",
      "2: 320x320 1 potato, 54.2ms\n",
      "3: 320x320 7 potatos, 54.2ms\n",
      "4: 320x320 2 potatos, 54.2ms\n",
      "5: 320x320 2 potatos, 54.2ms\n",
      "6: 320x320 3 potatos, 54.2ms\n",
      "7: 320x320 4 potatos, 54.2ms\n",
      "8: 320x320 7 potatos, 54.2ms\n",
      "9: 320x320 4 potatos, 54.2ms\n",
      "10: 320x320 5 potatos, 54.2ms\n",
      "11: 320x320 3 potatos, 54.2ms\n",
      "12: 320x320 5 potatos, 54.2ms\n",
      "13: 320x320 1 potato, 54.2ms\n",
      "14: 320x320 6 potatos, 54.2ms\n",
      "15: 320x320 6 potatos, 54.2ms\n",
      "16: 320x320 1 potato, 54.2ms\n",
      "17: 320x320 6 potatos, 54.2ms\n",
      "18: 320x320 1 potato, 54.2ms\n",
      "19: 320x320 3 potatos, 54.2ms\n",
      "20: 320x320 3 potatos, 54.2ms\n",
      "21: 320x320 2 potatos, 54.2ms\n",
      "22: 320x320 2 potatos, 54.2ms\n",
      "23: 320x320 4 potatos, 54.2ms\n",
      "24: 320x320 3 potatos, 54.2ms\n",
      "25: 320x320 6 potatos, 54.2ms\n",
      "26: 320x320 4 potatos, 54.2ms\n",
      "27: 320x320 2 potatos, 54.2ms\n",
      "28: 320x320 2 potatos, 54.2ms\n",
      "29: 320x320 9 potatos, 54.2ms\n",
      "Speed: 0.5ms preprocess, 54.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [105, 118, 100],\n",
      "        ...,\n",
      "        [110, 126,  98],\n",
      "        [110, 127,  97],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [144, 146, 125],\n",
      "        ...,\n",
      "        [151, 183, 136],\n",
      "        [157, 183, 143],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [148, 151, 130],\n",
      "        ...,\n",
      "        [148, 181, 133],\n",
      "        [155, 182, 141],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (200, 231)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 62,  93,  42],\n",
      "        ...,\n",
      "        [ 70,  83,  53],\n",
      "        [ 70,  83,  53],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 81,  83,  63],\n",
      "        ...,\n",
      "        [109, 143,  91],\n",
      "        [111, 145,  94],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 81,  83,  63],\n",
      "        ...,\n",
      "        [109, 143,  91],\n",
      "        [111, 145,  94],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (230, 223)\n",
      "path: 'image1.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [119, 137, 113],\n",
      "        ...,\n",
      "        [146, 153, 133],\n",
      "        [146, 153, 133],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [110, 117,  90],\n",
      "        ...,\n",
      "        [ 89, 104,  72],\n",
      "        [ 90, 105,  73],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [109, 115,  90],\n",
      "        ...,\n",
      "        [ 88, 105,  73],\n",
      "        [ 88, 105,  73],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (360, 372)\n",
      "path: 'image2.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 94, 153, 221],\n",
      "        ...,\n",
      "        [ 69, 120, 178],\n",
      "        [ 68, 119, 176],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 73, 103,  53],\n",
      "        ...,\n",
      "        [ 83, 115, 129],\n",
      "        [ 88, 119, 133],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 73, 103,  53],\n",
      "        ...,\n",
      "        [ 94, 125, 139],\n",
      "        [100, 131, 145],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (205, 201)\n",
      "path: 'image3.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 47,  98, 152],\n",
      "        ...,\n",
      "        [ 58, 132, 201],\n",
      "        [ 59, 133, 202],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [143, 146, 122],\n",
      "        ...,\n",
      "        [104, 124, 104],\n",
      "        [107, 126, 107],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [145, 148, 124],\n",
      "        ...,\n",
      "        [105, 125, 105],\n",
      "        [107, 126, 107],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (233, 261)\n",
      "path: 'image4.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 25,  46,  51],\n",
      "        ...,\n",
      "        [107, 167, 223],\n",
      "        [108, 168, 224],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [131, 129, 109],\n",
      "        ...,\n",
      "        [ 51,  54,  24],\n",
      "        [ 51,  54,  24],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [125, 126, 103],\n",
      "        ...,\n",
      "        [ 52,  55,  25],\n",
      "        [ 52,  55,  25],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (201, 199)\n",
      "path: 'image5.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [208, 215, 201],\n",
      "        ...,\n",
      "        [198, 196, 190],\n",
      "        [196, 196, 190],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [144, 133, 118],\n",
      "        ...,\n",
      "        [117, 169, 229],\n",
      "        [118, 168, 228],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [145, 134, 119],\n",
      "        ...,\n",
      "        [116, 168, 228],\n",
      "        [118, 168, 228],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (153, 155)\n",
      "path: 'image6.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [145, 211, 249],\n",
      "        ...,\n",
      "        [ 63, 136, 211],\n",
      "        [ 65, 137, 212],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 28,  26,   8],\n",
      "        ...,\n",
      "        [ 98, 168, 224],\n",
      "        [102, 172, 228],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 30,  27,   9],\n",
      "        ...,\n",
      "        [100, 169, 225],\n",
      "        [103, 173, 229],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (193, 172)\n",
      "path: 'image7.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [107, 155, 195],\n",
      "        ...,\n",
      "        [116, 196, 245],\n",
      "        [116, 192, 245],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 88, 152, 207],\n",
      "        ...,\n",
      "        [ 96, 115,  93],\n",
      "        [ 96, 115,  93],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 93, 153, 209],\n",
      "        ...,\n",
      "        [ 94, 115,  93],\n",
      "        [ 94, 115,  93],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (240, 231)\n",
      "path: 'image8.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [102, 167, 231],\n",
      "        ...,\n",
      "        [ 98, 164, 228],\n",
      "        [101, 166, 230],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [110, 181, 239],\n",
      "        ...,\n",
      "        [ 69,  84,  72],\n",
      "        [ 69,  84,  72],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [110, 181, 239],\n",
      "        ...,\n",
      "        [ 69,  84,  72],\n",
      "        [ 69,  84,  72],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (174, 176)\n",
      "path: 'image9.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [164, 183, 200],\n",
      "        [164, 183, 200],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [119, 178, 238],\n",
      "        ...,\n",
      "        [117, 171, 221],\n",
      "        [116, 169, 219],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [118, 173, 233],\n",
      "        ...,\n",
      "        [117, 171, 221],\n",
      "        [116, 169, 219],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (248, 194)\n",
      "path: 'image10.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 90, 159, 219],\n",
      "        ...,\n",
      "        [167, 167, 153],\n",
      "        [166, 166, 152],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 49,  47,  27],\n",
      "        ...,\n",
      "        [174, 167, 145],\n",
      "        [174, 166, 147],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 49,  46,  30],\n",
      "        ...,\n",
      "        [172, 167, 147],\n",
      "        [174, 166, 147],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (181, 168)\n",
      "path: 'image11.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [113, 189, 243],\n",
      "        ...,\n",
      "        [100, 161, 223],\n",
      "        [100, 162, 226],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [154, 188, 230],\n",
      "        ...,\n",
      "        [110, 192, 246],\n",
      "        [112, 192, 246],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [146, 185, 226],\n",
      "        ...,\n",
      "        [111, 190, 245],\n",
      "        [112, 189, 246],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (168, 162)\n",
      "path: 'image12.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [211, 218, 217],\n",
      "        ...,\n",
      "        [216, 219, 223],\n",
      "        [216, 219, 223],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [178, 175, 164],\n",
      "        ...,\n",
      "        [173, 165, 168],\n",
      "        [173, 165, 168],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [174, 172, 160],\n",
      "        ...,\n",
      "        [172, 164, 167],\n",
      "        [173, 165, 168],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (122, 103)\n",
      "path: 'image13.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 51, 115, 176],\n",
      "        ...,\n",
      "        [ 88, 154, 222],\n",
      "        [ 89, 155, 223],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [100, 175, 240],\n",
      "        ...,\n",
      "        [ 55, 110, 173],\n",
      "        [ 56, 109, 178],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 96, 172, 237],\n",
      "        ...,\n",
      "        [ 52, 107, 169],\n",
      "        [ 48, 101, 169],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (167, 172)\n",
      "path: 'image14.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 46,  93, 140],\n",
      "        ...,\n",
      "        [ 90, 159, 225],\n",
      "        [ 90, 159, 225],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 74, 150, 222],\n",
      "        ...,\n",
      "        [103,  97,  73],\n",
      "        [104,  98,  74],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 69, 145, 217],\n",
      "        ...,\n",
      "        [103,  97,  73],\n",
      "        [103,  97,  73],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (200, 209)\n",
      "path: 'image15.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [169, 188, 189],\n",
      "        ...,\n",
      "        [162, 176, 192],\n",
      "        [162, 176, 192],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [164, 161, 154],\n",
      "        ...,\n",
      "        [186, 192, 193],\n",
      "        [183, 189, 190],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [162, 160, 153],\n",
      "        ...,\n",
      "        [185, 190, 192],\n",
      "        [185, 190, 192],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (122, 112)\n",
      "path: 'image16.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [115, 198, 246],\n",
      "        ...,\n",
      "        [103, 189, 243],\n",
      "        [104, 190, 244],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [125, 169, 214],\n",
      "        ...,\n",
      "        [146, 195, 246],\n",
      "        [146, 195, 246],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [124, 168, 212],\n",
      "        ...,\n",
      "        [145, 194, 245],\n",
      "        [145, 194, 245],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (150, 163)\n",
      "path: 'image17.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 35,  38,  25],\n",
      "        ...,\n",
      "        [ 67,  60,  48],\n",
      "        [ 67,  60,  47],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 67, 102,  47],\n",
      "        ...,\n",
      "        [ 74,  89,  63],\n",
      "        [ 75,  90,  65],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 68, 103,  47],\n",
      "        ...,\n",
      "        [ 73,  91,  65],\n",
      "        [ 74,  91,  68],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (253, 270)\n",
      "path: 'image18.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [198, 208, 187],\n",
      "        ...,\n",
      "        [ 65,  73,  89],\n",
      "        [ 53,  72,  91],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 90, 148, 211],\n",
      "        ...,\n",
      "        [ 86, 168, 229],\n",
      "        [ 88, 171, 231],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 89, 150, 214],\n",
      "        ...,\n",
      "        [ 88, 167, 229],\n",
      "        [ 89, 167, 232],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (154, 172)\n",
      "path: 'image19.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [188, 209, 178],\n",
      "        ...,\n",
      "        [195, 203, 185],\n",
      "        [195, 204, 183],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 62,  52,  40],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 62,  53,  38],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (184, 225)\n",
      "path: 'image20.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 61,  51,  39],\n",
      "        ...,\n",
      "        [ 84, 172, 238],\n",
      "        [ 87, 174, 240],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   2,   1],\n",
      "        ...,\n",
      "        [ 49,  49,  30],\n",
      "        [ 49,  49,  30],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   1,   0],\n",
      "        ...,\n",
      "        [ 51,  51,  31],\n",
      "        [ 51,  51,  31],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (195, 97)\n",
      "path: 'image21.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [200, 203, 193],\n",
      "        [201, 204, 194],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 47,  45,  26],\n",
      "        ...,\n",
      "        [107, 180, 233],\n",
      "        [104, 180, 233],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 47,  45,  26],\n",
      "        ...,\n",
      "        [104, 180, 233],\n",
      "        [102, 181, 233],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (174, 177)\n",
      "path: 'image22.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 91, 175, 243],\n",
      "        ...,\n",
      "        [ 91, 168, 228],\n",
      "        [ 91, 168, 228],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [102, 159, 224],\n",
      "        ...,\n",
      "        [ 59,  75,  55],\n",
      "        [ 58,  74,  54],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 98, 159, 223],\n",
      "        ...,\n",
      "        [ 58,  75,  55],\n",
      "        [ 58,  75,  55],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (146, 153)\n",
      "path: 'image23.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [197, 196, 194],\n",
      "        ...,\n",
      "        [109, 180, 233],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 93, 147, 201],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 90, 145, 198],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (160, 134)\n",
      "path: 'image24.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 81, 143, 210],\n",
      "        ...,\n",
      "        [159, 148, 147],\n",
      "        [162, 152, 151],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 86, 171, 236],\n",
      "        ...,\n",
      "        [ 42,  58,  61],\n",
      "        [ 44,  59,  62],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 88, 171, 236],\n",
      "        ...,\n",
      "        [ 44,  55,  60],\n",
      "        [ 45,  55,  62],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (167, 162)\n",
      "path: 'image25.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 73, 146, 215],\n",
      "        ...,\n",
      "        [101, 181, 240],\n",
      "        [ 98, 178, 239],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 76, 154, 221],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [ 94, 153, 221],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 77, 155, 222],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [ 90, 150, 217],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (176, 160)\n",
      "path: 'image26.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [145, 179, 118],\n",
      "        ...,\n",
      "        [111, 124,  91],\n",
      "        [111, 124,  91],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 69, 140, 208],\n",
      "        ...,\n",
      "        [122, 140, 113],\n",
      "        [122, 140, 113],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 69, 140, 208],\n",
      "        ...,\n",
      "        [122, 140, 113],\n",
      "        [123, 141, 115],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (241, 823)\n",
      "path: 'image27.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [124, 137,  93],\n",
      "        ...,\n",
      "        [146, 179, 111],\n",
      "        [146, 179, 111],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 55, 118, 189],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 54, 117, 188],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (334, 268)\n",
      "path: 'image28.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [138, 217, 252],\n",
      "        ...,\n",
      "        [ 65,  81,  72],\n",
      "        [ 65,  81,  72],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 72, 147, 219],\n",
      "        ...,\n",
      "        [137, 141, 127],\n",
      "        [139, 144, 130],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 68, 148, 216],\n",
      "        ...,\n",
      "        [136, 141, 124],\n",
      "        [137, 143, 125],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (175, 197)\n",
      "path: 'image29.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.5158846999014107, 'inference': 54.17262776657784, 'postprocess': 1.0104972330736928}]\n",
      "\n",
      "0: 320x320 1 potato, 53.1ms\n",
      "1: 320x320 1 potato, 53.1ms\n",
      "2: 320x320 1 potato, 53.1ms\n",
      "3: 320x320 5 potatos, 53.1ms\n",
      "4: 320x320 3 potatos, 53.1ms\n",
      "5: 320x320 2 potatos, 53.1ms\n",
      "6: 320x320 3 potatos, 53.1ms\n",
      "7: 320x320 5 potatos, 53.1ms\n",
      "8: 320x320 3 potatos, 53.1ms\n",
      "9: 320x320 4 potatos, 53.1ms\n",
      "10: 320x320 3 potatos, 53.1ms\n",
      "11: 320x320 1 potato, 53.1ms\n",
      "12: 320x320 5 potatos, 53.1ms\n",
      "13: 320x320 5 potatos, 53.1ms\n",
      "14: 320x320 1 potato, 53.1ms\n",
      "15: 320x320 7 potatos, 53.1ms\n",
      "16: 320x320 1 potato, 53.1ms\n",
      "17: 320x320 1 potato, 53.1ms\n",
      "18: 320x320 7 potatos, 53.1ms\n",
      "19: 320x320 3 potatos, 53.1ms\n",
      "20: 320x320 1 potato, 53.1ms\n",
      "21: 320x320 6 potatos, 53.1ms\n",
      "22: 320x320 5 potatos, 53.1ms\n",
      "23: 320x320 5 potatos, 53.1ms\n",
      "24: 320x320 2 potatos, 53.1ms\n",
      "25: 320x320 3 potatos, 53.1ms\n",
      "Speed: 0.6ms preprocess, 53.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 95, 109,  88],\n",
      "        ...,\n",
      "        [ 81, 103,  69],\n",
      "        [ 81, 104,  68],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [150, 152, 131],\n",
      "        ...,\n",
      "        [148, 175, 129],\n",
      "        [153, 179, 136],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [151, 153, 132],\n",
      "        ...,\n",
      "        [144, 173, 126],\n",
      "        [150, 179, 132],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (197, 228)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 74, 115,  62],\n",
      "        ...,\n",
      "        [ 89, 113,  82],\n",
      "        [ 89, 113,  80],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 83,  90,  69],\n",
      "        ...,\n",
      "        [115, 144,  96],\n",
      "        [116, 145,  97],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 84,  91,  70],\n",
      "        ...,\n",
      "        [115, 144,  96],\n",
      "        [116, 145,  97],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (227, 221)\n",
      "path: 'image1.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [124, 138, 116],\n",
      "        ...,\n",
      "        [157, 162, 145],\n",
      "        [155, 161, 144],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [113, 115,  87],\n",
      "        ...,\n",
      "        [ 86, 103,  73],\n",
      "        [ 86, 103,  73],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [111, 115,  84],\n",
      "        ...,\n",
      "        [ 86, 103,  73],\n",
      "        [ 86, 103,  73],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (345, 357)\n",
      "path: 'image2.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 72, 103, 160],\n",
      "        ...,\n",
      "        [107, 158, 210],\n",
      "        [107, 158, 210],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 72,  98,  52],\n",
      "        ...,\n",
      "        [120, 157, 180],\n",
      "        [123, 155, 188],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 74, 101,  54],\n",
      "        ...,\n",
      "        [124, 160, 183],\n",
      "        [126, 159, 192],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (204, 199)\n",
      "path: 'image3.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 66, 123, 188],\n",
      "        ...,\n",
      "        [ 56, 136, 208],\n",
      "        [ 56, 136, 208],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [140, 145, 118],\n",
      "        ...,\n",
      "        [111, 129, 109],\n",
      "        [112, 130, 110],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [144, 148, 122],\n",
      "        ...,\n",
      "        [112, 130, 110],\n",
      "        [113, 131, 111],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (236, 263)\n",
      "path: 'image4.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 63, 123, 192],\n",
      "        ...,\n",
      "        [ 69, 122, 181],\n",
      "        [ 72, 124, 183],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 86,  87,  63],\n",
      "        ...,\n",
      "        [ 61,  60,  37],\n",
      "        [ 61,  60,  37],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 86,  87,  63],\n",
      "        ...,\n",
      "        [ 61,  60,  37],\n",
      "        [ 61,  60,  37],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (193, 192)\n",
      "path: 'image5.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [205, 212, 198],\n",
      "        ...,\n",
      "        [193, 193, 193],\n",
      "        [194, 195, 193],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [131, 157, 164],\n",
      "        ...,\n",
      "        [104, 159, 212],\n",
      "        [105, 160, 214],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [131, 160, 175],\n",
      "        ...,\n",
      "        [ 97, 152, 205],\n",
      "        [ 97, 152, 205],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (156, 157)\n",
      "path: 'image6.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [153, 222, 251],\n",
      "        ...,\n",
      "        [ 73, 150, 228],\n",
      "        [ 73, 150, 228],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 35,  33,  15],\n",
      "        ...,\n",
      "        [117, 194, 243],\n",
      "        [122, 198, 247],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 37,  34,  16],\n",
      "        ...,\n",
      "        [119, 196, 245],\n",
      "        [124, 201, 250],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (199, 177)\n",
      "path: 'image7.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 90, 122, 161],\n",
      "        ...,\n",
      "        [112, 188, 242],\n",
      "        [112, 188, 242],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [115, 182, 233],\n",
      "        ...,\n",
      "        [ 95, 116,  93],\n",
      "        [ 95, 116,  93],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [109, 176, 228],\n",
      "        ...,\n",
      "        [ 95, 116,  93],\n",
      "        [ 95, 116,  93],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (242, 233)\n",
      "path: 'image8.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [107, 175, 236],\n",
      "        ...,\n",
      "        [103, 172, 238],\n",
      "        [104, 173, 239],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [101, 169, 230],\n",
      "        ...,\n",
      "        [ 51,  68,  55],\n",
      "        [ 51,  68,  55],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [101, 167, 229],\n",
      "        ...,\n",
      "        [ 48,  70,  53],\n",
      "        [ 48,  70,  53],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (168, 170)\n",
      "path: 'image9.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [195, 207, 185],\n",
      "        ...,\n",
      "        [153, 178, 200],\n",
      "        [161, 179, 201],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [103, 172, 232],\n",
      "        ...,\n",
      "        [112, 168, 218],\n",
      "        [112, 169, 216],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [103, 172, 232],\n",
      "        ...,\n",
      "        [112, 168, 218],\n",
      "        [112, 169, 216],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (238, 185)\n",
      "path: 'image10.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [209, 221, 218],\n",
      "        ...,\n",
      "        [214, 219, 223],\n",
      "        [212, 218, 222],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [174, 172, 160],\n",
      "        ...,\n",
      "        [178, 168, 169],\n",
      "        [178, 168, 169],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [173, 171, 159],\n",
      "        ...,\n",
      "        [176, 167, 168],\n",
      "        [176, 167, 168],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (125, 105)\n",
      "path: 'image11.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 44, 108, 176],\n",
      "        ...,\n",
      "        [ 75, 141, 209],\n",
      "        [ 73, 139, 207],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 84, 159, 228],\n",
      "        ...,\n",
      "        [ 58,  97, 150],\n",
      "        [ 58,  96, 151],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 84, 158, 230],\n",
      "        ...,\n",
      "        [ 55,  94, 148],\n",
      "        [ 53,  94, 148],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (179, 184)\n",
      "path: 'image12.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [ 94, 165, 225],\n",
      "        [ 96, 167, 228],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 95, 166, 226],\n",
      "        ...,\n",
      "        [ 89,  81,  62],\n",
      "        [ 89,  81,  62],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 94, 165, 225],\n",
      "        ...,\n",
      "        [ 89,  81,  62],\n",
      "        [ 89,  81,  62],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (191, 199)\n",
      "path: 'image13.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [176, 190, 196],\n",
      "        ...,\n",
      "        [171, 181, 198],\n",
      "        [171, 181, 198],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [157, 158, 147],\n",
      "        ...,\n",
      "        [174, 183, 183],\n",
      "        [174, 183, 186],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [154, 158, 147],\n",
      "        ...,\n",
      "        [174, 183, 183],\n",
      "        [174, 183, 183],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (126, 116)\n",
      "path: 'image14.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 74, 132, 195],\n",
      "        ...,\n",
      "        [ 88, 173, 238],\n",
      "        [ 89, 174, 239],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 86, 130, 174],\n",
      "        ...,\n",
      "        [ 90, 140, 197],\n",
      "        [ 90, 140, 197],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 81, 124, 166],\n",
      "        ...,\n",
      "        [ 89, 140, 197],\n",
      "        [ 89, 140, 197],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (157, 169)\n",
      "path: 'image15.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [152, 162, 118],\n",
      "        ...,\n",
      "        [ 49,  45,  26],\n",
      "        [ 49,  45,  26],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 49,  70,  28],\n",
      "        ...,\n",
      "        [ 52,  65,  27],\n",
      "        [ 51,  62,  28],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 51,  72,  30],\n",
      "        ...,\n",
      "        [ 54,  67,  30],\n",
      "        [ 53,  65,  31],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (233, 249)\n",
      "path: 'image16.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [195, 202, 182],\n",
      "        ...,\n",
      "        [ 46,  68,  84],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 98, 167, 233],\n",
      "        ...,\n",
      "        [ 82, 165, 230],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 96, 165, 231],\n",
      "        ...,\n",
      "        [ 81, 164, 229],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (149, 166)\n",
      "path: 'image17.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [185, 207, 180],\n",
      "        ...,\n",
      "        [197, 210, 185],\n",
      "        [196, 209, 183],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 91, 158, 219],\n",
      "        ...,\n",
      "        [119, 189, 245],\n",
      "        [120, 190, 246],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 93, 160, 223],\n",
      "        ...,\n",
      "        [119, 190, 244],\n",
      "        [120, 192, 245],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (194, 238)\n",
      "path: 'image18.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 63,  54,  48],\n",
      "        ...,\n",
      "        [ 49, 104, 173],\n",
      "        [ 56, 111, 180],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 22,  25,   1],\n",
      "        ...,\n",
      "        [ 48,  51,  31],\n",
      "        [ 48,  51,  31],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 25,  28,   4],\n",
      "        ...,\n",
      "        [ 51,  53,  33],\n",
      "        [ 51,  53,  33],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (210, 107)\n",
      "path: 'image19.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [187, 192, 185],\n",
      "        [187, 192, 185],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [112, 173, 224],\n",
      "        [113, 175, 224],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 61,  56,  37],\n",
      "        ...,\n",
      "        [111, 172, 223],\n",
      "        [111, 172, 223],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (167, 170)\n",
      "path: 'image20.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 79, 160, 228],\n",
      "        ...,\n",
      "        [ 90, 167, 226],\n",
      "        [ 89, 165, 226],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 81, 125, 190],\n",
      "        ...,\n",
      "        [ 97, 141, 200],\n",
      "        [ 90, 134, 189],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 76, 120, 186],\n",
      "        ...,\n",
      "        [ 87, 131, 189],\n",
      "        [ 86, 130, 185],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (149, 155)\n",
      "path: 'image21.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [197, 196, 194],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 98, 143, 201],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [102, 148, 207],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (158, 132)\n",
      "path: 'image22.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 81, 157, 229],\n",
      "        ...,\n",
      "        [ 94, 175, 239],\n",
      "        [ 93, 174, 238],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 55, 137, 201],\n",
      "        ...,\n",
      "        [ 84, 136, 197],\n",
      "        [ 89, 140, 202],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 59, 140, 204],\n",
      "        ...,\n",
      "        [ 84, 136, 200],\n",
      "        [ 86, 137, 201],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (178, 165)\n",
      "path: 'image23.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [108, 165, 221],\n",
      "        ...,\n",
      "        [110, 131,  97],\n",
      "        [110, 131,  97],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 54, 113, 181],\n",
      "        ...,\n",
      "        [107, 112,  88],\n",
      "        [108, 113,  89],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 54, 113, 181],\n",
      "        ...,\n",
      "        [107, 112,  88],\n",
      "        [108, 113,  89],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (288, 976)\n",
      "path: 'image24.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [131, 138, 111],\n",
      "        ...,\n",
      "        [151, 179, 117],\n",
      "        [151, 179, 117],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 41,  82, 124],\n",
      "        ...,\n",
      "        [ 35,  40,  20],\n",
      "        [ 40,  40,  22],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 41,  82, 124],\n",
      "        ...,\n",
      "        [ 35,  40,  20],\n",
      "        [ 39,  39,  20],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (386, 310)\n",
      "path: 'image25.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.583966346032237, 'inference': 53.09551123075205, 'postprocess': 1.0108878078216759}]\n",
      "\n",
      "0: 320x320 1 potato, 52.6ms\n",
      "1: 320x320 1 potato, 52.6ms\n",
      "2: 320x320 1 potato, 52.6ms\n",
      "3: 320x320 5 potatos, 52.6ms\n",
      "4: 320x320 4 potatos, 52.6ms\n",
      "5: 320x320 2 potatos, 52.6ms\n",
      "6: 320x320 3 potatos, 52.6ms\n",
      "7: 320x320 7 potatos, 52.6ms\n",
      "8: 320x320 6 potatos, 52.6ms\n",
      "9: 320x320 4 potatos, 52.6ms\n",
      "10: 320x320 3 potatos, 52.6ms\n",
      "11: 320x320 1 potato, 52.6ms\n",
      "12: 320x320 6 potatos, 52.6ms\n",
      "13: 320x320 5 potatos, 52.6ms\n",
      "14: 320x320 1 potato, 52.6ms\n",
      "15: 320x320 8 potatos, 52.6ms\n",
      "16: 320x320 1 potato, 52.6ms\n",
      "17: 320x320 2 potatos, 52.6ms\n",
      "18: 320x320 5 potatos, 52.6ms\n",
      "19: 320x320 2 potatos, 52.6ms\n",
      "20: 320x320 2 potatos, 52.6ms\n",
      "21: 320x320 6 potatos, 52.6ms\n",
      "22: 320x320 3 potatos, 52.6ms\n",
      "23: 320x320 6 potatos, 52.6ms\n",
      "24: 320x320 2 potatos, 52.6ms\n",
      "25: 320x320 3 potatos, 52.6ms\n",
      "26: 320x320 1 potato, 52.6ms\n",
      "27: 320x320 4 potatos, 52.6ms\n",
      "Speed: 0.4ms preprocess, 52.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 320)\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 93, 107,  86],\n",
      "        ...,\n",
      "        [ 72,  87,  48],\n",
      "        [ 72,  87,  48],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [140, 144, 119],\n",
      "        ...,\n",
      "        [120, 153, 105],\n",
      "        [123, 155, 108],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [144, 147, 123],\n",
      "        ...,\n",
      "        [119, 152, 104],\n",
      "        [120, 153, 105],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (192, 223)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 93, 131,  86],\n",
      "        ...,\n",
      "        [ 91, 119,  87],\n",
      "        [ 91, 119,  87],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 80,  86,  61],\n",
      "        ...,\n",
      "        [130, 152, 116],\n",
      "        [132, 154, 118],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 80,  86,  61],\n",
      "        ...,\n",
      "        [132, 154, 118],\n",
      "        [136, 158, 122],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (224, 218)\n",
      "path: 'image1.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [125, 144, 117],\n",
      "        ...,\n",
      "        [146, 159, 140],\n",
      "        [146, 159, 140],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [113, 113,  88],\n",
      "        ...,\n",
      "        [ 94, 108,  80],\n",
      "        [ 95, 109,  81],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [112, 112,  87],\n",
      "        ...,\n",
      "        [ 94, 108,  80],\n",
      "        [ 95, 109,  81],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (335, 347)\n",
      "path: 'image2.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 58,  93, 152],\n",
      "        ...,\n",
      "        [111, 159, 207],\n",
      "        [111, 159, 207],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 76,  94,  55],\n",
      "        ...,\n",
      "        [122, 155, 188],\n",
      "        [123, 154, 194],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 79,  96,  58],\n",
      "        ...,\n",
      "        [122, 155, 188],\n",
      "        [122, 153, 193],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (205, 200)\n",
      "path: 'image3.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 65, 126, 195],\n",
      "        ...,\n",
      "        [ 56, 134, 209],\n",
      "        [ 56, 134, 209],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [134, 141, 115],\n",
      "        ...,\n",
      "        [112, 131, 109],\n",
      "        [112, 131, 109],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [134, 141, 115],\n",
      "        ...,\n",
      "        [112, 131, 109],\n",
      "        [112, 131, 109],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (237, 263)\n",
      "path: 'image4.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 74, 138, 205],\n",
      "        ...,\n",
      "        [ 87, 134, 196],\n",
      "        [ 83, 131, 193],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 75,  73,  53],\n",
      "        ...,\n",
      "        [ 68,  68,  42],\n",
      "        [ 68,  68,  42],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 73,  73,  53],\n",
      "        ...,\n",
      "        [ 68,  67,  44],\n",
      "        [ 68,  67,  44],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (189, 188)\n",
      "path: 'image5.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [207, 212, 201],\n",
      "        ...,\n",
      "        [193, 193, 193],\n",
      "        [193, 194, 192],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [144, 141, 130],\n",
      "        ...,\n",
      "        [101, 153, 207],\n",
      "        [101, 153, 207],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [145, 143, 131],\n",
      "        ...,\n",
      "        [101, 153, 207],\n",
      "        [101, 153, 207],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (155, 156)\n",
      "path: 'image6.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [162, 228, 251],\n",
      "        ...,\n",
      "        [ 98, 181, 245],\n",
      "        [ 98, 182, 243],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 27,  25,   5],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 28,  26,   8],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (196, 174)\n",
      "path: 'image7.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [101, 153, 207],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [116, 182, 237],\n",
      "        ...,\n",
      "        [110, 127, 104],\n",
      "        [110, 127, 104],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [111, 178, 232],\n",
      "        ...,\n",
      "        [110, 127, 104],\n",
      "        [111, 129, 105],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (274, 263)\n",
      "path: 'image8.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 88, 159, 226],\n",
      "        ...,\n",
      "        [ 96, 166, 229],\n",
      "        [ 95, 167, 230],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (165, 168)\n",
      "path: 'image9.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [195, 208, 182],\n",
      "        ...,\n",
      "        [183, 190, 182],\n",
      "        [186, 192, 180],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [108, 178, 229],\n",
      "        ...,\n",
      "        [ 90, 103, 139],\n",
      "        [ 88, 103, 139],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [107, 176, 228],\n",
      "        ...,\n",
      "        [ 84,  97, 133],\n",
      "        [ 83,  98, 134],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (236, 184)\n",
      "path: 'image10.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [208, 219, 217],\n",
      "        ...,\n",
      "        [215, 225, 228],\n",
      "        [214, 224, 226],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [182, 179, 169],\n",
      "        ...,\n",
      "        [175, 168, 169],\n",
      "        [175, 168, 169],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [179, 175, 166],\n",
      "        ...,\n",
      "        [175, 168, 169],\n",
      "        [175, 168, 169],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (125, 107)\n",
      "path: 'image11.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [ 66, 131, 201],\n",
      "        [ 66, 131, 201],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 63, 137, 205],\n",
      "        ...,\n",
      "        [ 47,  93, 146],\n",
      "        [ 46,  90, 144],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 65, 138, 207],\n",
      "        ...,\n",
      "        [ 47,  94, 145],\n",
      "        [ 45,  90, 144],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (187, 192)\n",
      "path: 'image12.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 82, 145, 216],\n",
      "        ...,\n",
      "        [ 88,  80,  61],\n",
      "        [ 87,  79,  60],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 83, 146, 217],\n",
      "        ...,\n",
      "        [ 88,  80,  61],\n",
      "        [ 87,  79,  60],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (187, 194)\n",
      "path: 'image13.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [180, 190, 197],\n",
      "        ...,\n",
      "        [171, 182, 197],\n",
      "        [168, 183, 194],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [169, 174, 161],\n",
      "        ...,\n",
      "        [196, 193, 197],\n",
      "        [196, 193, 195],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [168, 175, 161],\n",
      "        ...,\n",
      "        [200, 194, 196],\n",
      "        [195, 193, 193],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (128, 119)\n",
      "path: 'image14.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [100, 168, 229],\n",
      "        ...,\n",
      "        [ 82, 160, 226],\n",
      "        [ 87, 165, 231],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [118, 168, 209],\n",
      "        ...,\n",
      "        [ 90, 150, 208],\n",
      "        [ 96, 153, 209],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [118, 168, 209],\n",
      "        ...,\n",
      "        [ 91, 151, 209],\n",
      "        [ 97, 154, 210],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (156, 167)\n",
      "path: 'image15.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 55,  77,  98],\n",
      "        ...,\n",
      "        [ 89, 172, 237],\n",
      "        [ 84, 173, 237],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 63,  90,  42],\n",
      "        ...,\n",
      "        [143, 143, 110],\n",
      "        [139, 141, 109],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 65,  91,  44],\n",
      "        ...,\n",
      "        [141, 141, 109],\n",
      "        [141, 141, 109],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (176, 191)\n",
      "path: 'image16.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [197, 202, 182],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [104, 172, 235],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [100, 168, 235],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (143, 159)\n",
      "path: 'image17.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [192, 208, 180],\n",
      "        ...,\n",
      "        [195, 208, 182],\n",
      "        [195, 208, 182],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [110, 165, 218],\n",
      "        ...,\n",
      "        [133, 190, 246],\n",
      "        [131, 188, 244],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [105, 162, 218],\n",
      "        ...,\n",
      "        [132, 194, 246],\n",
      "        [130, 192, 244],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (188, 231)\n",
      "path: 'image18.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [179, 181, 155],\n",
      "        ...,\n",
      "        [ 63, 107, 155],\n",
      "        [ 65, 105, 160],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 48,  49,  26],\n",
      "        ...,\n",
      "        [ 40,  41,  24],\n",
      "        [ 40,  41,  24],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 51,  54,  30],\n",
      "        ...,\n",
      "        [ 42,  41,  25],\n",
      "        [ 42,  45,  25],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (212, 112)\n",
      "path: 'image19.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [109, 178, 236],\n",
      "        ...,\n",
      "        [182, 189, 182],\n",
      "        [183, 190, 183],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [127, 180, 233],\n",
      "        [127, 180, 233],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 62,  61,  38],\n",
      "        ...,\n",
      "        [127, 180, 233],\n",
      "        [127, 180, 233],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (156, 160)\n",
      "path: 'image20.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 79, 161, 232],\n",
      "        ...,\n",
      "        [ 77, 145, 208],\n",
      "        [ 74, 143, 209],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [101, 158, 223],\n",
      "        ...,\n",
      "        [105, 151, 205],\n",
      "        [104, 155, 209],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 93, 150, 215],\n",
      "        ...,\n",
      "        [101, 146, 201],\n",
      "        [101, 152, 205],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (152, 159)\n",
      "path: 'image21.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [198, 197, 195],\n",
      "        ...,\n",
      "        [112, 183, 242],\n",
      "        [112, 183, 242],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 82, 132, 189],\n",
      "        ...,\n",
      "        [ 70,  69,  41],\n",
      "        [ 69,  68,  40],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [ 69,  68,  40],\n",
      "        [ 69,  68,  40],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (155, 130)\n",
      "path: 'image22.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 79, 151, 223],\n",
      "        ...,\n",
      "        [ 79, 159, 226],\n",
      "        [ 77, 158, 225],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 89, 174, 239],\n",
      "        ...,\n",
      "        [ 95, 141, 200],\n",
      "        [ 96, 143, 201],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 90, 175, 240],\n",
      "        ...,\n",
      "        [100, 146, 204],\n",
      "        [100, 146, 204],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (178, 163)\n",
      "path: 'image23.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [116, 157, 211],\n",
      "        ...,\n",
      "        [113, 159,  94],\n",
      "        [113, 159,  94],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [124, 127, 103],\n",
      "        [124, 127, 103],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [125, 129, 104],\n",
      "        [125, 129, 104],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (356, 1184)\n",
      "path: 'image24.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [139, 172,  95],\n",
      "        ...,\n",
      "        [140, 175, 110],\n",
      "        [140, 175, 110],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [120, 146, 185],\n",
      "        ...,\n",
      "        [ 44,  40,  17],\n",
      "        [ 44,  40,  17],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [120, 148, 187],\n",
      "        ...,\n",
      "        [ 44,  40,  17],\n",
      "        [ 45,  41,  18],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (450, 366)\n",
      "path: 'image25.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [169, 185, 195],\n",
      "        ...,\n",
      "        [155, 179, 179],\n",
      "        [155, 179, 179],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [183, 175, 166],\n",
      "        ...,\n",
      "        [  6,   0,   0],\n",
      "        [  6,   0,   0],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [185, 176, 167],\n",
      "        ...,\n",
      "        [  6,   0,   0],\n",
      "        [  8,   0,   0],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (201, 195)\n",
      "path: 'image26.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [116, 193, 243],\n",
      "        ...,\n",
      "        [ 86, 155, 218],\n",
      "        [ 87, 157, 219],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [134, 172, 210],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [ 84, 153, 211],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [134, 173, 215],\n",
      "        ...,\n",
      "        [ 83, 153, 209],\n",
      "        [ 84, 154, 210],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (166, 160)\n",
      "path: 'image27.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.43266217887451475, 'inference': 52.550005964544006, 'postprocess': 1.0674211428392613}]\n",
      "\n",
      "0: 320x320 1 potato, 50.3ms\n",
      "1: 320x320 1 potato, 50.3ms\n",
      "2: 320x320 1 potato, 50.3ms\n",
      "3: 320x320 4 potatos, 50.3ms\n",
      "4: 320x320 5 potatos, 50.3ms\n",
      "5: 320x320 2 potatos, 50.3ms\n",
      "6: 320x320 3 potatos, 50.3ms\n",
      "7: 320x320 10 potatos, 50.3ms\n",
      "8: 320x320 7 potatos, 50.3ms\n",
      "9: 320x320 5 potatos, 50.3ms\n",
      "10: 320x320 5 potatos, 50.3ms\n",
      "11: 320x320 1 potato, 50.3ms\n",
      "12: 320x320 9 potatos, 50.3ms\n",
      "13: 320x320 5 potatos, 50.3ms\n",
      "14: 320x320 1 potato, 50.3ms\n",
      "15: 320x320 6 potatos, 50.3ms\n",
      "16: 320x320 1 potato, 50.3ms\n",
      "17: 320x320 3 potatos, 50.3ms\n",
      "18: 320x320 5 potatos, 50.3ms\n",
      "19: 320x320 2 potatos, 50.3ms\n",
      "20: 320x320 2 potatos, 50.3ms\n",
      "21: 320x320 4 potatos, 50.3ms\n",
      "22: 320x320 2 potatos, 50.3ms\n",
      "23: 320x320 5 potatos, 50.3ms\n",
      "24: 320x320 2 potatos, 50.3ms\n",
      "25: 320x320 3 potatos, 50.3ms\n",
      "26: 320x320 3 potatos, 50.3ms\n",
      "27: 320x320 3 potatos, 50.3ms\n",
      "28: 320x320 5 potatos, 50.3ms\n",
      "Speed: 0.4ms preprocess, 50.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 320)\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 90,  97,  82],\n",
      "        ...,\n",
      "        [ 44,  47,  19],\n",
      "        [ 44,  47,  19],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [122, 122, 102],\n",
      "        ...,\n",
      "        [101, 136,  88],\n",
      "        [102, 137,  89],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [127, 127, 108],\n",
      "        ...,\n",
      "        [102, 137,  89],\n",
      "        [103, 138,  90],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (190, 220)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [100, 146, 103],\n",
      "        ...,\n",
      "        [ 96, 122,  86],\n",
      "        [ 95, 120,  84],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 79,  81,  60],\n",
      "        ...,\n",
      "        [145, 154, 139],\n",
      "        [145, 154, 139],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 80,  82,  61],\n",
      "        ...,\n",
      "        [143, 153, 134],\n",
      "        [141, 152, 133],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (216, 209)\n",
      "path: 'image1.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [124, 141, 111],\n",
      "        ...,\n",
      "        [165, 185, 158],\n",
      "        [164, 183, 157],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [107, 105,  82],\n",
      "        ...,\n",
      "        [109, 115,  90],\n",
      "        [111, 117,  93],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [105, 104,  81],\n",
      "        ...,\n",
      "        [109, 115,  90],\n",
      "        [110, 116,  91],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (326, 338)\n",
      "path: 'image2.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 65, 113, 175],\n",
      "        ...,\n",
      "        [113, 159, 210],\n",
      "        [115, 161, 209],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 77,  93,  60],\n",
      "        ...,\n",
      "        [102, 146, 200],\n",
      "        [103, 147, 202],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 80,  95,  62],\n",
      "        ...,\n",
      "        [100, 145, 200],\n",
      "        [ 96, 143, 201],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (212, 205)\n",
      "path: 'image3.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 72, 145, 214],\n",
      "        ...,\n",
      "        [ 56, 136, 210],\n",
      "        [ 56, 136, 210],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [131, 136, 115],\n",
      "        ...,\n",
      "        [110, 129, 107],\n",
      "        [110, 129, 107],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [131, 136, 115],\n",
      "        ...,\n",
      "        [110, 129, 107],\n",
      "        [110, 129, 107],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (234, 257)\n",
      "path: 'image4.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 86, 157, 217],\n",
      "        ...,\n",
      "        [ 83, 136, 195],\n",
      "        [ 84, 137, 196],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 80,  79,  55],\n",
      "        ...,\n",
      "        [ 70,  69,  46],\n",
      "        [ 70,  69,  46],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 79,  77,  54],\n",
      "        ...,\n",
      "        [ 70,  69,  46],\n",
      "        [ 70,  69,  46],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (189, 188)\n",
      "path: 'image5.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [208, 214, 202],\n",
      "        ...,\n",
      "        [190, 194, 190],\n",
      "        [192, 194, 188],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [145, 133, 122],\n",
      "        ...,\n",
      "        [ 90, 137, 188],\n",
      "        [ 80, 129, 180],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [146, 134, 123],\n",
      "        ...,\n",
      "        [ 94, 140, 192],\n",
      "        [ 87, 137, 185],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (157, 157)\n",
      "path: 'image6.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [169, 232, 253],\n",
      "        ...,\n",
      "        [ 91, 167, 232],\n",
      "        [ 89, 166, 228],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 22,  19,   1],\n",
      "        ...,\n",
      "        [157, 222, 253],\n",
      "        [150, 215, 252],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 23,  20,   2],\n",
      "        ...,\n",
      "        [154, 219, 251],\n",
      "        [150, 215, 252],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (192, 171)\n",
      "path: 'image7.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 47, 102, 171],\n",
      "        ...,\n",
      "        [118, 173, 219],\n",
      "        [116, 166, 205],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [107, 173, 228],\n",
      "        ...,\n",
      "        [109, 126, 103],\n",
      "        [109, 126, 103],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [103, 172, 226],\n",
      "        ...,\n",
      "        [109, 126, 103],\n",
      "        [109, 126, 103],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (255, 246)\n",
      "path: 'image8.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 79, 159, 230],\n",
      "        ...,\n",
      "        [104, 172, 235],\n",
      "        [105, 173, 236],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [118, 169, 231],\n",
      "        ...,\n",
      "        [ 38,  70,  74],\n",
      "        [ 42,  73,  66],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [117, 168, 230],\n",
      "        ...,\n",
      "        [ 41,  75,  82],\n",
      "        [ 44,  75,  69],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (162, 164)\n",
      "path: 'image9.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [190, 204, 183],\n",
      "        ...,\n",
      "        [127, 188, 240],\n",
      "        [125, 186, 238],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [122, 182, 238],\n",
      "        ...,\n",
      "        [115, 172, 218],\n",
      "        [113, 171, 217],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [122, 182, 238],\n",
      "        ...,\n",
      "        [111, 168, 215],\n",
      "        [111, 168, 215],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (192, 151)\n",
      "path: 'image10.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [214, 217, 218],\n",
      "        ...,\n",
      "        [219, 230, 232],\n",
      "        [219, 230, 232],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [196, 187, 181],\n",
      "        ...,\n",
      "        [175, 167, 171],\n",
      "        [175, 167, 171],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [194, 188, 179],\n",
      "        ...,\n",
      "        [175, 168, 169],\n",
      "        [175, 168, 169],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (123, 105)\n",
      "path: 'image11.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 46, 109, 180],\n",
      "        ...,\n",
      "        [105, 167, 236],\n",
      "        [107, 168, 236],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 68, 143, 211],\n",
      "        ...,\n",
      "        [ 60,  87, 120],\n",
      "        [ 53,  87, 129],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 63, 138, 207],\n",
      "        ...,\n",
      "        [ 59,  86, 119],\n",
      "        [ 52,  86, 127],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (195, 199)\n",
      "path: 'image12.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 31,  47,  58],\n",
      "        ...,\n",
      "        [ 81, 151, 214],\n",
      "        [ 80, 150, 212],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [ 86,  82,  59],\n",
      "        [ 83,  83,  58],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [ 86,  82,  59],\n",
      "        [ 83,  83,  58],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (178, 186)\n",
      "path: 'image13.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [179, 187, 194],\n",
      "        ...,\n",
      "        [158, 181, 207],\n",
      "        [160, 179, 205],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [181, 181, 168],\n",
      "        ...,\n",
      "        [ 58,  68,  68],\n",
      "        [ 56,  66,  70],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [181, 181, 168],\n",
      "        ...,\n",
      "        [ 58,  68,  68],\n",
      "        [ 56,  66,  70],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (125, 117)\n",
      "path: 'image14.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 76, 147, 215],\n",
      "        ...,\n",
      "        [ 77, 152, 218],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 90, 140, 180],\n",
      "        ...,\n",
      "        [111, 181, 232],\n",
      "        [108, 178, 229],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [101, 151, 190],\n",
      "        ...,\n",
      "        [111, 181, 232],\n",
      "        [108, 178, 229],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (155, 167)\n",
      "path: 'image15.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [178, 193, 141],\n",
      "        ...,\n",
      "        [171, 183, 153],\n",
      "        [169, 182, 152],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 80, 104,  65],\n",
      "        ...,\n",
      "        [173, 174, 138],\n",
      "        [172, 173, 136],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 81, 105,  65],\n",
      "        ...,\n",
      "        [169, 171, 134],\n",
      "        [167, 168, 132],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (205, 222)\n",
      "path: 'image16.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [197, 203, 179],\n",
      "        ...,\n",
      "        [ 75,  70,  59],\n",
      "        [ 72,  67,  55],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 95, 171, 232],\n",
      "        ...,\n",
      "        [ 87, 161, 228],\n",
      "        [ 88, 162, 229],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 94, 169, 231],\n",
      "        ...,\n",
      "        [ 88, 159, 226],\n",
      "        [ 89, 160, 228],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (143, 160)\n",
      "path: 'image17.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [190, 207, 179],\n",
      "        ...,\n",
      "        [194, 205, 183],\n",
      "        [194, 205, 183],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [113, 173, 222],\n",
      "        ...,\n",
      "        [ 86, 136, 195],\n",
      "        [ 79, 132, 189],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [112, 172, 221],\n",
      "        ...,\n",
      "        [100, 150, 209],\n",
      "        [ 95, 148, 205],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (192, 235)\n",
      "path: 'image18.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [176, 180, 155],\n",
      "        ...,\n",
      "        [ 74, 112, 161],\n",
      "        [ 79, 117, 166],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 60,  68,  37],\n",
      "        ...,\n",
      "        [ 38,  38,  19],\n",
      "        [ 39,  39,  20],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 59,  70,  37],\n",
      "        ...,\n",
      "        [ 39,  41,  22],\n",
      "        [ 40,  42,  23],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (216, 117)\n",
      "path: 'image19.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [113, 178, 237],\n",
      "        ...,\n",
      "        [187, 194, 187],\n",
      "        [187, 194, 186],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 67,  67,  47],\n",
      "        ...,\n",
      "        [113, 164, 221],\n",
      "        [118, 168, 225],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 66,  66,  46],\n",
      "        ...,\n",
      "        [115, 165, 222],\n",
      "        [118, 168, 225],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (152, 156)\n",
      "path: 'image20.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 80, 152, 224],\n",
      "        ...,\n",
      "        [ 91, 159, 222],\n",
      "        [ 84, 152, 215],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 82, 138, 203],\n",
      "        ...,\n",
      "        [124, 172, 225],\n",
      "        [120, 172, 225],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 83, 139, 204],\n",
      "        ...,\n",
      "        [120, 172, 225],\n",
      "        [119, 171, 224],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (144, 150)\n",
      "path: 'image21.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [201, 205, 197],\n",
      "        ...,\n",
      "        [105, 150, 204],\n",
      "        [104, 148, 203],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 79, 130, 192],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 75, 126, 188],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (191, 159)\n",
      "path: 'image22.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 61, 125, 198],\n",
      "        ...,\n",
      "        [ 75, 151, 223],\n",
      "        [ 75, 147, 221],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [154, 212, 245],\n",
      "        ...,\n",
      "        [107, 151, 209],\n",
      "        [107, 153, 211],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [150, 209, 247],\n",
      "        ...,\n",
      "        [105, 150, 208],\n",
      "        [105, 152, 210],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (173, 159)\n",
      "path: 'image23.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [102, 139, 192],\n",
      "        ...,\n",
      "        [130, 171, 104],\n",
      "        [130, 171, 104],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [110, 181, 235],\n",
      "        ...,\n",
      "        [118, 127, 105],\n",
      "        [118, 127, 105],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [110, 181, 235],\n",
      "        ...,\n",
      "        [118, 127, 105],\n",
      "        [118, 127, 105],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (406, 1318)\n",
      "path: 'image24.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [130, 169, 101],\n",
      "        ...,\n",
      "        [132, 171, 104],\n",
      "        [132, 171, 104],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [112, 129, 148],\n",
      "        ...,\n",
      "        [ 42,  56,  62],\n",
      "        [ 44,  58,  63],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [115, 131, 151],\n",
      "        ...,\n",
      "        [ 49,  63,  69],\n",
      "        [ 52,  66,  72],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (455, 378)\n",
      "path: 'image25.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [195, 207, 185],\n",
      "        ...,\n",
      "        [192, 201, 180],\n",
      "        [194, 201, 181],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 67, 107, 159],\n",
      "        ...,\n",
      "        [ 86, 129, 187],\n",
      "        [ 95, 131, 193],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 65, 104, 157],\n",
      "        ...,\n",
      "        [ 83, 126, 185],\n",
      "        [ 94, 130, 192],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (123, 175)\n",
      "path: 'image26.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [117, 189, 245],\n",
      "        ...,\n",
      "        [125, 192, 253],\n",
      "        [123, 192, 250],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [150, 174, 215],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [133, 158, 198],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (151, 146)\n",
      "path: 'image27.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'potato'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [ 53,  62,  48],\n",
      "        [ 53,  62,  48],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 51, 115, 183],\n",
      "        ...,\n",
      "        [115, 115, 102],\n",
      "        [116, 116, 103],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [ 48, 112, 181],\n",
      "        ...,\n",
      "        [115, 115, 102],\n",
      "        [116, 116, 103],\n",
      "        [  0,   0, 255]],\n",
      "\n",
      "       [[  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        ...,\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255],\n",
      "        [  0,   0, 255]]], dtype=uint8)\n",
      "orig_shape: (173, 194)\n",
      "path: 'image28.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/kuanyshbakytuly/runs/segment/predict'\n",
      "speed: {'preprocess': 0.4357054482358668, 'inference': 50.340076137719485, 'postprocess': 1.292475586022443}]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     48\u001b[39m             cv2.putText(\n\u001b[32m     49\u001b[39m                 annotated_frame,\n\u001b[32m     50\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(track_id[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m                 \u001b[32m2\u001b[39m\n\u001b[32m     56\u001b[39m             )\n\u001b[32m     57\u001b[39m         potato_boxes.append(boxes)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m results_seg = \u001b[43mmodel_seg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpotato_boxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(results_seg)\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Display the resized, annotated frame\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m#cv2.imshow(\"YOLOv8 Tracking\", annotated_frame)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/ultralytics/engine/model.py:550\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, source, stream, predictor, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.predictor, \u001b[33m\"\u001b[39m\u001b[33mset_prompts\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[32m    549\u001b[39m     \u001b[38;5;28mself\u001b[39m.predictor.set_prompts(prompts)\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predictor.predict_cli(source=source) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/ultralytics/engine/predictor.py:214\u001b[39m, in \u001b[36mBasePredictor.__call__\u001b[39m\u001b[34m(self, source, model, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_inference(source, model, *args, **kwargs)\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:36\u001b[39m, in \u001b[36m_wrap_generator.<locals>.generator_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m         response = \u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     40\u001b[39m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/ultralytics/engine/predictor.py:323\u001b[39m, in \u001b[36mBasePredictor.stream_inference\u001b[39m\u001b[34m(self, source, model, *args, **kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[32m1\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     preds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.embed:\n\u001b[32m    325\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/ultralytics/engine/predictor.py:171\u001b[39m, in \u001b[36mBasePredictor.inference\u001b[39m\u001b[34m(self, im, *args, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[32m    166\u001b[39m visualize = (\n\u001b[32m    167\u001b[39m     increment_path(\u001b[38;5;28mself\u001b[39m.save_dir / Path(\u001b[38;5;28mself\u001b[39m.batch[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]).stem, mkdir=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.visualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.source_type.tensor)\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    170\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/ultralytics/nn/autobackend.py:571\u001b[39m, in \u001b[36mAutoBackend.forward\u001b[39m\u001b[34m(self, im, augment, visualize, embed, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nn_module:\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[43m=\u001b[49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m=\u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jit:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py:120\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loss(x, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py:138\u001b[39m, in \u001b[36mBaseModel.predict\u001b[39m\u001b[34m(self, x, profile, visualize, augment, embed)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._predict_augment(x)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py:159\u001b[39m, in \u001b[36mBaseModel._predict_once\u001b[39m\u001b[34m(self, x, profile, visualize, embed)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28mself\u001b[39m._profile_one_layer(m, x, dt)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m x = \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[32m    160\u001b[39m y.append(x \u001b[38;5;28;01mif\u001b[39;00m m.i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/ultralytics/nn/modules/head.py:205\u001b[39m, in \u001b[36mSegment.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    202\u001b[39m bs = p.shape[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# batch size\u001b[39;00m\n\u001b[32m    204\u001b[39m mc = torch.cat([\u001b[38;5;28mself\u001b[39m.cv4[i](x[i]).view(bs, \u001b[38;5;28mself\u001b[39m.nm, -\u001b[32m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.nl)], \u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# mask coefficients\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m x = \u001b[43mDetect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x, mc, p\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/ultralytics/nn/modules/head.py:72\u001b[39m, in \u001b[36mDetect.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.forward_end2end(x)\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.nl):\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     x[i] = torch.cat((\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m.cv3[i](x[i])), \u001b[32m1\u001b[39m)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:  \u001b[38;5;66;03m# Training path\u001b[39;00m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/ultralytics/nn/modules/conv.py:91\u001b[39m, in \u001b[36mConv.forward_fuse\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     82\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[33;03m    Apply convolution and activation without batch normalization.\u001b[39;00m\n\u001b[32m     84\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m \u001b[33;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.act(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "path = 'vides/Дизайн без названия (10).mp4'\n",
    "cap = cv2.VideoCapture(path)\n",
    "# Initialize a YOLO-World model\n",
    "model = YOLO(\"best (2).pt\")  # or choose yolov8m/l-world.pt\n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Create VideoWriter to save output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('Tracking_Outputs/outputs_2__botsort_0.05ntt_0.5tht_0.99match'+path.split('/')[-1], fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "    results = model.track(frame, persist=True, conf=0.4, tracker='bytetrack_custom.yaml', verbose=False)\n",
    "    \n",
    "    # Create a copy of the frame to draw our custom annotations\n",
    "    annotated_frame = frame.copy()\n",
    "    \n",
    "    # Assuming results[0] contains the current frame's detection results\n",
    "    # and that the boxes attribute holds detection info\n",
    "    potato_boxes = []\n",
    "    if results and results[0].boxes is not None:\n",
    "        for box in results[0].boxes:\n",
    "            # Extract coordinates (assuming box.xyxy returns a list/array)\n",
    "            # The indexing may depend on the format; adjust if necessary\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "            boxes = annotated_frame[y1:y2, x1:x2]\n",
    "            \n",
    "            # Get the track id; this might be stored as 'id' or 'track_id' depending on the version\n",
    "            track_id = getattr(box, 'id', None) or getattr(box, 'track_id', None)\n",
    "            track_id = np.round(track_id.numpy(), 2) if hasattr(track_id, 'numpy') else np.round(track_id, 2)\n",
    "            \n",
    "            # Draw the bounding box\n",
    "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            \n",
    "            # Draw the track id if available\n",
    "            if track_id is not None:\n",
    "                cv2.putText(\n",
    "                    annotated_frame,\n",
    "                    f\"ID: {str(track_id[0])}\",\n",
    "                    (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.9,\n",
    "                    (255, 255, 255),\n",
    "                    2\n",
    "                )\n",
    "            potato_boxes.append(boxes)\n",
    "    \n",
    "    results_seg = model_seg.predict(potato_boxes)\n",
    "    print(results_seg)\n",
    "    \n",
    "    \n",
    "    # Display the resized, annotated frame\n",
    "    #cv2.imshow(\"YOLOv8 Tracking\", annotated_frame)\n",
    "    out.write(annotated_frame)\n",
    "# Release video capture and close display window\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Processed video saved to \")\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_seg = model_seg.predict('boxes/1.png', verbose=False)\n",
    "results_seg[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_seg[0].masks.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[      109.6,      1.7125],\n",
       "        [      109.6,      4.2812],\n",
       "        [     108.74,      5.1375],\n",
       "        [     107.89,      5.1375],\n",
       "        [     107.03,      5.9938],\n",
       "        [     105.32,      5.9938],\n",
       "        [     104.46,        6.85],\n",
       "        [     102.75,        6.85],\n",
       "        [     101.89,      7.7063],\n",
       "        [     100.18,      7.7063],\n",
       "        [     99.325,      8.5625],\n",
       "        [     97.613,      8.5625],\n",
       "        [     96.756,      9.4188],\n",
       "        [     94.188,      9.4188],\n",
       "        [     93.331,      10.275],\n",
       "        [     91.619,      10.275],\n",
       "        [     90.763,      11.131],\n",
       "        [      89.05,      11.131],\n",
       "        [     88.194,      11.988],\n",
       "        [     86.481,      11.988],\n",
       "        [     85.625,      12.844],\n",
       "        [     83.056,      12.844],\n",
       "        [       82.2,        13.7],\n",
       "        [     80.488,        13.7],\n",
       "        [     79.631,      14.556],\n",
       "        [     77.919,      14.556],\n",
       "        [     77.062,      15.413],\n",
       "        [      75.35,      15.413],\n",
       "        [     74.494,      16.269],\n",
       "        [     72.781,      16.269],\n",
       "        [     71.925,      17.125],\n",
       "        [     70.213,      17.125],\n",
       "        [     69.356,      17.981],\n",
       "        [       68.5,      17.981],\n",
       "        [     67.644,      18.838],\n",
       "        [     66.788,      18.838],\n",
       "        [     65.931,      19.694],\n",
       "        [     65.075,      19.694],\n",
       "        [     62.506,      22.263],\n",
       "        [      61.65,      22.263],\n",
       "        [     59.938,      23.975],\n",
       "        [     59.081,      23.975],\n",
       "        [     58.225,      24.831],\n",
       "        [     57.369,      24.831],\n",
       "        [     55.656,      26.544],\n",
       "        [       54.8,      26.544],\n",
       "        [     52.231,      29.113],\n",
       "        [     51.375,      29.113],\n",
       "        [     49.663,      30.825],\n",
       "        [     48.806,      30.825],\n",
       "        [     45.381,       34.25],\n",
       "        [     44.525,       34.25],\n",
       "        [       41.1,      37.675],\n",
       "        [     40.244,      37.675],\n",
       "        [     36.819,        41.1],\n",
       "        [     36.819,      41.956],\n",
       "        [     31.681,      47.094],\n",
       "        [     31.681,       47.95],\n",
       "        [     28.256,      51.375],\n",
       "        [     28.256,      52.231],\n",
       "        [     26.544,      53.944],\n",
       "        [     26.544,        54.8],\n",
       "        [     23.975,      57.369],\n",
       "        [     23.975,      58.225],\n",
       "        [     22.263,      59.938],\n",
       "        [     22.263,      60.794],\n",
       "        [      20.55,      62.506],\n",
       "        [      20.55,      63.363],\n",
       "        [     19.694,      64.219],\n",
       "        [     19.694,      65.075],\n",
       "        [     18.838,      65.931],\n",
       "        [     18.838,      66.788],\n",
       "        [     17.981,      67.644],\n",
       "        [     17.981,        68.5],\n",
       "        [     17.125,      69.356],\n",
       "        [     17.125,      70.213],\n",
       "        [     16.269,      71.069],\n",
       "        [     16.269,      71.925],\n",
       "        [     15.413,      72.781],\n",
       "        [     15.413,      73.638],\n",
       "        [       13.7,       75.35],\n",
       "        [       13.7,      76.206],\n",
       "        [     12.844,      77.062],\n",
       "        [     12.844,      77.919],\n",
       "        [     11.988,      78.775],\n",
       "        [     11.988,      79.631],\n",
       "        [     11.131,      80.488],\n",
       "        [     11.131,      81.344],\n",
       "        [     10.275,        82.2],\n",
       "        [     10.275,      83.056],\n",
       "        [     9.4188,      83.913],\n",
       "        [     9.4188,      84.769],\n",
       "        [     8.5625,      85.625],\n",
       "        [     8.5625,      86.481],\n",
       "        [     7.7063,      87.338],\n",
       "        [     7.7063,       89.05],\n",
       "        [       6.85,      89.906],\n",
       "        [       6.85,      91.619],\n",
       "        [     5.9938,      92.475],\n",
       "        [     5.9938,      95.044],\n",
       "        [     5.1375,        95.9],\n",
       "        [     5.1375,      100.18],\n",
       "        [     4.2812,      101.04],\n",
       "        [     4.2812,      103.61],\n",
       "        [      3.425,      104.46],\n",
       "        [      3.425,      106.18],\n",
       "        [     2.5688,      107.03],\n",
       "        [     2.5688,      110.46],\n",
       "        [     1.7125,      111.31],\n",
       "        [     1.7125,      112.17],\n",
       "        [    0.85625,      113.03],\n",
       "        [          0,      113.03],\n",
       "        [          0,      180.67],\n",
       "        [     1.7125,      180.67],\n",
       "        [     2.5688,      181.53],\n",
       "        [     2.5688,      182.38],\n",
       "        [     5.1375,      184.95],\n",
       "        [     5.1375,      185.81],\n",
       "        [       6.85,      187.52],\n",
       "        [       6.85,      188.38],\n",
       "        [     8.5625,      190.09],\n",
       "        [     8.5625,      190.94],\n",
       "        [     9.4188,       191.8],\n",
       "        [     9.4188,      192.66],\n",
       "        [     10.275,      193.51],\n",
       "        [     10.275,      194.37],\n",
       "        [     11.131,      195.23],\n",
       "        [     11.131,      196.08],\n",
       "        [     11.988,      196.94],\n",
       "        [     11.988,      197.79],\n",
       "        [     12.844,      198.65],\n",
       "        [     12.844,      199.51],\n",
       "        [       13.7,      200.36],\n",
       "        [       13.7,      201.22],\n",
       "        [     14.556,      202.08],\n",
       "        [     14.556,      202.93],\n",
       "        [     15.413,      203.79],\n",
       "        [     15.413,       205.5],\n",
       "        [     16.269,      206.36],\n",
       "        [     16.269,      208.07],\n",
       "        [     17.125,      208.93],\n",
       "        [     17.125,      209.78],\n",
       "        [     17.981,      210.64],\n",
       "        [     17.981,      211.49],\n",
       "        [     18.838,      212.35],\n",
       "        [     18.838,      213.21],\n",
       "        [      20.55,      214.92],\n",
       "        [      20.55,      215.78],\n",
       "        [     22.263,      217.49],\n",
       "        [     22.263,      218.34],\n",
       "        [     23.975,      220.06],\n",
       "        [     23.975,      220.91],\n",
       "        [     24.831,      221.77],\n",
       "        [     24.831,      222.63],\n",
       "        [     25.688,      223.48],\n",
       "        [     25.688,      224.34],\n",
       "        [       27.4,      226.05],\n",
       "        [       27.4,      226.91],\n",
       "        [     28.256,      227.76],\n",
       "        [     28.256,      228.62],\n",
       "        [     29.113,      229.48],\n",
       "        [     29.113,      230.33],\n",
       "        [     30.825,      232.04],\n",
       "        [     30.825,       232.9],\n",
       "        [     32.538,      234.61],\n",
       "        [     32.538,      235.47],\n",
       "        [      34.25,      237.18],\n",
       "        [      34.25,      238.04],\n",
       "        [     36.819,      240.61],\n",
       "        [     36.819,      241.46],\n",
       "        [     37.675,      242.32],\n",
       "        [     37.675,      243.18],\n",
       "        [     39.388,      244.89],\n",
       "        [     39.388,      245.74],\n",
       "        [     40.244,       246.6],\n",
       "        [     40.244,      248.31],\n",
       "        [       41.1,      249.17],\n",
       "        [       41.1,      250.03],\n",
       "        [     41.956,      250.88],\n",
       "        [     41.956,      251.74],\n",
       "        [     42.813,      252.59],\n",
       "        [     42.813,      253.45],\n",
       "        [     43.669,      254.31],\n",
       "        [     43.669,      255.16],\n",
       "        [     44.525,      256.02],\n",
       "        [     44.525,      256.88],\n",
       "        [     46.238,      258.59],\n",
       "        [     46.238,      259.44],\n",
       "        [     48.806,      262.01],\n",
       "        [     48.806,      262.87],\n",
       "        [     50.519,      264.58],\n",
       "        [     50.519,      265.44],\n",
       "        [     52.231,      267.15],\n",
       "        [     52.231,      268.01],\n",
       "        [     53.088,      268.01],\n",
       "        [     53.944,      268.86],\n",
       "        [       54.8,      268.86],\n",
       "        [     55.656,      269.72],\n",
       "        [     56.513,      269.72],\n",
       "        [     57.369,      270.58],\n",
       "        [     59.081,      270.58],\n",
       "        [     59.938,      271.43],\n",
       "        [     60.794,      271.43],\n",
       "        [      61.65,      272.29],\n",
       "        [      61.65,      273.14],\n",
       "        [     153.27,      273.14],\n",
       "        [     153.27,      272.29],\n",
       "        [     154.12,      271.43],\n",
       "        [     154.98,      271.43],\n",
       "        [     155.84,      270.58],\n",
       "        [     158.41,      270.58],\n",
       "        [     159.26,      269.72],\n",
       "        [     160.98,      269.72],\n",
       "        [     161.83,      268.86],\n",
       "        [     163.54,      268.86],\n",
       "        [      164.4,      268.01],\n",
       "        [     166.11,      268.01],\n",
       "        [     167.83,      266.29],\n",
       "        [     168.68,      266.29],\n",
       "        [     171.25,      263.73],\n",
       "        [     172.11,      263.73],\n",
       "        [     172.96,      262.87],\n",
       "        [     173.82,      262.87],\n",
       "        [     174.68,      262.01],\n",
       "        [     175.53,      262.01],\n",
       "        [     176.39,      261.16],\n",
       "        [     177.24,      261.16],\n",
       "        [      178.1,       260.3],\n",
       "        [     178.96,       260.3],\n",
       "        [     179.81,      259.44],\n",
       "        [     180.67,      259.44],\n",
       "        [     181.53,      258.59],\n",
       "        [     182.38,      258.59],\n",
       "        [     183.24,      257.73],\n",
       "        [     184.09,      257.73],\n",
       "        [     184.95,      256.88],\n",
       "        [     185.81,      256.88],\n",
       "        [     186.66,      256.02],\n",
       "        [     187.52,      256.02],\n",
       "        [     188.38,      255.16],\n",
       "        [     190.09,      255.16],\n",
       "        [     190.94,      254.31],\n",
       "        [      191.8,      254.31],\n",
       "        [     192.66,      253.45],\n",
       "        [     193.51,      253.45],\n",
       "        [     194.37,      252.59],\n",
       "        [     196.08,      252.59],\n",
       "        [     196.94,      251.74],\n",
       "        [     197.79,      251.74],\n",
       "        [     198.65,      250.88],\n",
       "        [     199.51,      250.88],\n",
       "        [     200.36,      250.03],\n",
       "        [     201.22,      250.03],\n",
       "        [     202.08,      249.17],\n",
       "        [     202.93,      249.17],\n",
       "        [     204.64,      247.46],\n",
       "        [      205.5,      247.46],\n",
       "        [     206.36,       246.6],\n",
       "        [     207.21,       246.6],\n",
       "        [     208.93,      244.89],\n",
       "        [     209.78,      244.89],\n",
       "        [     213.21,      241.46],\n",
       "        [     214.06,      241.46],\n",
       "        [     217.49,      238.04],\n",
       "        [     218.34,      238.04],\n",
       "        [     223.48,       232.9],\n",
       "        [     223.48,      232.04],\n",
       "        [     231.19,      224.34],\n",
       "        [     231.19,      223.48],\n",
       "        [     234.61,      220.06],\n",
       "        [     234.61,       219.2],\n",
       "        [     237.18,      216.63],\n",
       "        [     237.18,      215.78],\n",
       "        [     239.75,      213.21],\n",
       "        [     239.75,      212.35],\n",
       "        [     241.46,      210.64],\n",
       "        [     241.46,      209.78],\n",
       "        [     242.32,      208.93],\n",
       "        [     242.32,      208.07],\n",
       "        [     243.18,      207.21],\n",
       "        [     243.18,      206.36],\n",
       "        [     244.89,      204.64],\n",
       "        [     244.89,      203.79],\n",
       "        [     245.74,      202.93],\n",
       "        [     245.74,      202.08],\n",
       "        [      246.6,      201.22],\n",
       "        [      246.6,      200.36],\n",
       "        [     247.46,      199.51],\n",
       "        [     247.46,      198.65],\n",
       "        [     248.31,      197.79],\n",
       "        [     248.31,      196.94],\n",
       "        [     249.17,      196.08],\n",
       "        [     249.17,      195.23],\n",
       "        [     250.03,      194.37],\n",
       "        [     250.03,      192.66],\n",
       "        [     250.88,       191.8],\n",
       "        [     250.88,      190.09],\n",
       "        [     251.74,      189.23],\n",
       "        [     251.74,      188.38],\n",
       "        [     252.59,      187.52],\n",
       "        [     252.59,      185.81],\n",
       "        [     253.45,      184.95],\n",
       "        [     253.45,      184.09],\n",
       "        [     254.31,      183.24],\n",
       "        [     254.31,      181.53],\n",
       "        [     255.16,      180.67],\n",
       "        [     255.16,      178.96],\n",
       "        [     256.02,       178.1],\n",
       "        [     256.02,      176.39],\n",
       "        [     256.88,      175.53],\n",
       "        [     256.88,      174.68],\n",
       "        [     257.73,      173.82],\n",
       "        [     257.73,      172.11],\n",
       "        [     258.59,      171.25],\n",
       "        [     258.59,      169.54],\n",
       "        [     259.44,      168.68],\n",
       "        [     259.44,      166.97],\n",
       "        [      260.3,      166.11],\n",
       "        [      260.3,       164.4],\n",
       "        [     261.16,      163.54],\n",
       "        [     261.16,      161.83],\n",
       "        [     262.01,      160.98],\n",
       "        [     262.01,      160.12],\n",
       "        [     262.87,      159.26],\n",
       "        [     262.87,      157.55],\n",
       "        [     263.73,      156.69],\n",
       "        [     263.73,      154.98],\n",
       "        [     264.58,      154.12],\n",
       "        [     264.58,      152.41],\n",
       "        [     265.44,      151.56],\n",
       "        [     265.44,      149.84],\n",
       "        [     266.29,      148.99],\n",
       "        [     266.29,      147.28],\n",
       "        [     267.15,      146.42],\n",
       "        [     267.15,      143.85],\n",
       "        [     268.01,      142.99],\n",
       "        [     268.01,      140.43],\n",
       "        [     268.86,      139.57],\n",
       "        [     268.86,         137],\n",
       "        [     269.72,      136.14],\n",
       "        [     269.72,      131.86],\n",
       "        [     270.58,      131.01],\n",
       "        [     270.58,      127.58],\n",
       "        [     271.43,      126.73],\n",
       "        [     271.43,      124.16],\n",
       "        [     272.29,       123.3],\n",
       "        [     273.14,       123.3],\n",
       "        [     273.14,      77.062],\n",
       "        [     272.29,      77.062],\n",
       "        [     270.58,       75.35],\n",
       "        [     270.58,      74.494],\n",
       "        [     269.72,      73.638],\n",
       "        [     269.72,      72.781],\n",
       "        [     268.86,      71.925],\n",
       "        [     268.86,      70.213],\n",
       "        [     268.01,      69.356],\n",
       "        [     268.01,        68.5],\n",
       "        [     267.15,      67.644],\n",
       "        [     267.15,      66.788],\n",
       "        [     266.29,      65.931],\n",
       "        [     266.29,      65.075],\n",
       "        [     265.44,      64.219],\n",
       "        [     265.44,      63.363],\n",
       "        [     264.58,      62.506],\n",
       "        [     264.58,       61.65],\n",
       "        [     263.73,      60.794],\n",
       "        [     263.73,      59.081],\n",
       "        [     262.87,      58.225],\n",
       "        [     262.87,      57.369],\n",
       "        [     262.01,      56.513],\n",
       "        [     262.01,      55.656],\n",
       "        [     261.16,        54.8],\n",
       "        [     261.16,      53.944],\n",
       "        [      260.3,      53.088],\n",
       "        [      260.3,      52.231],\n",
       "        [     258.59,      50.519],\n",
       "        [     258.59,      49.663],\n",
       "        [     256.02,      47.094],\n",
       "        [     256.02,      46.238],\n",
       "        [     248.31,      38.531],\n",
       "        [     248.31,      37.675],\n",
       "        [     244.03,      33.394],\n",
       "        [     244.03,      32.538],\n",
       "        [     231.19,      19.694],\n",
       "        [     230.33,      19.694],\n",
       "        [     227.76,      17.125],\n",
       "        [     226.91,      17.125],\n",
       "        [     225.19,      15.413],\n",
       "        [     224.34,      15.413],\n",
       "        [     222.63,        13.7],\n",
       "        [     221.77,        13.7],\n",
       "        [     220.91,      12.844],\n",
       "        [     220.06,      12.844],\n",
       "        [      219.2,      11.988],\n",
       "        [     218.34,      11.988],\n",
       "        [     217.49,      11.131],\n",
       "        [     216.63,      11.131],\n",
       "        [     215.78,      10.275],\n",
       "        [     214.92,      10.275],\n",
       "        [     214.06,      9.4188],\n",
       "        [     213.21,      9.4188],\n",
       "        [     212.35,      8.5625],\n",
       "        [     210.64,      8.5625],\n",
       "        [     208.93,        6.85],\n",
       "        [     207.21,        6.85],\n",
       "        [     206.36,      5.9938],\n",
       "        [     204.64,      5.9938],\n",
       "        [     202.93,      4.2812],\n",
       "        [     202.93,      1.7125]], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_seg[0].masks.xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the larger frame (for example, a video frame)\n",
    "frame = cv2.imread('frane.jpg')  # Or use video frame captured via cv2.VideoCapture()\n",
    "\n",
    "# Load the image you want to overlay\n",
    "overlay_image = cv2.imread('Screenshot 2025-04-01 at 23.07.16.png')\n",
    "\n",
    "# Resize overlay image if necessary (to fit it into the larger frame)\n",
    "overlay_height, overlay_width = overlay_image.shape[:2]\n",
    "frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "# Set the region where you want to place the overlay image\n",
    "# For example, top-left corner of the larger frame\n",
    "x_offset, y_offset = 100, 100  # Starting position (top-left corner)\n",
    "end_x = x_offset + overlay_width\n",
    "end_y = y_offset + overlay_height\n",
    "\n",
    "# Resize overlay image if it is larger than the region in the frame\n",
    "if end_x > frame_width or end_y > frame_height:\n",
    "    scale_factor = min(frame_width / overlay_width, frame_height / overlay_height)\n",
    "    overlay_image = cv2.resize(overlay_image, (int(overlay_width * scale_factor), int(overlay_height * scale_factor)))\n",
    "    overlay_height, overlay_width = overlay_image.shape[:2]\n",
    "\n",
    "    # Recalculate end_x and end_y for the resized image\n",
    "    end_x = x_offset + overlay_width\n",
    "    end_y = y_offset + overlay_height\n",
    "\n",
    "# Place the overlay image into the frame\n",
    "frame[y_offset:end_y, x_offset:end_x] = overlay_image\n",
    "\n",
    "# Optionally, add a border around the overlay image (if needed)\n",
    "cv2.rectangle(frame, (x_offset, y_offset), (end_x, end_y), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite('frame_with_lineika.png', frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'vides/Дизайн без названия (32).mp4'\n",
    "model_object_detection_path = \"best (2).pt\"\n",
    "model_image_segmantation_path = \"best_yoloseg.pt\"\n",
    "output_path = 'Tracking_Outputs/outputs_2_' + path.split('/')[-1]\n",
    "tracker_config = 'bytetrack_custom.yaml'\n",
    "conf_threshold = 0.4\n",
    "colors = [144, 80, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed video saved to: inference_output/output.mp4\n"
     ]
    }
   ],
   "source": [
    "!python inference.py --video_path=Videos/video.mp4  --model_object_detection=Models/best.pt  --model_image_segmentation=Models/best_yoloseg.pt --output_path=inference_output/output.mp4 --output_data_path=output_data.json --area_segment_path=area_for_segment.json --ratio_path=area_config.json --tracker_config=bytetrack_custom.yaml --conf_threshold=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: (144, 119), End: (1150, 121)\n",
      "area_for_segment: [144, 119, 1150, 121]\n",
      "cm_per_pixel: 0.009940357852882704\n",
      "Сохранено в 'area_config.json'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "drawing = False\n",
    "start_point = (-1, -1)\n",
    "lines = []\n",
    "\n",
    "def draw_overlay_text(img):\n",
    "    text = \"Mark up Ruler in frame | Press 'c' to clear, 'Esc' to exit\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    scale = 0.7\n",
    "    thickness = 2\n",
    "    size = cv2.getTextSize(text, font, scale, thickness)[0]\n",
    "    text_x = 10\n",
    "    text_y = img.shape[0] - 10\n",
    "    cv2.putText(img, text, (text_x, text_y), font, scale, (255, 255, 255), thickness, cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "def draw_line(event, x, y, flags, param):\n",
    "    global drawing, start_point, lines, frame\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        start_point = (x, y)\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and drawing:\n",
    "        frame_copy = frame.copy()\n",
    "        cv2.line(frame_copy, start_point, (x, y), (255, 0, 0), 2)\n",
    "        frame_copy = draw_overlay_text(frame_copy)\n",
    "        cv2.imshow(\"Frame\", frame_copy)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        end_point = (x, y)\n",
    "        lines.append((start_point[0], start_point[1], end_point[0], end_point[1]))\n",
    "        cv2.line(frame, start_point, end_point, (255, 0, 0), 2)\n",
    "        frame = draw_overlay_text(frame)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "# === Загрузка кадра ===\n",
    "frame = cv2.imread('frame_with_lineika.png')\n",
    "if frame is None:\n",
    "    raise FileNotFoundError(\"Файл 'frame_with_lineika.png' не найден.\")\n",
    "seg_fram = frame.copy()\n",
    "cv2.imwrite('frane.jpg', seg_fram)\n",
    "\n",
    "frame = draw_overlay_text(frame)\n",
    "cv2.imshow(\"Frame\", frame)\n",
    "cv2.setMouseCallback(\"Frame\", draw_line)\n",
    "\n",
    "# === Главный цикл ===\n",
    "while True:\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # Esc\n",
    "        break\n",
    "    elif key == ord('c'):  # Clear\n",
    "        lines.clear()\n",
    "        frame = seg_fram.copy()\n",
    "        frame = draw_overlay_text(frame)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "# === Подсчёт границ и линейки ===\n",
    "if lines:\n",
    "    min_x = min_y = float('inf')\n",
    "    max_x = max_y = float('-inf')\n",
    "\n",
    "    for x1, y1, x2, y2 in lines:\n",
    "        min_x = min(min_x, x1, x2)\n",
    "        min_y = min(min_y, y1, y2)\n",
    "        max_x = max(max_x, x1, x2)\n",
    "        max_y = max(max_y, y1, y2)\n",
    "        print(f\"Start: ({x1}, {y1}), End: ({x2}, {y2})\")\n",
    "\n",
    "    area_for_segment = [int(min_x), int(min_y), int(max_x), int(max_y)]\n",
    "    cm_per_pixel = 10 / (max_x - min_x)  # Предполагаем, что линия = 10 см по горизонтали\n",
    "\n",
    "    print(f\"area_for_segment: {area_for_segment}\")\n",
    "    print(f\"cm_per_pixel: {cm_per_pixel}\")\n",
    "\n",
    "    # === Сохраняем данные ===\n",
    "    with open(\"area_config.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"area_for_segment\": area_for_segment,\n",
    "            \"cm_per_pixel\": cm_per_pixel\n",
    "        }, f, indent=2)\n",
    "    print(\"Сохранено в 'area_config.json'\")\n",
    "\n",
    "else:\n",
    "    print(\"Линии не размечены.\")\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_per_pixel=0.01002004008016032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area_for_segment = [144, 122, 1148, 123]\n",
      "Saved to area_for_segment.json\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Initialize variables\n",
    "drawing = False\n",
    "start_point = (-1, -1)\n",
    "lines = []\n",
    "\n",
    "def draw_overlay_text(img):\n",
    "    overlay_text = \"Mark up lines in frame | Press 'c' to clear, 'Esc' to exit\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    scale = 0.7\n",
    "    thickness = 2\n",
    "    size = cv2.getTextSize(overlay_text, font, scale, thickness)[0]\n",
    "    text_x = 10\n",
    "    text_y = img.shape[0] - 10  # Place at bottom\n",
    "    cv2.putText(img, overlay_text, (text_x, text_y), font, scale, (255, 255, 255), thickness, cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "# Mouse callback\n",
    "def draw_line(event, x, y, flags, param):\n",
    "    global drawing, start_point, lines, frame\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        start_point = (x, y)\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and drawing:\n",
    "        frame_copy = frame.copy()\n",
    "        cv2.line(frame_copy, start_point, (x, y), (255, 0, 0), 2)\n",
    "        frame_copy = draw_overlay_text(frame_copy)\n",
    "        cv2.imshow(\"Frame\", frame_copy)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        end_point = (x, y)\n",
    "        lines.append((start_point[0], start_point[1], end_point[0], end_point[1]))\n",
    "        cv2.line(frame, start_point, end_point, (255, 0, 0), 2)\n",
    "        frame = draw_overlay_text(frame)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "# Load frame\n",
    "frame = cv2.imread('frane.jpg')\n",
    "if frame is None:\n",
    "    raise FileNotFoundError(\"Image 'frane.jpg' not found.\")\n",
    "seg_fram = frame.copy()\n",
    "cv2.imwrite('frane.jpg', seg_fram)\n",
    "\n",
    "frame = draw_overlay_text(frame)\n",
    "cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "cv2.setMouseCallback(\"Frame\", draw_line)\n",
    "\n",
    "# Interaction loop\n",
    "while True:\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # ESC to exit\n",
    "        break\n",
    "    elif key == ord('c'):  # 'c' to clear\n",
    "        lines.clear()\n",
    "        frame = seg_fram.copy()\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "# Calculate area\n",
    "if lines:\n",
    "    min_x = min_y = float('inf')\n",
    "    max_x = max_y = float('-inf')\n",
    "\n",
    "    for x1, y1, x2, y2 in lines:\n",
    "        min_x = min(min_x, x1, x2)\n",
    "        min_y = min(min_y, y1, y2)\n",
    "        max_x = max(max_x, x1, x2)\n",
    "        max_y = max(max_y, y1, y2)\n",
    "\n",
    "    area_for_segment = [int(min_x), int(min_y), int(max_x), int(max_y)]\n",
    "    print(\"area_for_segment =\", area_for_segment)\n",
    "\n",
    "    # Save as .json\n",
    "    with open(\"area_for_segment.json\", \"w\") as f:\n",
    "        json.dump(area_for_segment, f)\n",
    "    print(\"Saved to area_for_segment.json\")\n",
    "\n",
    "    # Optional: Save as .npy\n",
    "    #np.save(\"area_for_segment.npy\", np.array(area_for_segment))\n",
    "\n",
    "else:\n",
    "    print(\"No lines drawn. Area not saved.\")\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vides/Дизайн без названия (1) 2.mp4', 'vides/Дизайн без названия (2) 2.mp4', 'vides/Дизайн без названия (3) 2.mp4', 'vides/Дизайн без названия.mp4', 'vides/Дизайн без названия (1).mp4', 'vides/Дизайн без названия (10).mp4', 'vides/Дизайн без названия (11).mp4', 'vides/Дизайн без названия (12).mp4', 'vides/Дизайн без названия (13).mp4', 'vides/Дизайн без названия (14).mp4', 'vides/Дизайн без названия (15).mp4', 'vides/Дизайн без названия (16).mp4', 'vides/Дизайн без названия (17).mp4', 'vides/Дизайн без названия (18).mp4', 'vides/Дизайн без названия (2).mp4', 'vides/Дизайн без названия (20).mp4', 'vides/Дизайн без названия (21).mp4', 'vides/Дизайн без названия (22).mp4', 'vides/Дизайн без названия (23).mp4', 'vides/Дизайн без названия (24).mp4', 'vides/Дизайн без названия (25).mp4', 'vides/Дизайн без названия (26).mp4', 'vides/Дизайн без названия (27).mp4', 'vides/Дизайн без названия (28).mp4', 'vides/Дизайн без названия (29).mp4', 'vides/Дизайн без названия (3).mp4', 'vides/Дизайн без названия (30).mp4', 'vides/Дизайн без названия (31).mp4', 'vides/Дизайн без названия (32).mp4', 'vides/Дизайн без названия (33).mp4', 'vides/Дизайн без названия (34).mp4', 'vides/Дизайн без названия (4).mp4', 'vides/Дизайн без названия (5).mp4', 'vides/Дизайн без названия (6).mp4', 'vides/Дизайн без названия (7).mp4', 'vides/Дизайн без названия (8).mp4', 'vides/Дизайн без названия (9).mp4']\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Initialize a YOLO-World model\n",
    "model = YOLO(\"best (2).pt\")  # or choose yolov8m/l-world.pt\n",
    "model_seg = YOLO(\"best_yoloseg.pt\")\n",
    "\n",
    "import glob\n",
    "videos = sorted(glob.glob('vides/*'))\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_for_segment=[1324, 12, 2327, 2146]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "\n",
    "consumer = KafkaConsumer('my_topic',\n",
    "                         bootstrap_servers=['localhost:9092'],\n",
    "                         auto_offset_reset='earliest',\n",
    "                         enable_auto_commit=False,\n",
    "                         group_id='my_group_id',\n",
    "                         value_deserializer=lambda x: x.decode('utf-8')\n",
    "                        )\n",
    "\n",
    "for message in consumer:\n",
    "    print(\"Received message: \", message.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_version=(2, 6, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed video saved to: Tracking_Outputs/outputs_2_Дизайн без названия (32).mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import time  # For capturing current time\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "\n",
    "camera_id = 1\n",
    "\n",
    "# === Configuration ===\n",
    "path = 'vides/Дизайн без названия (32).mp4'\n",
    "model_object_detection_path = \"best (2).pt\"\n",
    "model_image_segmantation_path = \"best_yoloseg.pt\"\n",
    "output_path = 'Tracking_Outputs/outputs_2_' + path.split('/')[-1]\n",
    "tracker_config = 'bytetrack_custom.yaml'\n",
    "conf_threshold = 0.4\n",
    "colors = [144, 80, 70]\n",
    "\n",
    "with open(\"area_config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "area_for_segment = tuple(config[\"area_for_segment\"])\n",
    "cm_per_pixel = float(config[\"cm_per_pixel\"])\n",
    "\n",
    "# === Load models ===\n",
    "model = YOLO(model_object_detection_path)\n",
    "model_seg = YOLO(model_image_segmantation_path)  # <-- Укажи путь к сегментационной модели\n",
    "\n",
    "# === Video input/output ===\n",
    "cap = cv2.VideoCapture(path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# === Tracking state ===\n",
    "frame_limit = 30\n",
    "frame_count = 0\n",
    "counter = 0\n",
    "map_track_size = {}\n",
    "\n",
    "# Prepare a dictionary to store all potato data\n",
    "potato_data = {}\n",
    "\n",
    "while cap.isOpened() and frame_count < frame_limit:\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    results = model.track(\n",
    "        frame,\n",
    "        persist=True,\n",
    "        conf=conf_threshold,\n",
    "        tracker=tracker_config,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "    cv2.rectangle(annotated_frame, (area_for_segment[0], area_for_segment[1]),\n",
    "                  (area_for_segment[2], area_for_segment[3]), (255, 0, 0), 2)\n",
    "\n",
    "    potato_boxes = []\n",
    "    potato_img_boxes = []\n",
    "\n",
    "    if results and results[0].boxes is not None:\n",
    "        for box in results[0].boxes:\n",
    "            coords = box.xyxy[0].cpu().numpy().astype(int)\n",
    "            x1, y1, x2, y2 = coords\n",
    "            track_id = int(box.id.cpu().numpy()[0])\n",
    "\n",
    "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "            prev_size = map_track_size.get(track_id, (0, 0))\n",
    "            cv2.putText(annotated_frame, f\"ID: {track_id}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "            cv2.putText(annotated_frame, f\"{round(prev_size[0], 2)}cm {round(prev_size[1], 2)}cm\",\n",
    "                        (x1, y1 + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "\n",
    "            if (area_for_segment[0] <= x1 <= area_for_segment[2] and\n",
    "                area_for_segment[1] <= y1 <= area_for_segment[3] and\n",
    "                area_for_segment[0] <= x2 <= area_for_segment[2] and\n",
    "                area_for_segment[1] <= y2 <= area_for_segment[3]):\n",
    "\n",
    "                img_box = frame[y1:y2, x1:x2]\n",
    "                potato_img_boxes.append(img_box)\n",
    "                potato_boxes.append([x1, y1, x2, y2, track_id])\n",
    "                counter += 1\n",
    "                cv2.imwrite(f'boxes/{counter}.png', img_box)\n",
    "\n",
    "    # Segmentation\n",
    "    if potato_img_boxes:\n",
    "        results_seg = model_seg.predict(potato_img_boxes, verbose=False)\n",
    "        for i, result in enumerate(results_seg):\n",
    "            x1, y1, x2, y2, track_id = potato_boxes[i]\n",
    "            prev_major, prev_minor = map_track_size.get(track_id, (0, 0))\n",
    "\n",
    "            for mask in result.masks.xy:\n",
    "                abs_coords = mask + np.array([x1, y1])\n",
    "                abs_coords = abs_coords.astype(np.int32)\n",
    "\n",
    "                contour = np.int32([abs_coords]).reshape((-1, 1, 2))\n",
    "\n",
    "                if contour.shape[0] >= 5:\n",
    "                    ellipse = cv2.fitEllipse(contour)\n",
    "                    _, axes, _ = ellipse\n",
    "                    major_axis = max(axes) * cm_per_pixel\n",
    "                    minor_axis = min(axes) * cm_per_pixel\n",
    "\n",
    "                    avg_major = (major_axis + prev_major) / 2 if prev_major else major_axis\n",
    "                    avg_minor = (minor_axis + prev_minor) / 2 if prev_minor else minor_axis\n",
    "\n",
    "                    map_track_size[track_id] = (avg_major, avg_minor)\n",
    "\n",
    "                    cv2.fillPoly(annotated_frame, [contour], colors)\n",
    "\n",
    "                    # Save potato data for each unique track_id\n",
    "                    data = {\n",
    "                        \"camera_id\": camera_id,\n",
    "                        \"potato_id\": track_id,  # Unique track ID\n",
    "                        \"type\": \"potato\",\n",
    "                        \"size\": f\"{round(major_axis, 2)}-{round(minor_axis, 2)} mm\",\n",
    "                        \"coordinates\": [x1, y1, x2, y2],\n",
    "                        \"frame_id\": frame_count,  # Frame ID\n",
    "                        \"time\": datetime.now().strftime(\"%H:%M:%S\"),\n",
    "                        \"passed\": \"yes\",  # Example status\n",
    "                        \"sorted\": \"no\"  # Example status\n",
    "                    }\n",
    "                    \n",
    "                    # Store the data in the dictionary using the potato_id as the key\n",
    "                    potato_data[track_id] = data\n",
    "\n",
    "    cv2.putText(annotated_frame, f\"Potato Count: {counter}\",\n",
    "                (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)\n",
    "\n",
    "    out.write(annotated_frame)\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Processed video saved to: {output_path}\")\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the potato data to a JSON file after processing\n",
    "with open('potato_data.json', 'w') as json_file:\n",
    "    json.dump(potato_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Using cached psycopg2-2.9.10-cp312-cp312-macosx_13_0_arm64.whl\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.10\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "connection to server on socket \"/tmp/.s.PGSQL.5432\" failed: FATAL:  role \"postgres\" does not exist\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Connect to PostgreSQL\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m conn = \u001b[43mpsycopg2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdbname=test user=postgres password=secret\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m cursor = conn.cursor()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Example JSON data received from Kafka\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project_Conveyer/.venv/lib/python3.12/site-packages/psycopg2/__init__.py:122\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     kwasync[\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m] = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    121\u001b[39m dsn = _ext.make_dsn(dsn, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m conn = \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    124\u001b[39m     conn.cursor_factory = cursor_factory\n",
      "\u001b[31mOperationalError\u001b[39m: connection to server on socket \"/tmp/.s.PGSQL.5432\" failed: FATAL:  role \"postgres\" does not exist\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\"dbname=test user=postgres password=secret\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Example JSON data received from Kafka\n",
    "data = {\n",
    "    \"camera_id\": 1,\n",
    "    \"potato_id\": 2,\n",
    "    \"type\": \"potato\",\n",
    "    \"size\": \"30-40 mm\",\n",
    "    \"coordinates\": [100, 200, 150, 250],\n",
    "    \"frame_id\": 1,\n",
    "    \"time\": \"10:23\",\n",
    "    \"passed\": \"yes\",\n",
    "    \"sorted\": \"no\"\n",
    "}\n",
    "\n",
    "# Insert JSON data into PostgreSQL\n",
    "cursor.execute(\"\"\"\n",
    "    INSERT INTO potatoes (camera_id, potato_id, type, size, coordinates, frame_id, time, passed, sorted)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\", (data['camera_id'], data['potato_id'], data['type'], data['size'], json.dumps(data['coordinates']), data['frame_id'], data['time'], data['passed'], data['sorted']))\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: (3.064242039988179, 2.5904243025846614),\n",
       " 4: (4.07979047847893, 3.033572600217525),\n",
       " 5: (3.4010108534940975, 3.173164528214143),\n",
       " 6: (3.53462463868166, 3.021297263716887),\n",
       " 7: (3.0341724403396633, 2.6458453558728783),\n",
       " 9: (3.026054505116954, 2.623809702649623),\n",
       " 1: (2.506380998090895, 2.4529465310320346),\n",
       " 11: (3.516642472786989, 2.929390894028849),\n",
       " 17: (4.271641699727885, 3.4626068978128073),\n",
       " 10: (2.8830012410341617, 2.6482639988820873),\n",
       " 16: (3.115660587628045, 3.015160424436978),\n",
       " 13: (3.071064805697821, 2.496601166371592),\n",
       " 18: (2.8276113900010715, 2.584707937641946),\n",
       " 19: (3.180077147627163, 2.607558915514745),\n",
       " 20: (2.769369610803638, 2.615850129442846),\n",
       " 23: (3.6395697889920466, 3.235202972779054),\n",
       " 22: (3.198273377810308, 2.962906174287051),\n",
       " 21: (2.794325528498403, 2.453862192157753),\n",
       " 25: (2.975825919416959, 2.7085219022028433),\n",
       " 26: (2.5693122084011772, 2.3530028196040518)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_track_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[144, 80, 70]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_seg[0].keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Masks object with attributes:\n",
       "\n",
       "data: tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
       "orig_shape: (190, 220)\n",
       "shape: torch.Size([1, 320, 320])\n",
       "xy: [array([[      90.75,       0.125],\n",
       "       [      90.75,      2.1875],\n",
       "       [     89.375,      3.5625],\n",
       "       [         88,      3.5625],\n",
       "       [     87.312,        4.25],\n",
       "       [     85.938,        4.25],\n",
       "       [      85.25,      4.9375],\n",
       "       [     84.562,      4.9375],\n",
       "       [     83.875,       5.625],\n",
       "       [       82.5,       5.625],\n",
       "       [     81.812,      6.3125],\n",
       "       [      79.75,      6.3125],\n",
       "       [     79.062,           7],\n",
       "       [     77.688,           7],\n",
       "       [         77,      7.6875],\n",
       "       [     75.625,      7.6875],\n",
       "       [     74.938,       8.375],\n",
       "       [     73.562,       8.375],\n",
       "       [     72.875,      9.0625],\n",
       "       [       71.5,      9.0625],\n",
       "       [     70.812,        9.75],\n",
       "       [     69.438,        9.75],\n",
       "       [      68.75,      10.438],\n",
       "       [     67.375,      10.438],\n",
       "       [     66.688,      11.125],\n",
       "       [         66,      11.125],\n",
       "       [     65.312,      11.812],\n",
       "       [     64.625,      11.812],\n",
       "       [     63.938,        12.5],\n",
       "       [      63.25,        12.5],\n",
       "       [     62.562,      13.187],\n",
       "       [     61.875,      13.187],\n",
       "       [     61.188,      13.875],\n",
       "       [       60.5,      13.875],\n",
       "       [     59.812,      14.562],\n",
       "       [     59.125,      14.562],\n",
       "       [      57.75,      15.937],\n",
       "       [     57.062,      15.937],\n",
       "       [     55.688,      17.312],\n",
       "       [         55,      17.312],\n",
       "       [      52.25,      20.062],\n",
       "       [     51.562,      20.062],\n",
       "       [     46.062,      25.562],\n",
       "       [     45.375,      25.562],\n",
       "       [     43.312,      27.625],\n",
       "       [     42.625,      27.625],\n",
       "       [     39.875,      30.375],\n",
       "       [     39.188,      30.375],\n",
       "       [     37.812,       31.75],\n",
       "       [     37.125,       31.75],\n",
       "       [     33.688,      35.187],\n",
       "       [         33,      35.187],\n",
       "       [     26.125,      42.062],\n",
       "       [     26.125,       42.75],\n",
       "       [     23.375,        45.5],\n",
       "       [     23.375,      46.187],\n",
       "       [         22,      47.562],\n",
       "       [         22,       48.25],\n",
       "       [     20.625,      49.625],\n",
       "       [     20.625,      50.312],\n",
       "       [      19.25,      51.687],\n",
       "       [      19.25,      52.375],\n",
       "       [     18.562,      53.062],\n",
       "       [     18.562,       53.75],\n",
       "       [     17.188,      55.125],\n",
       "       [     17.188,      55.812],\n",
       "       [     15.812,      57.187],\n",
       "       [     15.812,      57.875],\n",
       "       [     14.438,       59.25],\n",
       "       [     14.438,      59.937],\n",
       "       [      13.75,      60.625],\n",
       "       [      13.75,      61.312],\n",
       "       [     12.375,      62.687],\n",
       "       [     12.375,      63.375],\n",
       "       [         11,       64.75],\n",
       "       [         11,      65.438],\n",
       "       [     10.312,      66.125],\n",
       "       [     10.312,      66.812],\n",
       "       [     8.9375,      68.188],\n",
       "       [     8.9375,      68.875],\n",
       "       [       8.25,      69.562],\n",
       "       [       8.25,       70.25],\n",
       "       [     7.5625,      70.938],\n",
       "       [     7.5625,      71.625],\n",
       "       [      6.875,      72.312],\n",
       "       [      6.875,          73],\n",
       "       [     6.1875,      73.688],\n",
       "       [     6.1875,      74.375],\n",
       "       [        5.5,      75.062],\n",
       "       [        5.5,       75.75],\n",
       "       [     4.8125,      76.438],\n",
       "       [     4.8125,      77.812],\n",
       "       [      4.125,        78.5],\n",
       "       [      4.125,      79.188],\n",
       "       [     3.4375,      79.875],\n",
       "       [      1.375,      79.875],\n",
       "       [      1.375,         117],\n",
       "       [     3.4375,         117],\n",
       "       [      4.125,      117.69],\n",
       "       [      4.125,      119.06],\n",
       "       [     4.8125,      119.75],\n",
       "       [     4.8125,      121.12],\n",
       "       [        5.5,      121.81],\n",
       "       [        5.5,      123.19],\n",
       "       [      6.875,      124.56],\n",
       "       [      6.875,      125.25],\n",
       "       [       8.25,      126.62],\n",
       "       [       8.25,      127.31],\n",
       "       [     8.9375,         128],\n",
       "       [     8.9375,      128.69],\n",
       "       [     10.312,      130.06],\n",
       "       [     10.312,      130.75],\n",
       "       [     11.688,      132.12],\n",
       "       [     11.688,      132.81],\n",
       "       [     13.062,      134.19],\n",
       "       [     13.062,      134.88],\n",
       "       [      13.75,      135.56],\n",
       "       [      13.75,      136.25],\n",
       "       [     15.125,      137.62],\n",
       "       [     15.125,      138.31],\n",
       "       [       16.5,      139.69],\n",
       "       [       16.5,      140.38],\n",
       "       [     17.875,      141.75],\n",
       "       [     17.875,      142.44],\n",
       "       [     19.938,       144.5],\n",
       "       [     19.938,      145.19],\n",
       "       [     22.688,      147.94],\n",
       "       [     22.688,      148.62],\n",
       "       [     28.875,      154.81],\n",
       "       [     29.562,      154.81],\n",
       "       [     44.688,      169.94],\n",
       "       [     45.375,      169.94],\n",
       "       [     47.438,         172],\n",
       "       [     48.125,         172],\n",
       "       [     50.188,      174.06],\n",
       "       [     50.875,      174.06],\n",
       "       [      52.25,      175.44],\n",
       "       [     52.938,      175.44],\n",
       "       [     53.625,      176.12],\n",
       "       [     54.312,      176.12],\n",
       "       [         55,      176.81],\n",
       "       [     55.688,      176.81],\n",
       "       [     56.375,       177.5],\n",
       "       [     57.062,       177.5],\n",
       "       [      57.75,      178.19],\n",
       "       [     58.438,      178.19],\n",
       "       [     59.125,      178.88],\n",
       "       [       60.5,      178.88],\n",
       "       [     61.188,      179.56],\n",
       "       [     61.875,      179.56],\n",
       "       [     62.562,      180.25],\n",
       "       [     63.938,      180.25],\n",
       "       [     64.625,      180.94],\n",
       "       [     65.312,      180.94],\n",
       "       [         66,      181.62],\n",
       "       [     67.375,      181.62],\n",
       "       [     68.062,      182.31],\n",
       "       [     70.125,      182.31],\n",
       "       [     70.812,         183],\n",
       "       [       71.5,         183],\n",
       "       [     72.188,      183.69],\n",
       "       [      74.25,      183.69],\n",
       "       [     74.938,      184.38],\n",
       "       [         77,      184.38],\n",
       "       [     77.688,      185.06],\n",
       "       [      79.75,      185.06],\n",
       "       [     80.438,      185.75],\n",
       "       [     81.812,      185.75],\n",
       "       [       82.5,      186.44],\n",
       "       [      85.25,      186.44],\n",
       "       [     85.938,      187.12],\n",
       "       [     88.688,      187.12],\n",
       "       [     89.375,      187.81],\n",
       "       [     94.188,      187.81],\n",
       "       [     94.875,       188.5],\n",
       "       [     100.38,       188.5],\n",
       "       [     101.06,      189.19],\n",
       "       [     116.88,      189.19],\n",
       "       [     117.56,       188.5],\n",
       "       [     123.75,       188.5],\n",
       "       [     124.44,      187.81],\n",
       "       [     127.88,      187.81],\n",
       "       [     128.56,      187.12],\n",
       "       [        132,      187.12],\n",
       "       [     132.69,      186.44],\n",
       "       [     135.44,      186.44],\n",
       "       [     136.12,      185.75],\n",
       "       [     138.88,      185.75],\n",
       "       [     139.56,      185.06],\n",
       "       [     142.31,      185.06],\n",
       "       [        143,      184.38],\n",
       "       [     145.06,      184.38],\n",
       "       [     145.75,      183.69],\n",
       "       [     147.12,      183.69],\n",
       "       [     147.81,         183],\n",
       "       [     149.19,         183],\n",
       "       [     149.88,      182.31],\n",
       "       [     151.25,      182.31],\n",
       "       [     151.94,      181.62],\n",
       "       [     153.31,      181.62],\n",
       "       [        154,      180.94],\n",
       "       [     155.38,      180.94],\n",
       "       [     156.06,      180.25],\n",
       "       [     156.75,      180.25],\n",
       "       [     157.44,      179.56],\n",
       "       [     158.12,      179.56],\n",
       "       [     158.81,      178.88],\n",
       "       [      159.5,      178.88],\n",
       "       [     160.19,      178.19],\n",
       "       [     160.88,      178.19],\n",
       "       [     161.56,       177.5],\n",
       "       [     162.25,       177.5],\n",
       "       [     163.62,      176.12],\n",
       "       [     164.31,      176.12],\n",
       "       [        165,      175.44],\n",
       "       [     166.38,      175.44],\n",
       "       [     167.06,      174.75],\n",
       "       [     167.75,      174.75],\n",
       "       [     169.12,      173.38],\n",
       "       [     169.81,      173.38],\n",
       "       [      170.5,      172.69],\n",
       "       [     171.19,      172.69],\n",
       "       [     171.88,         172],\n",
       "       [     172.56,         172],\n",
       "       [     173.25,      171.31],\n",
       "       [     173.94,      171.31],\n",
       "       [     174.62,      170.62],\n",
       "       [     175.31,      170.62],\n",
       "       [        176,      169.94],\n",
       "       [     176.69,      169.94],\n",
       "       [     177.38,      169.25],\n",
       "       [     178.06,      169.25],\n",
       "       [     179.44,      167.88],\n",
       "       [     180.12,      167.88],\n",
       "       [     182.19,      165.81],\n",
       "       [     182.88,      165.81],\n",
       "       [     184.25,      164.44],\n",
       "       [     184.94,      164.44],\n",
       "       [        187,      162.38],\n",
       "       [     187.69,      162.38],\n",
       "       [     193.19,      156.88],\n",
       "       [     193.88,      156.88],\n",
       "       [     200.06,      150.69],\n",
       "       [     200.06,         150],\n",
       "       [     202.81,      147.25],\n",
       "       [     202.81,      146.56],\n",
       "       [     204.19,      145.19],\n",
       "       [     204.19,       144.5],\n",
       "       [     204.88,      143.81],\n",
       "       [     204.88,      143.12],\n",
       "       [     206.25,      141.75],\n",
       "       [     206.25,      141.06],\n",
       "       [     207.62,      139.69],\n",
       "       [     207.62,         139],\n",
       "       [     208.31,      138.31],\n",
       "       [     208.31,      137.62],\n",
       "       [     209.69,      136.25],\n",
       "       [     209.69,      135.56],\n",
       "       [     211.06,      134.19],\n",
       "       [     211.06,       133.5],\n",
       "       [     212.44,      132.12],\n",
       "       [     212.44,      131.44],\n",
       "       [     213.12,      130.75],\n",
       "       [     213.12,      130.06],\n",
       "       [      214.5,      128.69],\n",
       "       [      214.5,         128],\n",
       "       [     215.19,      127.31],\n",
       "       [     215.19,      126.62],\n",
       "       [     215.88,      125.94],\n",
       "       [     215.88,      124.56],\n",
       "       [     216.56,      123.88],\n",
       "       [     216.56,       122.5],\n",
       "       [     217.25,      121.81],\n",
       "       [     217.25,      120.44],\n",
       "       [     217.94,      119.75],\n",
       "       [     217.94,      119.06],\n",
       "       [     218.62,      118.38],\n",
       "       [     219.31,      118.38],\n",
       "       [     219.31,      77.125],\n",
       "       [     218.62,      77.125],\n",
       "       [     217.94,      76.438],\n",
       "       [     217.94,      75.062],\n",
       "       [     217.25,      74.375],\n",
       "       [     217.25,      71.625],\n",
       "       [     216.56,      70.938],\n",
       "       [     216.56,      68.875],\n",
       "       [     215.88,      68.188],\n",
       "       [     215.88,      66.812],\n",
       "       [     215.19,      66.125],\n",
       "       [     215.19,       64.75],\n",
       "       [      214.5,      64.062],\n",
       "       [      214.5,      63.375],\n",
       "       [     213.81,      62.687],\n",
       "       [     213.81,          62],\n",
       "       [     213.12,      61.312],\n",
       "       [     213.12,      59.937],\n",
       "       [     212.44,       59.25],\n",
       "       [     212.44,      58.562],\n",
       "       [     211.75,      57.875],\n",
       "       [     211.75,      57.187],\n",
       "       [     211.06,        56.5],\n",
       "       [     211.06,      55.812],\n",
       "       [     210.38,      55.125],\n",
       "       [     210.38,      54.437],\n",
       "       [     209.69,       53.75],\n",
       "       [     209.69,      53.062],\n",
       "       [        209,      52.375],\n",
       "       [        209,      51.687],\n",
       "       [     207.62,      50.312],\n",
       "       [     207.62,      49.625],\n",
       "       [     205.56,      47.562],\n",
       "       [     205.56,      46.875],\n",
       "       [      203.5,      44.812],\n",
       "       [      203.5,      44.125],\n",
       "       [     193.19,      33.812],\n",
       "       [     193.19,      33.125],\n",
       "       [     190.44,      30.375],\n",
       "       [     189.75,      30.375],\n",
       "       [     186.31,      26.937],\n",
       "       [     185.62,      26.937],\n",
       "       [     182.19,        23.5],\n",
       "       [      181.5,        23.5],\n",
       "       [     179.44,      21.438],\n",
       "       [     178.75,      21.438],\n",
       "       [     176.69,      19.375],\n",
       "       [        176,      19.375],\n",
       "       [     174.62,          18],\n",
       "       [     173.94,          18],\n",
       "       [     172.56,      16.625],\n",
       "       [     171.88,      16.625],\n",
       "       [     171.19,      15.937],\n",
       "       [      170.5,      15.937],\n",
       "       [     169.12,      14.562],\n",
       "       [     168.44,      14.562],\n",
       "       [     167.75,      13.875],\n",
       "       [     167.06,      13.875],\n",
       "       [     166.38,      13.187],\n",
       "       [     165.69,      13.187],\n",
       "       [        165,        12.5],\n",
       "       [     163.62,        12.5],\n",
       "       [     162.94,      11.812],\n",
       "       [     162.25,      11.812],\n",
       "       [     161.56,      11.125],\n",
       "       [     160.88,      11.125],\n",
       "       [     160.19,      10.438],\n",
       "       [      159.5,      10.438],\n",
       "       [     158.12,      9.0625],\n",
       "       [     157.44,      9.0625],\n",
       "       [     156.75,       8.375],\n",
       "       [     156.06,       8.375],\n",
       "       [     155.38,      7.6875],\n",
       "       [        154,      7.6875],\n",
       "       [     153.31,           7],\n",
       "       [     152.62,           7],\n",
       "       [     151.94,      6.3125],\n",
       "       [     150.56,      6.3125],\n",
       "       [     149.88,       5.625],\n",
       "       [     149.19,       5.625],\n",
       "       [      148.5,      4.9375],\n",
       "       [     147.12,      4.9375],\n",
       "       [     146.44,        4.25],\n",
       "       [     145.75,        4.25],\n",
       "       [     145.06,      3.5625],\n",
       "       [        143,      3.5625],\n",
       "       [     141.62,      2.1875],\n",
       "       [     141.62,       0.125]], dtype=float32)]\n",
       "xyn: [array([[     0.4125,  0.00065789],\n",
       "       [     0.4125,    0.011513],\n",
       "       [    0.40625,     0.01875],\n",
       "       [        0.4,     0.01875],\n",
       "       [    0.39687,    0.022368],\n",
       "       [    0.39062,    0.022368],\n",
       "       [     0.3875,    0.025987],\n",
       "       [    0.38438,    0.025987],\n",
       "       [    0.38125,    0.029605],\n",
       "       [      0.375,    0.029605],\n",
       "       [    0.37187,    0.033224],\n",
       "       [     0.3625,    0.033224],\n",
       "       [    0.35938,    0.036842],\n",
       "       [    0.35313,    0.036842],\n",
       "       [       0.35,    0.040461],\n",
       "       [    0.34375,    0.040461],\n",
       "       [    0.34062,    0.044079],\n",
       "       [    0.33437,    0.044079],\n",
       "       [    0.33125,    0.047697],\n",
       "       [      0.325,    0.047697],\n",
       "       [    0.32188,    0.051316],\n",
       "       [    0.31563,    0.051316],\n",
       "       [     0.3125,    0.054934],\n",
       "       [    0.30625,    0.054934],\n",
       "       [    0.30312,    0.058553],\n",
       "       [        0.3,    0.058553],\n",
       "       [    0.29688,    0.062171],\n",
       "       [    0.29375,    0.062171],\n",
       "       [    0.29063,    0.065789],\n",
       "       [     0.2875,    0.065789],\n",
       "       [    0.28438,    0.069408],\n",
       "       [    0.28125,    0.069408],\n",
       "       [    0.27812,    0.073026],\n",
       "       [      0.275,    0.073026],\n",
       "       [    0.27187,    0.076645],\n",
       "       [    0.26875,    0.076645],\n",
       "       [     0.2625,    0.083882],\n",
       "       [    0.25938,    0.083882],\n",
       "       [    0.25313,    0.091118],\n",
       "       [       0.25,    0.091118],\n",
       "       [     0.2375,     0.10559],\n",
       "       [    0.23438,     0.10559],\n",
       "       [    0.20937,     0.13454],\n",
       "       [    0.20625,     0.13454],\n",
       "       [    0.19688,     0.14539],\n",
       "       [    0.19375,     0.14539],\n",
       "       [    0.18125,     0.15987],\n",
       "       [    0.17812,     0.15987],\n",
       "       [    0.17188,     0.16711],\n",
       "       [    0.16875,     0.16711],\n",
       "       [    0.15313,      0.1852],\n",
       "       [       0.15,      0.1852],\n",
       "       [    0.11875,     0.22138],\n",
       "       [    0.11875,       0.225],\n",
       "       [    0.10625,     0.23947],\n",
       "       [    0.10625,     0.24309],\n",
       "       [        0.1,     0.25033],\n",
       "       [        0.1,     0.25395],\n",
       "       [    0.09375,     0.26118],\n",
       "       [    0.09375,      0.2648],\n",
       "       [     0.0875,     0.27204],\n",
       "       [     0.0875,     0.27566],\n",
       "       [   0.084375,     0.27928],\n",
       "       [   0.084375,     0.28289],\n",
       "       [   0.078125,     0.29013],\n",
       "       [   0.078125,     0.29375],\n",
       "       [   0.071875,     0.30099],\n",
       "       [   0.071875,     0.30461],\n",
       "       [   0.065625,     0.31184],\n",
       "       [   0.065625,     0.31546],\n",
       "       [     0.0625,     0.31908],\n",
       "       [     0.0625,      0.3227],\n",
       "       [    0.05625,     0.32993],\n",
       "       [    0.05625,     0.33355],\n",
       "       [       0.05,     0.34079],\n",
       "       [       0.05,     0.34441],\n",
       "       [   0.046875,     0.34803],\n",
       "       [   0.046875,     0.35164],\n",
       "       [   0.040625,     0.35888],\n",
       "       [   0.040625,      0.3625],\n",
       "       [     0.0375,     0.36612],\n",
       "       [     0.0375,     0.36974],\n",
       "       [   0.034375,     0.37336],\n",
       "       [   0.034375,     0.37697],\n",
       "       [    0.03125,     0.38059],\n",
       "       [    0.03125,     0.38421],\n",
       "       [   0.028125,     0.38783],\n",
       "       [   0.028125,     0.39145],\n",
       "       [      0.025,     0.39507],\n",
       "       [      0.025,     0.39868],\n",
       "       [   0.021875,      0.4023],\n",
       "       [   0.021875,     0.40954],\n",
       "       [    0.01875,     0.41316],\n",
       "       [    0.01875,     0.41678],\n",
       "       [   0.015625,     0.42039],\n",
       "       [    0.00625,     0.42039],\n",
       "       [    0.00625,     0.61579],\n",
       "       [   0.015625,     0.61579],\n",
       "       [    0.01875,     0.61941],\n",
       "       [    0.01875,     0.62664],\n",
       "       [   0.021875,     0.63026],\n",
       "       [   0.021875,      0.6375],\n",
       "       [      0.025,     0.64112],\n",
       "       [      0.025,     0.64836],\n",
       "       [    0.03125,     0.65559],\n",
       "       [    0.03125,     0.65921],\n",
       "       [     0.0375,     0.66645],\n",
       "       [     0.0375,     0.67007],\n",
       "       [   0.040625,     0.67368],\n",
       "       [   0.040625,      0.6773],\n",
       "       [   0.046875,     0.68454],\n",
       "       [   0.046875,     0.68816],\n",
       "       [   0.053125,     0.69539],\n",
       "       [   0.053125,     0.69901],\n",
       "       [   0.059375,     0.70625],\n",
       "       [   0.059375,     0.70987],\n",
       "       [     0.0625,     0.71349],\n",
       "       [     0.0625,     0.71711],\n",
       "       [    0.06875,     0.72434],\n",
       "       [    0.06875,     0.72796],\n",
       "       [      0.075,      0.7352],\n",
       "       [      0.075,     0.73882],\n",
       "       [    0.08125,     0.74605],\n",
       "       [    0.08125,     0.74967],\n",
       "       [   0.090625,     0.76053],\n",
       "       [   0.090625,     0.76414],\n",
       "       [    0.10312,     0.77862],\n",
       "       [    0.10312,     0.78224],\n",
       "       [    0.13125,      0.8148],\n",
       "       [    0.13438,      0.8148],\n",
       "       [    0.20312,     0.89441],\n",
       "       [    0.20625,     0.89441],\n",
       "       [    0.21563,     0.90526],\n",
       "       [    0.21875,     0.90526],\n",
       "       [    0.22813,     0.91612],\n",
       "       [    0.23125,     0.91612],\n",
       "       [     0.2375,     0.92336],\n",
       "       [    0.24062,     0.92336],\n",
       "       [    0.24375,     0.92697],\n",
       "       [    0.24688,     0.92697],\n",
       "       [       0.25,     0.93059],\n",
       "       [    0.25313,     0.93059],\n",
       "       [    0.25625,     0.93421],\n",
       "       [    0.25938,     0.93421],\n",
       "       [     0.2625,     0.93783],\n",
       "       [    0.26562,     0.93783],\n",
       "       [    0.26875,     0.94145],\n",
       "       [      0.275,     0.94145],\n",
       "       [    0.27812,     0.94507],\n",
       "       [    0.28125,     0.94507],\n",
       "       [    0.28438,     0.94868],\n",
       "       [    0.29063,     0.94868],\n",
       "       [    0.29375,      0.9523],\n",
       "       [    0.29688,      0.9523],\n",
       "       [        0.3,     0.95592],\n",
       "       [    0.30625,     0.95592],\n",
       "       [    0.30937,     0.95954],\n",
       "       [    0.31875,     0.95954],\n",
       "       [    0.32188,     0.96316],\n",
       "       [      0.325,     0.96316],\n",
       "       [    0.32812,     0.96678],\n",
       "       [     0.3375,     0.96678],\n",
       "       [    0.34062,     0.97039],\n",
       "       [       0.35,     0.97039],\n",
       "       [    0.35313,     0.97401],\n",
       "       [     0.3625,     0.97401],\n",
       "       [    0.36562,     0.97763],\n",
       "       [    0.37187,     0.97763],\n",
       "       [      0.375,     0.98125],\n",
       "       [     0.3875,     0.98125],\n",
       "       [    0.39062,     0.98487],\n",
       "       [    0.40312,     0.98487],\n",
       "       [    0.40625,     0.98849],\n",
       "       [    0.42812,     0.98849],\n",
       "       [    0.43125,     0.99211],\n",
       "       [    0.45625,     0.99211],\n",
       "       [    0.45937,     0.99572],\n",
       "       [    0.53125,     0.99572],\n",
       "       [    0.53438,     0.99211],\n",
       "       [     0.5625,     0.99211],\n",
       "       [    0.56563,     0.98849],\n",
       "       [    0.58125,     0.98849],\n",
       "       [    0.58438,     0.98487],\n",
       "       [        0.6,     0.98487],\n",
       "       [    0.60312,     0.98125],\n",
       "       [    0.61563,     0.98125],\n",
       "       [    0.61875,     0.97763],\n",
       "       [    0.63125,     0.97763],\n",
       "       [    0.63437,     0.97401],\n",
       "       [    0.64688,     0.97401],\n",
       "       [       0.65,     0.97039],\n",
       "       [    0.65938,     0.97039],\n",
       "       [     0.6625,     0.96678],\n",
       "       [    0.66875,     0.96678],\n",
       "       [    0.67188,     0.96316],\n",
       "       [    0.67813,     0.96316],\n",
       "       [    0.68125,     0.95954],\n",
       "       [     0.6875,     0.95954],\n",
       "       [    0.69063,     0.95592],\n",
       "       [    0.69687,     0.95592],\n",
       "       [        0.7,      0.9523],\n",
       "       [    0.70625,      0.9523],\n",
       "       [    0.70938,     0.94868],\n",
       "       [     0.7125,     0.94868],\n",
       "       [    0.71562,     0.94507],\n",
       "       [    0.71875,     0.94507],\n",
       "       [    0.72188,     0.94145],\n",
       "       [      0.725,     0.94145],\n",
       "       [    0.72812,     0.93783],\n",
       "       [    0.73125,     0.93783],\n",
       "       [    0.73438,     0.93421],\n",
       "       [     0.7375,     0.93421],\n",
       "       [    0.74375,     0.92697],\n",
       "       [    0.74687,     0.92697],\n",
       "       [       0.75,     0.92336],\n",
       "       [    0.75625,     0.92336],\n",
       "       [    0.75937,     0.91974],\n",
       "       [     0.7625,     0.91974],\n",
       "       [    0.76875,      0.9125],\n",
       "       [    0.77188,      0.9125],\n",
       "       [      0.775,     0.90888],\n",
       "       [    0.77812,     0.90888],\n",
       "       [    0.78125,     0.90526],\n",
       "       [    0.78438,     0.90526],\n",
       "       [     0.7875,     0.90164],\n",
       "       [    0.79062,     0.90164],\n",
       "       [    0.79375,     0.89803],\n",
       "       [    0.79688,     0.89803],\n",
       "       [        0.8,     0.89441],\n",
       "       [    0.80313,     0.89441],\n",
       "       [    0.80625,     0.89079],\n",
       "       [    0.80937,     0.89079],\n",
       "       [    0.81563,     0.88355],\n",
       "       [    0.81875,     0.88355],\n",
       "       [    0.82812,      0.8727],\n",
       "       [    0.83125,      0.8727],\n",
       "       [     0.8375,     0.86546],\n",
       "       [    0.84062,     0.86546],\n",
       "       [       0.85,     0.85461],\n",
       "       [    0.85312,     0.85461],\n",
       "       [    0.87813,     0.82566],\n",
       "       [    0.88125,     0.82566],\n",
       "       [    0.90938,     0.79309],\n",
       "       [    0.90938,     0.78947],\n",
       "       [    0.92188,       0.775],\n",
       "       [    0.92188,     0.77138],\n",
       "       [    0.92813,     0.76414],\n",
       "       [    0.92813,     0.76053],\n",
       "       [    0.93125,     0.75691],\n",
       "       [    0.93125,     0.75329],\n",
       "       [     0.9375,     0.74605],\n",
       "       [     0.9375,     0.74243],\n",
       "       [    0.94375,      0.7352],\n",
       "       [    0.94375,     0.73158],\n",
       "       [    0.94687,     0.72796],\n",
       "       [    0.94687,     0.72434],\n",
       "       [    0.95312,     0.71711],\n",
       "       [    0.95312,     0.71349],\n",
       "       [    0.95938,     0.70625],\n",
       "       [    0.95938,     0.70263],\n",
       "       [    0.96562,     0.69539],\n",
       "       [    0.96562,     0.69178],\n",
       "       [    0.96875,     0.68816],\n",
       "       [    0.96875,     0.68454],\n",
       "       [      0.975,      0.6773],\n",
       "       [      0.975,     0.67368],\n",
       "       [    0.97812,     0.67007],\n",
       "       [    0.97812,     0.66645],\n",
       "       [    0.98125,     0.66283],\n",
       "       [    0.98125,     0.65559],\n",
       "       [    0.98438,     0.65197],\n",
       "       [    0.98438,     0.64474],\n",
       "       [     0.9875,     0.64112],\n",
       "       [     0.9875,     0.63388],\n",
       "       [    0.99063,     0.63026],\n",
       "       [    0.99063,     0.62664],\n",
       "       [    0.99375,     0.62303],\n",
       "       [    0.99687,     0.62303],\n",
       "       [    0.99687,     0.40592],\n",
       "       [    0.99375,     0.40592],\n",
       "       [    0.99063,      0.4023],\n",
       "       [    0.99063,     0.39507],\n",
       "       [     0.9875,     0.39145],\n",
       "       [     0.9875,     0.37697],\n",
       "       [    0.98438,     0.37336],\n",
       "       [    0.98438,      0.3625],\n",
       "       [    0.98125,     0.35888],\n",
       "       [    0.98125,     0.35164],\n",
       "       [    0.97812,     0.34803],\n",
       "       [    0.97812,     0.34079],\n",
       "       [      0.975,     0.33717],\n",
       "       [      0.975,     0.33355],\n",
       "       [    0.97188,     0.32993],\n",
       "       [    0.97188,     0.32632],\n",
       "       [    0.96875,      0.3227],\n",
       "       [    0.96875,     0.31546],\n",
       "       [    0.96562,     0.31184],\n",
       "       [    0.96562,     0.30822],\n",
       "       [     0.9625,     0.30461],\n",
       "       [     0.9625,     0.30099],\n",
       "       [    0.95938,     0.29737],\n",
       "       [    0.95938,     0.29375],\n",
       "       [    0.95625,     0.29013],\n",
       "       [    0.95625,     0.28651],\n",
       "       [    0.95312,     0.28289],\n",
       "       [    0.95312,     0.27928],\n",
       "       [       0.95,     0.27566],\n",
       "       [       0.95,     0.27204],\n",
       "       [    0.94375,      0.2648],\n",
       "       [    0.94375,     0.26118],\n",
       "       [    0.93437,     0.25033],\n",
       "       [    0.93437,     0.24671],\n",
       "       [      0.925,     0.23586],\n",
       "       [      0.925,     0.23224],\n",
       "       [    0.87813,     0.17796],\n",
       "       [    0.87813,     0.17434],\n",
       "       [    0.86563,     0.15987],\n",
       "       [     0.8625,     0.15987],\n",
       "       [    0.84688,     0.14178],\n",
       "       [    0.84375,     0.14178],\n",
       "       [    0.82812,     0.12368],\n",
       "       [      0.825,     0.12368],\n",
       "       [    0.81563,     0.11283],\n",
       "       [     0.8125,     0.11283],\n",
       "       [    0.80313,     0.10197],\n",
       "       [        0.8,     0.10197],\n",
       "       [    0.79375,    0.094737],\n",
       "       [    0.79062,    0.094737],\n",
       "       [    0.78438,      0.0875],\n",
       "       [    0.78125,      0.0875],\n",
       "       [    0.77812,    0.083882],\n",
       "       [      0.775,    0.083882],\n",
       "       [    0.76875,    0.076645],\n",
       "       [    0.76562,    0.076645],\n",
       "       [     0.7625,    0.073026],\n",
       "       [    0.75937,    0.073026],\n",
       "       [    0.75625,    0.069408],\n",
       "       [    0.75313,    0.069408],\n",
       "       [       0.75,    0.065789],\n",
       "       [    0.74375,    0.065789],\n",
       "       [    0.74063,    0.062171],\n",
       "       [     0.7375,    0.062171],\n",
       "       [    0.73438,    0.058553],\n",
       "       [    0.73125,    0.058553],\n",
       "       [    0.72812,    0.054934],\n",
       "       [      0.725,    0.054934],\n",
       "       [    0.71875,    0.047697],\n",
       "       [    0.71562,    0.047697],\n",
       "       [     0.7125,    0.044079],\n",
       "       [    0.70938,    0.044079],\n",
       "       [    0.70625,    0.040461],\n",
       "       [        0.7,    0.040461],\n",
       "       [    0.69687,    0.036842],\n",
       "       [    0.69375,    0.036842],\n",
       "       [    0.69063,    0.033224],\n",
       "       [    0.68437,    0.033224],\n",
       "       [    0.68125,    0.029605],\n",
       "       [    0.67813,    0.029605],\n",
       "       [      0.675,    0.025987],\n",
       "       [    0.66875,    0.025987],\n",
       "       [    0.66562,    0.022368],\n",
       "       [     0.6625,    0.022368],\n",
       "       [    0.65938,     0.01875],\n",
       "       [       0.65,     0.01875],\n",
       "       [    0.64375,    0.011513],\n",
       "       [    0.64375,  0.00065789]], dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_seg[0].masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([0.])\n",
       "conf: tensor([0.9805])\n",
       "data: tensor([[  2.4138,   1.0381, 218.7887, 189.7487,   0.9805,   0.0000]])\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (190, 220)\n",
       "shape: torch.Size([1, 6])\n",
       "xywh: tensor([[110.6013,  95.3934, 216.3749, 188.7106]])\n",
       "xywhn: tensor([[0.5027, 0.5021, 0.9835, 0.9932]])\n",
       "xyxy: tensor([[  2.4138,   1.0381, 218.7887, 189.7487]])\n",
       "xyxyn: tensor([[0.0110, 0.0055, 0.9945, 0.9987]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_seg[0].boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_prediction_on_frame(frame, results):\n",
    "    \"\"\"\n",
    "    Draw the prediction result on the frame.\n",
    "    \"\"\"\n",
    "    for box in results[0].boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0]  # Get box coordinates\n",
    "        label = box.cls[0]  # Get class label (if available)\n",
    "        conf = box.conf[0]  # Confidence score\n",
    "        conf_rounded = np.round(conf.numpy(), 2) if hasattr(conf, 'numpy') else np.round(conf, 2)\n",
    "    \n",
    "        # Convert confidence to string for OpenCV to display\n",
    "        conf_str = str(conf_rounded)\n",
    "\n",
    "        # Draw the bounding box on the image\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, conf_str, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    return frame\n",
    "\n",
    "def process_video(model, video_path, output_video_path):\n",
    "    \"\"\"\n",
    "    Process a single video and save the output with predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Trained model for prediction.\n",
    "    - video_path: Path to the input video.\n",
    "    - output_video_path: Path to save the output video.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Create VideoWriter to save output video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Preprocess the frame for the model\n",
    "        #processed_frame = preprocess_frame(frame)\n",
    "\n",
    "        # Predict using the model\n",
    "        results = model.predict(frame, conf=0.0)\n",
    "\n",
    "        # Draw the prediction on the frame\n",
    "        frame_with_prediction = draw_prediction_on_frame(frame, results)\n",
    "\n",
    "        # Write the processed frame to the output video\n",
    "        out.write(frame_with_prediction)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Processed video saved to {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 15 potatos, 80.8ms\n",
      "Speed: 6.7ms preprocess, 80.8ms inference, 20.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 54.0ms\n",
      "Speed: 2.3ms preprocess, 54.0ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 44.8ms\n",
      "Speed: 2.0ms preprocess, 44.8ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 potatos, 44.8ms\n",
      "Speed: 1.5ms preprocess, 44.8ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 44.1ms\n",
      "Speed: 1.6ms preprocess, 44.1ms inference, 17.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 65.6ms\n",
      "Speed: 3.4ms preprocess, 65.6ms inference, 18.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 29 potatos, 59.6ms\n",
      "Speed: 2.2ms preprocess, 59.6ms inference, 22.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 29 potatos, 42.6ms\n",
      "Speed: 2.2ms preprocess, 42.6ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 58.0ms\n",
      "Speed: 1.6ms preprocess, 58.0ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 45.6ms\n",
      "Speed: 1.8ms preprocess, 45.6ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 44.0ms\n",
      "Speed: 1.7ms preprocess, 44.0ms inference, 18.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 43.6ms\n",
      "Speed: 1.5ms preprocess, 43.6ms inference, 19.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 42.2ms\n",
      "Speed: 2.1ms preprocess, 42.2ms inference, 17.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 42.3ms\n",
      "Speed: 1.6ms preprocess, 42.3ms inference, 18.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 43.3ms\n",
      "Speed: 1.7ms preprocess, 43.3ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 190.9ms\n",
      "Speed: 3.0ms preprocess, 190.9ms inference, 51.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 58.7ms\n",
      "Speed: 2.0ms preprocess, 58.7ms inference, 18.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 64.2ms\n",
      "Speed: 2.3ms preprocess, 64.2ms inference, 18.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 68.9ms\n",
      "Speed: 1.8ms preprocess, 68.9ms inference, 19.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 potatos, 49.3ms\n",
      "Speed: 1.6ms preprocess, 49.3ms inference, 19.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 51.4ms\n",
      "Speed: 5.0ms preprocess, 51.4ms inference, 20.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 61.0ms\n",
      "Speed: 1.8ms preprocess, 61.0ms inference, 18.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 48.2ms\n",
      "Speed: 1.8ms preprocess, 48.2ms inference, 18.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 43.8ms\n",
      "Speed: 2.0ms preprocess, 43.8ms inference, 19.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 potatos, 61.8ms\n",
      "Speed: 1.8ms preprocess, 61.8ms inference, 18.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 51.0ms\n",
      "Speed: 2.0ms preprocess, 51.0ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 60.4ms\n",
      "Speed: 2.4ms preprocess, 60.4ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 53.6ms\n",
      "Speed: 2.4ms preprocess, 53.6ms inference, 18.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 59.4ms\n",
      "Speed: 1.6ms preprocess, 59.4ms inference, 17.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 28 potatos, 49.6ms\n",
      "Speed: 2.5ms preprocess, 49.6ms inference, 19.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 28 potatos, 51.4ms\n",
      "Speed: 2.1ms preprocess, 51.4ms inference, 18.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 28 potatos, 54.6ms\n",
      "Speed: 1.8ms preprocess, 54.6ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 29 potatos, 43.1ms\n",
      "Speed: 1.5ms preprocess, 43.1ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 39.0ms\n",
      "Speed: 2.8ms preprocess, 39.0ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 62.5ms\n",
      "Speed: 2.1ms preprocess, 62.5ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 57.2ms\n",
      "Speed: 1.6ms preprocess, 57.2ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 55.7ms\n",
      "Speed: 1.6ms preprocess, 55.7ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 49.2ms\n",
      "Speed: 1.5ms preprocess, 49.2ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 43.1ms\n",
      "Speed: 1.6ms preprocess, 43.1ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 47.8ms\n",
      "Speed: 1.5ms preprocess, 47.8ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 51.2ms\n",
      "Speed: 4.0ms preprocess, 51.2ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 potatos, 50.2ms\n",
      "Speed: 4.6ms preprocess, 50.2ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 29 potatos, 39.7ms\n",
      "Speed: 4.7ms preprocess, 39.7ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 44.1ms\n",
      "Speed: 1.9ms preprocess, 44.1ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 29 potatos, 49.7ms\n",
      "Speed: 1.6ms preprocess, 49.7ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 28 potatos, 44.6ms\n",
      "Speed: 1.7ms preprocess, 44.6ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 46.2ms\n",
      "Speed: 1.6ms preprocess, 46.2ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 50.9ms\n",
      "Speed: 1.7ms preprocess, 50.9ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 48.4ms\n",
      "Speed: 1.8ms preprocess, 48.4ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 44.2ms\n",
      "Speed: 1.5ms preprocess, 44.2ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 41.3ms\n",
      "Speed: 1.7ms preprocess, 41.3ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 41.2ms\n",
      "Speed: 4.1ms preprocess, 41.2ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 potatos, 42.4ms\n",
      "Speed: 1.6ms preprocess, 42.4ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 28 potatos, 54.3ms\n",
      "Speed: 3.3ms preprocess, 54.3ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 50.0ms\n",
      "Speed: 2.4ms preprocess, 50.0ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 48.9ms\n",
      "Speed: 1.5ms preprocess, 48.9ms inference, 17.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 44.4ms\n",
      "Speed: 1.7ms preprocess, 44.4ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 44.2ms\n",
      "Speed: 1.5ms preprocess, 44.2ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 43.2ms\n",
      "Speed: 3.4ms preprocess, 43.2ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 potatos, 45.3ms\n",
      "Speed: 1.6ms preprocess, 45.3ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 potatos, 48.7ms\n",
      "Speed: 1.5ms preprocess, 48.7ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 29 potatos, 46.5ms\n",
      "Speed: 1.8ms preprocess, 46.5ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 49.2ms\n",
      "Speed: 1.6ms preprocess, 49.2ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 29 potatos, 44.1ms\n",
      "Speed: 1.4ms preprocess, 44.1ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 49.2ms\n",
      "Speed: 1.6ms preprocess, 49.2ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 44.5ms\n",
      "Speed: 1.5ms preprocess, 44.5ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 43.9ms\n",
      "Speed: 2.0ms preprocess, 43.9ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 43.3ms\n",
      "Speed: 1.5ms preprocess, 43.3ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 29 potatos, 54.4ms\n",
      "Speed: 1.7ms preprocess, 54.4ms inference, 17.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 45.1ms\n",
      "Speed: 1.6ms preprocess, 45.1ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 potatos, 48.6ms\n",
      "Speed: 1.6ms preprocess, 48.6ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 41.2ms\n",
      "Speed: 1.5ms preprocess, 41.2ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 potatos, 51.4ms\n",
      "Speed: 1.5ms preprocess, 51.4ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 potatos, 48.4ms\n",
      "Speed: 1.8ms preprocess, 48.4ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 38 potatos, 43.1ms\n",
      "Speed: 1.6ms preprocess, 43.1ms inference, 18.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 43.1ms\n",
      "Speed: 1.5ms preprocess, 43.1ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 38 potatos, 40.3ms\n",
      "Speed: 1.6ms preprocess, 40.3ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 40 potatos, 47.7ms\n",
      "Speed: 1.8ms preprocess, 47.7ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 46.1ms\n",
      "Speed: 1.6ms preprocess, 46.1ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 47.2ms\n",
      "Speed: 1.6ms preprocess, 47.2ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 46.8ms\n",
      "Speed: 1.6ms preprocess, 46.8ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 47.4ms\n",
      "Speed: 1.5ms preprocess, 47.4ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 51.6ms\n",
      "Speed: 1.5ms preprocess, 51.6ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 43.8ms\n",
      "Speed: 1.5ms preprocess, 43.8ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 48.0ms\n",
      "Speed: 1.7ms preprocess, 48.0ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 46.9ms\n",
      "Speed: 1.5ms preprocess, 46.9ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 49 potatos, 59.5ms\n",
      "Speed: 1.6ms preprocess, 59.5ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 43.3ms\n",
      "Speed: 4.9ms preprocess, 43.3ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 48.8ms\n",
      "Speed: 1.8ms preprocess, 48.8ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 42.5ms\n",
      "Speed: 1.6ms preprocess, 42.5ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 49.1ms\n",
      "Speed: 1.8ms preprocess, 49.1ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 48.6ms\n",
      "Speed: 1.5ms preprocess, 48.6ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 50.4ms\n",
      "Speed: 1.7ms preprocess, 50.4ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 43.3ms\n",
      "Speed: 1.6ms preprocess, 43.3ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 48.2ms\n",
      "Speed: 1.5ms preprocess, 48.2ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 53.2ms\n",
      "Speed: 1.8ms preprocess, 53.2ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 46.5ms\n",
      "Speed: 1.5ms preprocess, 46.5ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 47.9ms\n",
      "Speed: 1.6ms preprocess, 47.9ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 55.6ms\n",
      "Speed: 2.6ms preprocess, 55.6ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 53.8ms\n",
      "Speed: 1.6ms preprocess, 53.8ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 46.1ms\n",
      "Speed: 1.7ms preprocess, 46.1ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 46.0ms\n",
      "Speed: 1.6ms preprocess, 46.0ms inference, 18.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 42.5ms\n",
      "Speed: 1.8ms preprocess, 42.5ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 40 potatos, 52.2ms\n",
      "Speed: 1.6ms preprocess, 52.2ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 45.0ms\n",
      "Speed: 1.5ms preprocess, 45.0ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 43.0ms\n",
      "Speed: 1.6ms preprocess, 43.0ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 47.1ms\n",
      "Speed: 1.7ms preprocess, 47.1ms inference, 19.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 42.7ms\n",
      "Speed: 1.5ms preprocess, 42.7ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 50.7ms\n",
      "Speed: 1.5ms preprocess, 50.7ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 46.6ms\n",
      "Speed: 1.6ms preprocess, 46.6ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 46.1ms\n",
      "Speed: 1.6ms preprocess, 46.1ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 49 potatos, 50.4ms\n",
      "Speed: 1.9ms preprocess, 50.4ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 50 potatos, 51.0ms\n",
      "Speed: 1.6ms preprocess, 51.0ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 52 potatos, 55.3ms\n",
      "Speed: 2.5ms preprocess, 55.3ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 52 potatos, 42.3ms\n",
      "Speed: 1.6ms preprocess, 42.3ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 52 potatos, 43.9ms\n",
      "Speed: 1.5ms preprocess, 43.9ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 54 potatos, 47.8ms\n",
      "Speed: 1.7ms preprocess, 47.8ms inference, 20.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 54 potatos, 44.0ms\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 51 potatos, 45.4ms\n",
      "Speed: 1.8ms preprocess, 45.4ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 51 potatos, 52.1ms\n",
      "Speed: 2.1ms preprocess, 52.1ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 51 potatos, 45.6ms\n",
      "Speed: 7.4ms preprocess, 45.6ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 50 potatos, 44.2ms\n",
      "Speed: 1.6ms preprocess, 44.2ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 55 potatos, 42.2ms\n",
      "Speed: 1.8ms preprocess, 42.2ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 52 potatos, 46.2ms\n",
      "Speed: 1.7ms preprocess, 46.2ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 52 potatos, 44.0ms\n",
      "Speed: 1.6ms preprocess, 44.0ms inference, 18.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 52 potatos, 45.6ms\n",
      "Speed: 1.6ms preprocess, 45.6ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 53 potatos, 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 54 potatos, 44.8ms\n",
      "Speed: 1.6ms preprocess, 44.8ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 53 potatos, 48.4ms\n",
      "Speed: 1.6ms preprocess, 48.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 55 potatos, 41.0ms\n",
      "Speed: 1.5ms preprocess, 41.0ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 60 potatos, 46.6ms\n",
      "Speed: 1.5ms preprocess, 46.6ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 56 potatos, 43.8ms\n",
      "Speed: 1.8ms preprocess, 43.8ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 56 potatos, 44.6ms\n",
      "Speed: 1.8ms preprocess, 44.6ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 54 potatos, 53.3ms\n",
      "Speed: 2.2ms preprocess, 53.3ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 55 potatos, 42.4ms\n",
      "Speed: 2.6ms preprocess, 42.4ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 53 potatos, 46.5ms\n",
      "Speed: 1.5ms preprocess, 46.5ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 53 potatos, 45.6ms\n",
      "Speed: 1.6ms preprocess, 45.6ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 53 potatos, 47.6ms\n",
      "Speed: 1.7ms preprocess, 47.6ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 50 potatos, 42.8ms\n",
      "Speed: 2.8ms preprocess, 42.8ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 50 potatos, 44.4ms\n",
      "Speed: 1.6ms preprocess, 44.4ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 51 potatos, 45.8ms\n",
      "Speed: 1.6ms preprocess, 45.8ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 52 potatos, 45.6ms\n",
      "Speed: 1.8ms preprocess, 45.6ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 53 potatos, 48.2ms\n",
      "Speed: 1.6ms preprocess, 48.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 53 potatos, 47.1ms\n",
      "Speed: 1.5ms preprocess, 47.1ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 52 potatos, 57.4ms\n",
      "Speed: 1.8ms preprocess, 57.4ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 53 potatos, 47.6ms\n",
      "Speed: 1.5ms preprocess, 47.6ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 51 potatos, 51.8ms\n",
      "Speed: 1.5ms preprocess, 51.8ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 50 potatos, 41.1ms\n",
      "Speed: 1.6ms preprocess, 41.1ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 55 potatos, 40.8ms\n",
      "Speed: 1.4ms preprocess, 40.8ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 51 potatos, 45.8ms\n",
      "Speed: 1.6ms preprocess, 45.8ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 50 potatos, 42.3ms\n",
      "Speed: 1.5ms preprocess, 42.3ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 49 potatos, 56.7ms\n",
      "Speed: 1.8ms preprocess, 56.7ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 44.0ms\n",
      "Speed: 1.6ms preprocess, 44.0ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 47.7ms\n",
      "Speed: 1.8ms preprocess, 47.7ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 50 potatos, 49.2ms\n",
      "Speed: 1.5ms preprocess, 49.2ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 51 potatos, 55.7ms\n",
      "Speed: 1.6ms preprocess, 55.7ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 42.7ms\n",
      "Speed: 3.6ms preprocess, 42.7ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 45.0ms\n",
      "Speed: 1.5ms preprocess, 45.0ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 50.8ms\n",
      "Speed: 1.7ms preprocess, 50.8ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 51.7ms\n",
      "Speed: 1.6ms preprocess, 51.7ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 47.8ms\n",
      "Speed: 2.4ms preprocess, 47.8ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 49.3ms\n",
      "Speed: 1.5ms preprocess, 49.3ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 46.8ms\n",
      "Speed: 3.8ms preprocess, 46.8ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 51.5ms\n",
      "Speed: 11.3ms preprocess, 51.5ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 41.9ms\n",
      "Speed: 1.7ms preprocess, 41.9ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 45.6ms\n",
      "Speed: 1.8ms preprocess, 45.6ms inference, 18.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 50.7ms\n",
      "Speed: 1.6ms preprocess, 50.7ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 52.9ms\n",
      "Speed: 1.5ms preprocess, 52.9ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 48.5ms\n",
      "Speed: 1.8ms preprocess, 48.5ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 50.7ms\n",
      "Speed: 1.6ms preprocess, 50.7ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 44.8ms\n",
      "Speed: 1.6ms preprocess, 44.8ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 45.7ms\n",
      "Speed: 1.4ms preprocess, 45.7ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 48.0ms\n",
      "Speed: 1.5ms preprocess, 48.0ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 48.8ms\n",
      "Speed: 1.6ms preprocess, 48.8ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 45.6ms\n",
      "Speed: 1.6ms preprocess, 45.6ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 56.5ms\n",
      "Speed: 1.5ms preprocess, 56.5ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 44.0ms\n",
      "Speed: 1.4ms preprocess, 44.0ms inference, 22.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 58.4ms\n",
      "Speed: 1.8ms preprocess, 58.4ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 40 potatos, 41.7ms\n",
      "Speed: 2.2ms preprocess, 41.7ms inference, 17.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 45.5ms\n",
      "Speed: 1.5ms preprocess, 45.5ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 67.8ms\n",
      "Speed: 2.2ms preprocess, 67.8ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 46.8ms\n",
      "Speed: 1.7ms preprocess, 46.8ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 46.6ms\n",
      "Speed: 1.9ms preprocess, 46.6ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 48.7ms\n",
      "Speed: 2.3ms preprocess, 48.7ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 47.1ms\n",
      "Speed: 4.9ms preprocess, 47.1ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 45.8ms\n",
      "Speed: 1.6ms preprocess, 45.8ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 potatos, 43.1ms\n",
      "Speed: 3.2ms preprocess, 43.1ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 potatos, 58.1ms\n",
      "Speed: 1.6ms preprocess, 58.1ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 38 potatos, 51.3ms\n",
      "Speed: 2.1ms preprocess, 51.3ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 potatos, 45.2ms\n",
      "Speed: 1.7ms preprocess, 45.2ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 38 potatos, 60.3ms\n",
      "Speed: 1.6ms preprocess, 60.3ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 47.3ms\n",
      "Speed: 1.6ms preprocess, 47.3ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 potatos, 45.1ms\n",
      "Speed: 7.7ms preprocess, 45.1ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 41.2ms\n",
      "Speed: 1.6ms preprocess, 41.2ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 potatos, 46.5ms\n",
      "Speed: 1.5ms preprocess, 46.5ms inference, 28.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 potatos, 51.3ms\n",
      "Speed: 1.6ms preprocess, 51.3ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 potatos, 42.5ms\n",
      "Speed: 1.5ms preprocess, 42.5ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 45.9ms\n",
      "Speed: 2.0ms preprocess, 45.9ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 potatos, 45.4ms\n",
      "Speed: 1.8ms preprocess, 45.4ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 38 potatos, 47.4ms\n",
      "Speed: 1.6ms preprocess, 47.4ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 42.2ms\n",
      "Speed: 1.6ms preprocess, 42.2ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 38 potatos, 44.4ms\n",
      "Speed: 1.7ms preprocess, 44.4ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 potatos, 41.8ms\n",
      "Speed: 1.5ms preprocess, 41.8ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 45.4ms\n",
      "Speed: 2.6ms preprocess, 45.4ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 38 potatos, 47.4ms\n",
      "Speed: 1.5ms preprocess, 47.4ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 38 potatos, 40.4ms\n",
      "Speed: 1.7ms preprocess, 40.4ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 47.6ms\n",
      "Speed: 1.6ms preprocess, 47.6ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 48.2ms\n",
      "Speed: 2.9ms preprocess, 48.2ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 56.6ms\n",
      "Speed: 1.6ms preprocess, 56.6ms inference, 17.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 42.0ms\n",
      "Speed: 2.4ms preprocess, 42.0ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 39.0ms\n",
      "Speed: 1.7ms preprocess, 39.0ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 47.5ms\n",
      "Speed: 1.4ms preprocess, 47.5ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 60.0ms\n",
      "Speed: 1.4ms preprocess, 60.0ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 41.0ms\n",
      "Speed: 1.8ms preprocess, 41.0ms inference, 19.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 40 potatos, 45.5ms\n",
      "Speed: 1.6ms preprocess, 45.5ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 potatos, 44.6ms\n",
      "Speed: 1.5ms preprocess, 44.6ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 38 potatos, 60.4ms\n",
      "Speed: 4.9ms preprocess, 60.4ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 38 potatos, 45.5ms\n",
      "Speed: 1.9ms preprocess, 45.5ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 40 potatos, 49.7ms\n",
      "Speed: 1.5ms preprocess, 49.7ms inference, 18.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 51.0ms\n",
      "Speed: 1.9ms preprocess, 51.0ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 49.5ms\n",
      "Speed: 1.6ms preprocess, 49.5ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 40 potatos, 45.6ms\n",
      "Speed: 1.7ms preprocess, 45.6ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 40.0ms\n",
      "Speed: 5.0ms preprocess, 40.0ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 43.8ms\n",
      "Speed: 1.7ms preprocess, 43.8ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 40 potatos, 52.9ms\n",
      "Speed: 1.8ms preprocess, 52.9ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 49.2ms\n",
      "Speed: 2.0ms preprocess, 49.2ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 51.3ms\n",
      "Speed: 1.7ms preprocess, 51.3ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 38.8ms\n",
      "Speed: 1.5ms preprocess, 38.8ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 49.2ms\n",
      "Speed: 1.7ms preprocess, 49.2ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 51 potatos, 44.3ms\n",
      "Speed: 1.5ms preprocess, 44.3ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 50 potatos, 44.9ms\n",
      "Speed: 1.5ms preprocess, 44.9ms inference, 19.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 63.1ms\n",
      "Speed: 1.5ms preprocess, 63.1ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 41.4ms\n",
      "Speed: 1.7ms preprocess, 41.4ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 47.9ms\n",
      "Speed: 1.8ms preprocess, 47.9ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 51.2ms\n",
      "Speed: 1.9ms preprocess, 51.2ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 62.2ms\n",
      "Speed: 2.0ms preprocess, 62.2ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 45.8ms\n",
      "Speed: 2.1ms preprocess, 45.8ms inference, 22.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 48.9ms\n",
      "Speed: 1.7ms preprocess, 48.9ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 49.7ms\n",
      "Speed: 1.5ms preprocess, 49.7ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 51.4ms\n",
      "Speed: 1.9ms preprocess, 51.4ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 53.1ms\n",
      "Speed: 1.9ms preprocess, 53.1ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 48.9ms\n",
      "Speed: 1.7ms preprocess, 48.9ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 49.5ms\n",
      "Speed: 1.5ms preprocess, 49.5ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 47.3ms\n",
      "Speed: 1.5ms preprocess, 47.3ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 40.3ms\n",
      "Speed: 1.4ms preprocess, 40.3ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 48.0ms\n",
      "Speed: 1.4ms preprocess, 48.0ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 45.5ms\n",
      "Speed: 1.5ms preprocess, 45.5ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 53.4ms\n",
      "Speed: 1.5ms preprocess, 53.4ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 45.6ms\n",
      "Speed: 1.7ms preprocess, 45.6ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 45.2ms\n",
      "Speed: 1.6ms preprocess, 45.2ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 42.6ms\n",
      "Speed: 1.6ms preprocess, 42.6ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 43.8ms\n",
      "Speed: 2.0ms preprocess, 43.8ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 49.2ms\n",
      "Speed: 1.6ms preprocess, 49.2ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 50.6ms\n",
      "Speed: 1.5ms preprocess, 50.6ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 60.0ms\n",
      "Speed: 1.8ms preprocess, 60.0ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 55.8ms\n",
      "Speed: 1.8ms preprocess, 55.8ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 44.7ms\n",
      "Speed: 1.9ms preprocess, 44.7ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 40 potatos, 46.5ms\n",
      "Speed: 2.0ms preprocess, 46.5ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 43.6ms\n",
      "Speed: 1.5ms preprocess, 43.6ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 47.4ms\n",
      "Speed: 1.6ms preprocess, 47.4ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 40.7ms\n",
      "Speed: 3.4ms preprocess, 40.7ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 43.0ms\n",
      "Speed: 1.4ms preprocess, 43.0ms inference, 19.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 49.6ms\n",
      "Speed: 1.8ms preprocess, 49.6ms inference, 20.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 55.9ms\n",
      "Speed: 1.7ms preprocess, 55.9ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 56.6ms\n",
      "Speed: 1.6ms preprocess, 56.6ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 51.3ms\n",
      "Speed: 1.6ms preprocess, 51.3ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 42.4ms\n",
      "Speed: 1.6ms preprocess, 42.4ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 46.3ms\n",
      "Speed: 1.5ms preprocess, 46.3ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 48.6ms\n",
      "Speed: 1.6ms preprocess, 48.6ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 49.4ms\n",
      "Speed: 1.9ms preprocess, 49.4ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 45.6ms\n",
      "Speed: 1.6ms preprocess, 45.6ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 41.0ms\n",
      "Speed: 1.7ms preprocess, 41.0ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 50.0ms\n",
      "Speed: 2.0ms preprocess, 50.0ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 47.5ms\n",
      "Speed: 1.5ms preprocess, 47.5ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 219.2ms\n",
      "Speed: 1.7ms preprocess, 219.2ms inference, 21.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 51.4ms\n",
      "Speed: 3.0ms preprocess, 51.4ms inference, 17.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 42.7ms\n",
      "Speed: 1.8ms preprocess, 42.7ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 54.3ms\n",
      "Speed: 1.6ms preprocess, 54.3ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 49 potatos, 49.6ms\n",
      "Speed: 1.5ms preprocess, 49.6ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 49 potatos, 44.7ms\n",
      "Speed: 5.4ms preprocess, 44.7ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 39.8ms\n",
      "Speed: 1.9ms preprocess, 39.8ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 50 potatos, 62.0ms\n",
      "Speed: 1.7ms preprocess, 62.0ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 53.7ms\n",
      "Speed: 1.9ms preprocess, 53.7ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 49 potatos, 47.1ms\n",
      "Speed: 1.6ms preprocess, 47.1ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 49 potatos, 46.4ms\n",
      "Speed: 5.7ms preprocess, 46.4ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 51 potatos, 47.9ms\n",
      "Speed: 1.6ms preprocess, 47.9ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 52 potatos, 55.0ms\n",
      "Speed: 1.5ms preprocess, 55.0ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 52 potatos, 44.8ms\n",
      "Speed: 1.5ms preprocess, 44.8ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 50 potatos, 51.7ms\n",
      "Speed: 1.6ms preprocess, 51.7ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 49 potatos, 44.7ms\n",
      "Speed: 2.7ms preprocess, 44.7ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 51 potatos, 51.0ms\n",
      "Speed: 1.8ms preprocess, 51.0ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 50 potatos, 54.1ms\n",
      "Speed: 1.7ms preprocess, 54.1ms inference, 19.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 45.2ms\n",
      "Speed: 1.7ms preprocess, 45.2ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 42.2ms\n",
      "Speed: 1.4ms preprocess, 42.2ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 43.2ms\n",
      "Speed: 1.5ms preprocess, 43.2ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 40.0ms\n",
      "Speed: 1.5ms preprocess, 40.0ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 42.1ms\n",
      "Speed: 1.7ms preprocess, 42.1ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 47.2ms\n",
      "Speed: 1.6ms preprocess, 47.2ms inference, 18.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 44.5ms\n",
      "Speed: 1.7ms preprocess, 44.5ms inference, 18.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 46.9ms\n",
      "Speed: 1.6ms preprocess, 46.9ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 44.5ms\n",
      "Speed: 1.4ms preprocess, 44.5ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 44.5ms\n",
      "Speed: 1.5ms preprocess, 44.5ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 47.0ms\n",
      "Speed: 3.8ms preprocess, 47.0ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 46.3ms\n",
      "Speed: 1.6ms preprocess, 46.3ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 46.5ms\n",
      "Speed: 1.5ms preprocess, 46.5ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 44.4ms\n",
      "Speed: 1.5ms preprocess, 44.4ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 40 potatos, 44.2ms\n",
      "Speed: 2.0ms preprocess, 44.2ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 40 potatos, 49.3ms\n",
      "Speed: 1.5ms preprocess, 49.3ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 45.5ms\n",
      "Speed: 1.5ms preprocess, 45.5ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 40 potatos, 42.0ms\n",
      "Speed: 3.0ms preprocess, 42.0ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 40 potatos, 60.0ms\n",
      "Speed: 1.6ms preprocess, 60.0ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 47.3ms\n",
      "Speed: 1.6ms preprocess, 47.3ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 45.0ms\n",
      "Speed: 1.6ms preprocess, 45.0ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 49.7ms\n",
      "Speed: 1.6ms preprocess, 49.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 52.3ms\n",
      "Speed: 1.6ms preprocess, 52.3ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 potatos, 49.5ms\n",
      "Speed: 1.7ms preprocess, 49.5ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 potatos, 43.2ms\n",
      "Speed: 1.6ms preprocess, 43.2ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 40.8ms\n",
      "Speed: 1.7ms preprocess, 40.8ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 potatos, 47.2ms\n",
      "Speed: 1.7ms preprocess, 47.2ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 potatos, 46.2ms\n",
      "Speed: 1.6ms preprocess, 46.2ms inference, 18.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 40 potatos, 52.5ms\n",
      "Speed: 1.7ms preprocess, 52.5ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 potatos, 53.3ms\n",
      "Speed: 1.9ms preprocess, 53.3ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 44.8ms\n",
      "Speed: 1.7ms preprocess, 44.8ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 46.5ms\n",
      "Speed: 1.5ms preprocess, 46.5ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 38 potatos, 51.7ms\n",
      "Speed: 1.6ms preprocess, 51.7ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 52.2ms\n",
      "Speed: 1.6ms preprocess, 52.2ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 47.9ms\n",
      "Speed: 1.7ms preprocess, 47.9ms inference, 18.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 potatos, 45.1ms\n",
      "Speed: 1.5ms preprocess, 45.1ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 potatos, 53.4ms\n",
      "Speed: 1.8ms preprocess, 53.4ms inference, 18.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 45.7ms\n",
      "Speed: 1.6ms preprocess, 45.7ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 39.7ms\n",
      "Speed: 1.8ms preprocess, 39.7ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 54.5ms\n",
      "Speed: 1.6ms preprocess, 54.5ms inference, 18.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 48.1ms\n",
      "Speed: 1.7ms preprocess, 48.1ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 50.0ms\n",
      "Speed: 1.6ms preprocess, 50.0ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 46.4ms\n",
      "Speed: 1.5ms preprocess, 46.4ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 52.2ms\n",
      "Speed: 1.8ms preprocess, 52.2ms inference, 17.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 46.9ms\n",
      "Speed: 1.8ms preprocess, 46.9ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 29 potatos, 46.2ms\n",
      "Speed: 1.6ms preprocess, 46.2ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 potatos, 48.0ms\n",
      "Speed: 1.6ms preprocess, 48.0ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 41.1ms\n",
      "Speed: 1.5ms preprocess, 41.1ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 45.2ms\n",
      "Speed: 1.6ms preprocess, 45.2ms inference, 18.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 47.5ms\n",
      "Speed: 1.5ms preprocess, 47.5ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 potatos, 49.8ms\n",
      "Speed: 1.9ms preprocess, 49.8ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 49.8ms\n",
      "Speed: 1.7ms preprocess, 49.8ms inference, 17.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 46.5ms\n",
      "Speed: 1.7ms preprocess, 46.5ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 potatos, 42.1ms\n",
      "Speed: 1.6ms preprocess, 42.1ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 45.3ms\n",
      "Speed: 1.7ms preprocess, 45.3ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 49.4ms\n",
      "Speed: 2.9ms preprocess, 49.4ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 potatos, 45.2ms\n",
      "Speed: 1.6ms preprocess, 45.2ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 potatos, 42.0ms\n",
      "Speed: 1.7ms preprocess, 42.0ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 potatos, 49.3ms\n",
      "Speed: 1.9ms preprocess, 49.3ms inference, 18.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 49.3ms\n",
      "Speed: 3.1ms preprocess, 49.3ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 potatos, 48.9ms\n",
      "Speed: 1.5ms preprocess, 48.9ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 53.1ms\n",
      "Speed: 1.5ms preprocess, 53.1ms inference, 18.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 47.3ms\n",
      "Speed: 1.8ms preprocess, 47.3ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 47.1ms\n",
      "Speed: 1.6ms preprocess, 47.1ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 28 potatos, 40.7ms\n",
      "Speed: 1.7ms preprocess, 40.7ms inference, 17.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 29 potatos, 48.0ms\n",
      "Speed: 1.6ms preprocess, 48.0ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 48.6ms\n",
      "Speed: 1.5ms preprocess, 48.6ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 43.1ms\n",
      "Speed: 1.4ms preprocess, 43.1ms inference, 20.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 57.0ms\n",
      "Speed: 4.2ms preprocess, 57.0ms inference, 18.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 52.7ms\n",
      "Speed: 2.7ms preprocess, 52.7ms inference, 18.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 47.9ms\n",
      "Speed: 1.9ms preprocess, 47.9ms inference, 19.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 53.5ms\n",
      "Speed: 1.6ms preprocess, 53.5ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 46.4ms\n",
      "Speed: 2.1ms preprocess, 46.4ms inference, 18.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 48.4ms\n",
      "Speed: 1.7ms preprocess, 48.4ms inference, 18.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 53.0ms\n",
      "Speed: 1.4ms preprocess, 53.0ms inference, 18.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 50.1ms\n",
      "Speed: 1.9ms preprocess, 50.1ms inference, 18.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 48.4ms\n",
      "Speed: 2.0ms preprocess, 48.4ms inference, 20.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 29 potatos, 50.1ms\n",
      "Speed: 2.3ms preprocess, 50.1ms inference, 17.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 potatos, 53.5ms\n",
      "Speed: 1.7ms preprocess, 53.5ms inference, 17.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 47.5ms\n",
      "Speed: 1.7ms preprocess, 47.5ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 56.0ms\n",
      "Speed: 1.8ms preprocess, 56.0ms inference, 17.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 47.1ms\n",
      "Speed: 1.7ms preprocess, 47.1ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 29 potatos, 65.2ms\n",
      "Speed: 1.7ms preprocess, 65.2ms inference, 18.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 51.3ms\n",
      "Speed: 1.5ms preprocess, 51.3ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 126.3ms\n",
      "Speed: 1.6ms preprocess, 126.3ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 43.3ms\n",
      "Speed: 1.7ms preprocess, 43.3ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 126.8ms\n",
      "Speed: 3.5ms preprocess, 126.8ms inference, 58.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 91.2ms\n",
      "Speed: 2.2ms preprocess, 91.2ms inference, 29.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 63.4ms\n",
      "Speed: 2.8ms preprocess, 63.4ms inference, 21.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 57.9ms\n",
      "Speed: 1.8ms preprocess, 57.9ms inference, 17.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 potatos, 49.5ms\n",
      "Speed: 1.6ms preprocess, 49.5ms inference, 21.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 potatos, 82.4ms\n",
      "Speed: 1.6ms preprocess, 82.4ms inference, 27.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 potatos, 46.4ms\n",
      "Speed: 1.6ms preprocess, 46.4ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 44.0ms\n",
      "Speed: 1.6ms preprocess, 44.0ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 potatos, 43.0ms\n",
      "Speed: 1.9ms preprocess, 43.0ms inference, 18.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 potatos, 50.4ms\n",
      "Speed: 1.9ms preprocess, 50.4ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 43.7ms\n",
      "Speed: 2.1ms preprocess, 43.7ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 potatos, 42.1ms\n",
      "Speed: 1.7ms preprocess, 42.1ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 38 potatos, 44.0ms\n",
      "Speed: 1.7ms preprocess, 44.0ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 38 potatos, 44.6ms\n",
      "Speed: 1.7ms preprocess, 44.6ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 potatos, 44.5ms\n",
      "Speed: 1.7ms preprocess, 44.5ms inference, 20.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 46.0ms\n",
      "Speed: 1.7ms preprocess, 46.0ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 potatos, 52.1ms\n",
      "Speed: 1.6ms preprocess, 52.1ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 potatos, 43.7ms\n",
      "Speed: 2.2ms preprocess, 43.7ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 potatos, 47.3ms\n",
      "Speed: 1.6ms preprocess, 47.3ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 44.1ms\n",
      "Speed: 1.6ms preprocess, 44.1ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 potatos, 47.1ms\n",
      "Speed: 1.6ms preprocess, 47.1ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 45.8ms\n",
      "Speed: 1.6ms preprocess, 45.8ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 44.2ms\n",
      "Speed: 2.2ms preprocess, 44.2ms inference, 17.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 potatos, 45.1ms\n",
      "Speed: 1.6ms preprocess, 45.1ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 potatos, 43.9ms\n",
      "Speed: 1.6ms preprocess, 43.9ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 potatos, 46.0ms\n",
      "Speed: 1.9ms preprocess, 46.0ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 47.3ms\n",
      "Speed: 1.6ms preprocess, 47.3ms inference, 19.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 72.2ms\n",
      "Speed: 4.9ms preprocess, 72.2ms inference, 44.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 50.8ms\n",
      "Speed: 2.1ms preprocess, 50.8ms inference, 17.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 potatos, 48.9ms\n",
      "Speed: 1.7ms preprocess, 48.9ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 46.8ms\n",
      "Speed: 1.8ms preprocess, 46.8ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 potatos, 42.9ms\n",
      "Speed: 1.6ms preprocess, 42.9ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 potatos, 41.7ms\n",
      "Speed: 1.7ms preprocess, 41.7ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 38 potatos, 44.2ms\n",
      "Speed: 1.6ms preprocess, 44.2ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 40.4ms\n",
      "Speed: 1.6ms preprocess, 40.4ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 40 potatos, 41.1ms\n",
      "Speed: 2.9ms preprocess, 41.1ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 45.3ms\n",
      "Speed: 2.1ms preprocess, 45.3ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 43.9ms\n",
      "Speed: 1.9ms preprocess, 43.9ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 50.0ms\n",
      "Speed: 1.5ms preprocess, 50.0ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 44.3ms\n",
      "Speed: 1.5ms preprocess, 44.3ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 46.1ms\n",
      "Speed: 1.6ms preprocess, 46.1ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 53.3ms\n",
      "Speed: 1.8ms preprocess, 53.3ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 44.9ms\n",
      "Speed: 1.8ms preprocess, 44.9ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 44.2ms\n",
      "Speed: 2.2ms preprocess, 44.2ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 50 potatos, 43.3ms\n",
      "Speed: 1.9ms preprocess, 43.3ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 43.8ms\n",
      "Speed: 1.6ms preprocess, 43.8ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 49 potatos, 42.5ms\n",
      "Speed: 2.7ms preprocess, 42.5ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 50 potatos, 43.7ms\n",
      "Speed: 1.6ms preprocess, 43.7ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 42.9ms\n",
      "Speed: 1.6ms preprocess, 42.9ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 47.3ms\n",
      "Speed: 1.8ms preprocess, 47.3ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 47.1ms\n",
      "Speed: 1.8ms preprocess, 47.1ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 45 potatos, 43.2ms\n",
      "Speed: 1.6ms preprocess, 43.2ms inference, 28.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 45.5ms\n",
      "Speed: 2.1ms preprocess, 45.5ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 79.4ms\n",
      "Speed: 3.8ms preprocess, 79.4ms inference, 17.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 60.8ms\n",
      "Speed: 1.7ms preprocess, 60.8ms inference, 20.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 70.0ms\n",
      "Speed: 3.1ms preprocess, 70.0ms inference, 17.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 44.4ms\n",
      "Speed: 1.6ms preprocess, 44.4ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 41.0ms\n",
      "Speed: 1.7ms preprocess, 41.0ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 48 potatos, 45.3ms\n",
      "Speed: 1.8ms preprocess, 45.3ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed video saved to test.mp4\n"
     ]
    }
   ],
   "source": [
    "process_video(model, path, 'test.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'videos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Open the video file\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m video_path = \u001b[43mvideos\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m      7\u001b[39m cap = cv2.VideoCapture(video_path)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Loop through the video frames\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'videos' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Open the video file\n",
    "video_path = videos[0]\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLO11 tracking on the frame, persisting tracks between frames\n",
    "        results = model.track(frame, persist=True)\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLO11 Tracking\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 71 potatos, 74.5ms\n",
      "Speed: 6.8ms preprocess, 74.5ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 66 potatos, 57.4ms\n",
      "Speed: 2.0ms preprocess, 57.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 68 potatos, 48.0ms\n",
      "Speed: 1.8ms preprocess, 48.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 66 potatos, 78.9ms\n",
      "Speed: 2.0ms preprocess, 78.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 67 potatos, 47.1ms\n",
      "Speed: 1.8ms preprocess, 47.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 63 potatos, 49.4ms\n",
      "Speed: 1.6ms preprocess, 49.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 61 potatos, 50.7ms\n",
      "Speed: 1.7ms preprocess, 50.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 62 potatos, 47.5ms\n",
      "Speed: 1.6ms preprocess, 47.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 63 potatos, 43.1ms\n",
      "Speed: 1.8ms preprocess, 43.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 62 potatos, 60.4ms\n",
      "Speed: 1.8ms preprocess, 60.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 62 potatos, 42.9ms\n",
      "Speed: 1.7ms preprocess, 42.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 61 potatos, 42.2ms\n",
      "Speed: 1.6ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 63 potatos, 47.2ms\n",
      "Speed: 1.6ms preprocess, 47.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 60 potatos, 43.8ms\n",
      "Speed: 1.5ms preprocess, 43.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 62 potatos, 41.7ms\n",
      "Speed: 1.7ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 60 potatos, 40.1ms\n",
      "Speed: 1.6ms preprocess, 40.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 59 potatos, 74.9ms\n",
      "Speed: 1.6ms preprocess, 74.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 59 potatos, 46.2ms\n",
      "Speed: 1.6ms preprocess, 46.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 60 potatos, 36.6ms\n",
      "Speed: 1.5ms preprocess, 36.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 62 potatos, 54.3ms\n",
      "Speed: 1.5ms preprocess, 54.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 59 potatos, 46.2ms\n",
      "Speed: 1.8ms preprocess, 46.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 60 potatos, 45.5ms\n",
      "Speed: 1.7ms preprocess, 45.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 59 potatos, 42.0ms\n",
      "Speed: 1.7ms preprocess, 42.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 56 potatos, 43.2ms\n",
      "Speed: 1.7ms preprocess, 43.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 59 potatos, 46.4ms\n",
      "Speed: 1.6ms preprocess, 46.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 58 potatos, 46.6ms\n",
      "Speed: 1.6ms preprocess, 46.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 56 potatos, 48.6ms\n",
      "Speed: 1.5ms preprocess, 48.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 55 potatos, 45.7ms\n",
      "Speed: 1.5ms preprocess, 45.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 55 potatos, 48.1ms\n",
      "Speed: 1.4ms preprocess, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 54 potatos, 45.5ms\n",
      "Speed: 1.8ms preprocess, 45.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 54 potatos, 42.3ms\n",
      "Speed: 1.8ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 52 potatos, 43.6ms\n",
      "Speed: 1.8ms preprocess, 43.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 51 potatos, 40.2ms\n",
      "Speed: 1.6ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 53 potatos, 46.9ms\n",
      "Speed: 1.7ms preprocess, 46.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 55 potatos, 45.0ms\n",
      "Speed: 1.5ms preprocess, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 53 potatos, 40.8ms\n",
      "Speed: 1.5ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 51 potatos, 40.0ms\n",
      "Speed: 1.6ms preprocess, 40.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 51 potatos, 42.0ms\n",
      "Speed: 1.5ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 39.8ms\n",
      "Speed: 1.4ms preprocess, 39.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 50 potatos, 39.4ms\n",
      "Speed: 1.5ms preprocess, 39.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 51 potatos, 42.8ms\n",
      "Speed: 1.6ms preprocess, 42.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 51 potatos, 41.8ms\n",
      "Speed: 1.7ms preprocess, 41.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 50 potatos, 53.1ms\n",
      "Speed: 1.5ms preprocess, 53.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 49 potatos, 40.6ms\n",
      "Speed: 1.5ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 49 potatos, 45.6ms\n",
      "Speed: 1.4ms preprocess, 45.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 46.6ms\n",
      "Speed: 1.6ms preprocess, 46.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 47 potatos, 40.8ms\n",
      "Speed: 1.8ms preprocess, 40.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 44.5ms\n",
      "Speed: 1.7ms preprocess, 44.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 potatos, 45.4ms\n",
      "Speed: 1.6ms preprocess, 45.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 48.2ms\n",
      "Speed: 1.7ms preprocess, 48.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 44.8ms\n",
      "Speed: 1.5ms preprocess, 44.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 45.9ms\n",
      "Speed: 1.6ms preprocess, 45.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 42.9ms\n",
      "Speed: 2.0ms preprocess, 42.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 40 potatos, 46.9ms\n",
      "Speed: 1.5ms preprocess, 46.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 45.9ms\n",
      "Speed: 1.5ms preprocess, 45.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 46.6ms\n",
      "Speed: 1.7ms preprocess, 46.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 44 potatos, 41.0ms\n",
      "Speed: 1.5ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 43 potatos, 45.5ms\n",
      "Speed: 1.6ms preprocess, 45.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 38.5ms\n",
      "Speed: 1.5ms preprocess, 38.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 40 potatos, 46.0ms\n",
      "Speed: 1.4ms preprocess, 46.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 potatos, 43.9ms\n",
      "Speed: 1.4ms preprocess, 43.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 potatos, 43.4ms\n",
      "Speed: 1.5ms preprocess, 43.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 39 potatos, 46.0ms\n",
      "Speed: 1.7ms preprocess, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 potatos, 41.8ms\n",
      "Speed: 1.6ms preprocess, 41.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 potatos, 44.6ms\n",
      "Speed: 1.6ms preprocess, 44.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 potatos, 40.3ms\n",
      "Speed: 1.5ms preprocess, 40.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 40.1ms\n",
      "Speed: 1.6ms preprocess, 40.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 47.3ms\n",
      "Speed: 1.7ms preprocess, 47.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 43.2ms\n",
      "Speed: 1.4ms preprocess, 43.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 potatos, 46.3ms\n",
      "Speed: 1.4ms preprocess, 46.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 44.0ms\n",
      "Speed: 1.6ms preprocess, 44.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 potatos, 48.7ms\n",
      "Speed: 1.8ms preprocess, 48.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 36.8ms\n",
      "Speed: 1.5ms preprocess, 36.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 48.5ms\n",
      "Speed: 1.5ms preprocess, 48.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 49.0ms\n",
      "Speed: 1.6ms preprocess, 49.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 potatos, 46.0ms\n",
      "Speed: 1.5ms preprocess, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 potatos, 42.9ms\n",
      "Speed: 1.6ms preprocess, 42.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 44.2ms\n",
      "Speed: 1.5ms preprocess, 44.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 potatos, 38.5ms\n",
      "Speed: 1.7ms preprocess, 38.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 28 potatos, 74.6ms\n",
      "Speed: 1.4ms preprocess, 74.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 29 potatos, 42.4ms\n",
      "Speed: 1.4ms preprocess, 42.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 29 potatos, 39.5ms\n",
      "Speed: 1.4ms preprocess, 39.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 29 potatos, 48.1ms\n",
      "Speed: 1.5ms preprocess, 48.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 potatos, 46.3ms\n",
      "Speed: 1.8ms preprocess, 46.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 28 potatos, 76.5ms\n",
      "Speed: 1.5ms preprocess, 76.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 potatos, 43.2ms\n",
      "Speed: 1.5ms preprocess, 43.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 potatos, 40.9ms\n",
      "Speed: 1.5ms preprocess, 40.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 potatos, 43.5ms\n",
      "Speed: 1.5ms preprocess, 43.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 potatos, 38.6ms\n",
      "Speed: 1.6ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 potatos, 46.2ms\n",
      "Speed: 1.7ms preprocess, 46.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 potatos, 47.9ms\n",
      "Speed: 1.8ms preprocess, 47.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 potatos, 41.6ms\n",
      "Speed: 1.6ms preprocess, 41.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 potatos, 36.5ms\n",
      "Speed: 1.5ms preprocess, 36.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 potatos, 41.2ms\n",
      "Speed: 1.5ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 potatos, 40.3ms\n",
      "Speed: 1.5ms preprocess, 40.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 potatos, 39.9ms\n",
      "Speed: 1.8ms preprocess, 39.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 potatos, 48.6ms\n",
      "Speed: 1.6ms preprocess, 48.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 potatos, 44.8ms\n",
      "Speed: 1.7ms preprocess, 44.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 potatos, 48.5ms\n",
      "Speed: 1.5ms preprocess, 48.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 potatos, 39.9ms\n",
      "Speed: 1.5ms preprocess, 39.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 potatos, 41.5ms\n",
      "Speed: 1.7ms preprocess, 41.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 potatos, 41.7ms\n",
      "Speed: 1.4ms preprocess, 41.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 potatos, 45.5ms\n",
      "Speed: 1.7ms preprocess, 45.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 potatos, 45.1ms\n",
      "Speed: 1.6ms preprocess, 45.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 potatos, 49.2ms\n",
      "Speed: 1.5ms preprocess, 49.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 potatos, 45.9ms\n",
      "Speed: 1.6ms preprocess, 45.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 potatos, 45.7ms\n",
      "Speed: 1.7ms preprocess, 45.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 potatos, 48.2ms\n",
      "Speed: 1.7ms preprocess, 48.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 potatos, 42.2ms\n",
      "Speed: 1.4ms preprocess, 42.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 potatos, 41.9ms\n",
      "Speed: 1.7ms preprocess, 41.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 potatos, 50.4ms\n",
      "Speed: 1.5ms preprocess, 50.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 potatos, 44.5ms\n",
      "Speed: 1.4ms preprocess, 44.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 potatos, 43.5ms\n",
      "Speed: 1.4ms preprocess, 43.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 potatos, 46.5ms\n",
      "Speed: 1.4ms preprocess, 46.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 potatos, 40.5ms\n",
      "Speed: 1.4ms preprocess, 40.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 potatos, 46.2ms\n",
      "Speed: 1.6ms preprocess, 46.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 potatos, 42.7ms\n",
      "Speed: 1.5ms preprocess, 42.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 potatos, 43.7ms\n",
      "Speed: 1.7ms preprocess, 43.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 potatos, 46.7ms\n",
      "Speed: 1.4ms preprocess, 46.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 potatos, 42.3ms\n",
      "Speed: 1.7ms preprocess, 42.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 potatos, 38.3ms\n",
      "Speed: 1.4ms preprocess, 38.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 potatos, 44.0ms\n",
      "Speed: 1.7ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 potatos, 47.1ms\n",
      "Speed: 1.4ms preprocess, 47.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 potatos, 44.9ms\n",
      "Speed: 1.6ms preprocess, 44.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 potatos, 44.1ms\n",
      "Speed: 1.6ms preprocess, 44.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 potatos, 48.9ms\n",
      "Speed: 1.4ms preprocess, 48.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 potatos, 43.1ms\n",
      "Speed: 1.4ms preprocess, 43.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 potatos, 42.5ms\n",
      "Speed: 1.9ms preprocess, 42.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 potatos, 40.5ms\n",
      "Speed: 1.5ms preprocess, 40.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 potatos, 38.6ms\n",
      "Speed: 1.6ms preprocess, 38.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 potatos, 43.0ms\n",
      "Speed: 1.4ms preprocess, 43.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 potatos, 43.9ms\n",
      "Speed: 1.6ms preprocess, 43.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 potatos, 44.7ms\n",
      "Speed: 1.5ms preprocess, 44.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 potatos, 45.1ms\n",
      "Speed: 1.6ms preprocess, 45.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 potatos, 44.8ms\n",
      "Speed: 1.5ms preprocess, 44.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 potatos, 42.2ms\n",
      "Speed: 1.5ms preprocess, 42.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 potatos, 40.4ms\n",
      "Speed: 1.5ms preprocess, 40.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 potatos, 41.3ms\n",
      "Speed: 1.5ms preprocess, 41.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 potatos, 40.2ms\n",
      "Speed: 1.4ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 potatos, 41.1ms\n",
      "Speed: 1.6ms preprocess, 41.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 potatos, 44.2ms\n",
      "Speed: 1.5ms preprocess, 44.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 potatos, 47.0ms\n",
      "Speed: 1.5ms preprocess, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 41.4ms\n",
      "Speed: 1.7ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 potatos, 40.8ms\n",
      "Speed: 1.7ms preprocess, 40.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 potatos, 43.7ms\n",
      "Speed: 1.6ms preprocess, 43.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 44.7ms\n",
      "Speed: 1.6ms preprocess, 44.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 42.2ms\n",
      "Speed: 1.6ms preprocess, 42.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 potatos, 43.6ms\n",
      "Speed: 1.7ms preprocess, 43.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 potatos, 40.3ms\n",
      "Speed: 1.6ms preprocess, 40.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 potatos, 43.8ms\n",
      "Speed: 1.5ms preprocess, 43.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 potatos, 48.8ms\n",
      "Speed: 1.5ms preprocess, 48.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 43.8ms\n",
      "Speed: 1.5ms preprocess, 43.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 potatos, 66.0ms\n",
      "Speed: 1.8ms preprocess, 66.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 potatos, 57.3ms\n",
      "Speed: 1.6ms preprocess, 57.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 potatos, 87.7ms\n",
      "Speed: 1.7ms preprocess, 87.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 potatos, 42.4ms\n",
      "Speed: 1.5ms preprocess, 42.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 potatos, 42.2ms\n",
      "Speed: 1.6ms preprocess, 42.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 50.0ms\n",
      "Speed: 1.6ms preprocess, 50.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 42.3ms\n",
      "Speed: 1.5ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 49.7ms\n",
      "Speed: 1.6ms preprocess, 49.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 potatos, 44.8ms\n",
      "Speed: 1.6ms preprocess, 44.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 potatos, 42.9ms\n",
      "Speed: 1.5ms preprocess, 42.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 potatos, 43.4ms\n",
      "Speed: 1.7ms preprocess, 43.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 40.2ms\n",
      "Speed: 1.6ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 46.2ms\n",
      "Speed: 1.5ms preprocess, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 46.2ms\n",
      "Speed: 1.8ms preprocess, 46.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 42.9ms\n",
      "Speed: 1.5ms preprocess, 42.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 42.1ms\n",
      "Speed: 1.5ms preprocess, 42.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 potatos, 49.3ms\n",
      "Speed: 1.8ms preprocess, 49.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 potatos, 43.1ms\n",
      "Speed: 1.6ms preprocess, 43.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 44.4ms\n",
      "Speed: 1.7ms preprocess, 44.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 potatos, 43.1ms\n",
      "Speed: 1.7ms preprocess, 43.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 50.2ms\n",
      "Speed: 1.6ms preprocess, 50.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 42.2ms\n",
      "Speed: 1.5ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 47.9ms\n",
      "Speed: 1.6ms preprocess, 47.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 potatos, 43.1ms\n",
      "Speed: 1.7ms preprocess, 43.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 44.1ms\n",
      "Speed: 1.8ms preprocess, 44.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 potatos, 47.9ms\n",
      "Speed: 1.6ms preprocess, 47.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 potatos, 44.6ms\n",
      "Speed: 1.4ms preprocess, 44.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 potatos, 43.7ms\n",
      "Speed: 1.7ms preprocess, 43.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 potatos, 46.7ms\n",
      "Speed: 1.5ms preprocess, 46.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 potatos, 45.9ms\n",
      "Speed: 1.4ms preprocess, 45.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 potatos, 44.4ms\n",
      "Speed: 1.5ms preprocess, 44.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 potatos, 40.8ms\n",
      "Speed: 1.6ms preprocess, 40.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 potatos, 42.2ms\n",
      "Speed: 1.5ms preprocess, 42.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 potatos, 42.6ms\n",
      "Speed: 1.5ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 potatos, 43.1ms\n",
      "Speed: 1.5ms preprocess, 43.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 potatos, 47.6ms\n",
      "Speed: 1.5ms preprocess, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 potatos, 42.1ms\n",
      "Speed: 1.8ms preprocess, 42.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 potatos, 41.4ms\n",
      "Speed: 1.4ms preprocess, 41.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 potatos, 41.1ms\n",
      "Speed: 1.4ms preprocess, 41.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 potatos, 41.7ms\n",
      "Speed: 1.7ms preprocess, 41.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 potatos, 42.8ms\n",
      "Speed: 1.4ms preprocess, 42.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 potatos, 39.9ms\n",
      "Speed: 1.6ms preprocess, 39.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 potatos, 49.9ms\n",
      "Speed: 1.7ms preprocess, 49.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 potatos, 44.0ms\n",
      "Speed: 1.7ms preprocess, 44.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 potatos, 45.9ms\n",
      "Speed: 1.4ms preprocess, 45.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 potatos, 44.8ms\n",
      "Speed: 1.5ms preprocess, 44.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 potatos, 47.5ms\n",
      "Speed: 1.5ms preprocess, 47.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 potatos, 41.9ms\n",
      "Speed: 1.5ms preprocess, 41.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 potatos, 45.5ms\n",
      "Speed: 1.7ms preprocess, 45.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 potatos, 44.6ms\n",
      "Speed: 1.6ms preprocess, 44.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 potatos, 46.7ms\n",
      "Speed: 1.6ms preprocess, 46.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 potatos, 50.6ms\n",
      "Speed: 1.4ms preprocess, 50.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 potatos, 39.8ms\n",
      "Speed: 1.7ms preprocess, 39.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 potatos, 46.6ms\n",
      "Speed: 1.5ms preprocess, 46.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 potatos, 43.3ms\n",
      "Speed: 1.7ms preprocess, 43.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 potatos, 40.4ms\n",
      "Speed: 1.9ms preprocess, 40.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 potatos, 42.8ms\n",
      "Speed: 1.5ms preprocess, 42.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 potatos, 45.0ms\n",
      "Speed: 1.6ms preprocess, 45.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 potatos, 47.3ms\n",
      "Speed: 1.4ms preprocess, 47.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 potatos, 45.4ms\n",
      "Speed: 1.4ms preprocess, 45.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 potatos, 42.1ms\n",
      "Speed: 1.7ms preprocess, 42.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 potatos, 41.7ms\n",
      "Speed: 1.7ms preprocess, 41.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 potatos, 40.2ms\n",
      "Speed: 1.4ms preprocess, 40.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 potatos, 43.2ms\n",
      "Speed: 1.5ms preprocess, 43.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 potatos, 42.3ms\n",
      "Speed: 1.7ms preprocess, 42.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 potatos, 49.3ms\n",
      "Speed: 1.5ms preprocess, 49.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 potatos, 41.2ms\n",
      "Speed: 1.6ms preprocess, 41.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 potatos, 56.4ms\n",
      "Speed: 15.7ms preprocess, 56.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 potatos, 43.5ms\n",
      "Speed: 1.6ms preprocess, 43.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 potatos, 42.4ms\n",
      "Speed: 1.9ms preprocess, 42.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 potatos, 43.8ms\n",
      "Speed: 1.7ms preprocess, 43.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 potatos, 44.3ms\n",
      "Speed: 1.5ms preprocess, 44.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 potatos, 46.1ms\n",
      "Speed: 1.4ms preprocess, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 potatos, 41.2ms\n",
      "Speed: 1.5ms preprocess, 41.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 potatos, 42.0ms\n",
      "Speed: 1.7ms preprocess, 42.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 potatos, 44.1ms\n",
      "Speed: 1.6ms preprocess, 44.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 potato, 39.4ms\n",
      "Speed: 1.5ms preprocess, 39.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 potato, 43.7ms\n",
      "Speed: 1.7ms preprocess, 43.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 potatos, 46.8ms\n",
      "Speed: 1.5ms preprocess, 46.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 potatos, 43.1ms\n",
      "Speed: 1.4ms preprocess, 43.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 potatos, 39.4ms\n",
      "Speed: 1.7ms preprocess, 39.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 potatos, 38.6ms\n",
      "Speed: 1.5ms preprocess, 38.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 potato, 38.8ms\n",
      "Speed: 1.6ms preprocess, 38.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 potatos, 40.4ms\n",
      "Speed: 1.8ms preprocess, 40.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 potatos, 42.5ms\n",
      "Speed: 1.4ms preprocess, 42.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 potatos, 43.9ms\n",
      "Speed: 1.5ms preprocess, 43.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 potatos, 43.5ms\n",
      "Speed: 1.6ms preprocess, 43.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 potatos, 41.5ms\n",
      "Speed: 1.7ms preprocess, 41.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 potatos, 47.3ms\n",
      "Speed: 1.7ms preprocess, 47.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 potatos, 44.2ms\n",
      "Speed: 1.5ms preprocess, 44.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 potatos, 42.0ms\n",
      "Speed: 1.8ms preprocess, 42.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 potatos, 45.4ms\n",
      "Speed: 1.5ms preprocess, 45.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 potatos, 41.7ms\n",
      "Speed: 1.7ms preprocess, 41.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 potatos, 43.4ms\n",
      "Speed: 1.5ms preprocess, 43.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 potato, 40.5ms\n",
      "Speed: 1.5ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 potato, 44.0ms\n",
      "Speed: 1.4ms preprocess, 44.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 potato, 41.1ms\n",
      "Speed: 1.7ms preprocess, 41.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Open the video file\n",
    "video_path = videos[0]\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Store the track history\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLO11 tracking on the frame, persisting tracks between frames\n",
    "        results = model.track(frame, conf=0.45, persist=True, tracker=\"bytetrack_custom.yaml\")\n",
    "\n",
    "        # Get the boxes and track IDs\n",
    "        boxes = results[0].boxes.xywh.cpu()\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Plot the tracks\n",
    "        for box, track_id in zip(boxes, track_ids):\n",
    "            x, y, w, h = box\n",
    "            track = track_history[track_id]\n",
    "            track.append((float(x), float(y)))  # x, y center point\n",
    "            if len(track) > 30:  # retain 30 tracks for 30 frames\n",
    "                track.pop(0)\n",
    "\n",
    "            # Draw the tracking lines\n",
    "            points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "            cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLO11 Tracking\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-27:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-28:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-25:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-29:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-33:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-31:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-32:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-34:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-35:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-36:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-37:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_video' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-74:\n",
      "Process SpawnPoolWorker-73:\n",
      "Process SpawnPoolWorker-70:\n",
      "Process SpawnPoolWorker-72:\n",
      "Process SpawnPoolWorker-67:\n",
      "Process SpawnPoolWorker-69:\n",
      "Process SpawnPoolWorker-71:\n",
      "Process SpawnPoolWorker-66:\n",
      "Process SpawnPoolWorker-65:\n",
      "Process SpawnPoolWorker-64:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-63:\n",
      "Process SpawnPoolWorker-61:\n",
      "Process SpawnPoolWorker-68:\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-38:\n",
      "Process SpawnPoolWorker-62:\n",
      "Process SpawnPoolWorker-56:\n",
      "Process SpawnPoolWorker-58:\n",
      "Process SpawnPoolWorker-40:\n",
      "Process SpawnPoolWorker-43:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-52:\n",
      "Process SpawnPoolWorker-46:\n",
      "Process SpawnPoolWorker-51:\n",
      "Process SpawnPoolWorker-54:\n",
      "Process SpawnPoolWorker-60:\n",
      "Process SpawnPoolWorker-47:\n",
      "Process SpawnPoolWorker-55:\n",
      "Process SpawnPoolWorker-59:\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-50:\n",
      "Process SpawnPoolWorker-49:\n",
      "Process SpawnPoolWorker-57:\n",
      "Process SpawnPoolWorker-39:\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-41:\n",
      "Process SpawnPoolWorker-44:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-42:\n",
      "Process SpawnPoolWorker-45:\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-48:\n",
      "Process SpawnPoolWorker-53:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 365, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 89\u001b[39m\n\u001b[32m     85\u001b[39m video_paths = videos\n\u001b[32m     87\u001b[39m output_video_paths = [\u001b[33m'\u001b[39m\u001b[33mYolov_model1_output/\u001b[39m\u001b[33m'\u001b[39m+i.split(\u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m)[-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m videos]\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[43mprocess_multiple_videos_in_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_paths\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mprocess_multiple_videos_in_parallel\u001b[39m\u001b[34m(model, video_paths, output_video_paths)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Create a pool of processes for parallel video processing\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes=\u001b[38;5;28mlen\u001b[39m(video_paths)) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# Map the function to the video paths and output paths\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_video\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvideo_paths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_paths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:375\u001b[39m, in \u001b[36mPool.starmap\u001b[39m\u001b[34m(self, func, iterable, chunksize)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    370\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[33;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[33;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[33;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:768\u001b[39m, in \u001b[36mApplyResult.get\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    769\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ready():\n\u001b[32m    770\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:765\u001b[39m, in \u001b[36mApplyResult.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:629\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    627\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def process_video(model, video_path, output_video_path):\n",
    "    \"\"\"\n",
    "    Process a single video and save the output with predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Trained model for prediction.\n",
    "    - video_path: Path to the input video.\n",
    "    - output_video_path: Path to save the output video.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Create VideoWriter to save output video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Preprocess the frame for the model\n",
    "        #processed_frame = preprocess_frame(frame)\n",
    "\n",
    "        # Predict using the model\n",
    "        results = model.predict(frame)\n",
    "\n",
    "        # Draw the prediction on the frame\n",
    "        frame_with_prediction = draw_prediction_on_frame(frame, results)\n",
    "\n",
    "        # Write the processed frame to the output video\n",
    "        out.write(frame_with_prediction)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Processed video saved to {output_video_path}\")\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    \"\"\"\n",
    "    Preprocess the frame for model prediction.\n",
    "    \"\"\"\n",
    "    frame_resized = cv2.resize(frame, (224, 224))\n",
    "    frame_normalized = frame_resized / 255.0  # Normalize to [0, 1]\n",
    "    return np.expand_dims(frame_normalized, axis=0)\n",
    "\n",
    "def draw_prediction_on_frame(frame, results):\n",
    "    \"\"\"\n",
    "    Draw the prediction result on the frame.\n",
    "    \"\"\"\n",
    "    for box in results[0].boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0]  # Get box coordinates\n",
    "        label = box.cls[0]  # Get class label (if available)\n",
    "        conf = box.conf[0]  # Confidence score\n",
    "\n",
    "        # Draw the bounding box on the image\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "    return frame\n",
    "\n",
    "def process_multiple_videos_in_parallel(model, video_paths, output_video_paths):\n",
    "    \"\"\"\n",
    "    Process multiple videos simultaneously using multiprocessing.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Trained model for prediction.\n",
    "    - video_paths: List of paths to the input videos.\n",
    "    - output_video_paths: List of paths to save the output videos.\n",
    "    \"\"\"\n",
    "    # Create a pool of processes for parallel video processing\n",
    "    with Pool(processes=len(video_paths)) as pool:\n",
    "        # Map the function to the video paths and output paths\n",
    "        pool.starmap(process_video, zip([model] * len(video_paths), video_paths, output_video_paths))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    video_paths = videos\n",
    "\n",
    "    output_video_paths = ['Yolov_model1_output/'+i.split('/')[-1] for i in videos]\n",
    "    process_multiple_videos_in_parallel(model, video_paths, output_video_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from IPython.display import display, Image\n",
    "# Assuming you have a pre-trained model and processor\n",
    "# model = ...\n",
    "# processor = ...\n",
    "\n",
    "confs = 0.0001\n",
    "ind = 37\n",
    "video_capture = cv2.VideoCapture(videos[ind])\n",
    "\n",
    "fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  \n",
    "output_video = cv2.VideoWriter(f\"output_1_{confs}.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "counter = 0\n",
    "\n",
    "text_labels = [[\"a potato\",]]\n",
    "while True:\n",
    "  \n",
    "  ret, frame = video_capture.read()\n",
    "  counter += 1\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "\n",
    "    \n",
    "  if counter % 25==0:\n",
    "      # Execute prediction for specified categories on an image\n",
    "      results = model.predict(frame, conf=confs)\n",
    "\n",
    "      \n",
    "        # Draw the boxes on the image\n",
    "      for box in results[0].boxes:\n",
    "          x1, y1, x2, y2 = box.xyxy[0]  # Get box coordinates\n",
    "          label = box.cls[0]  # Get class label (if available)\n",
    "          conf = box.conf[0]  # Confidence score\n",
    "\n",
    "          # Draw the bounding box on the image\n",
    "          cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "      # Save frame to \n",
    "      frame_filename = f'Dataset_30/images/{ind}_frame_{counter}.jpg'\n",
    "      cv2.imwrite(frame_filename, frame)\n",
    "\n",
    "      # Save annotations to annotations folder\n",
    "      annot_filename = f'Dataset_30/labels/{ind}_frame_{counter}.txt'\n",
    "      save(results, annot_filename)\n",
    "\n",
    "      frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  \n",
    "      plt.imshow(frame)\n",
    "      plt.axis(\"off\")\n",
    "      plt.show()\n",
    "\n",
    "# Release the video capture and writer objects\n",
    "video_capture.release()\n",
    "#output_video.release()\n",
    "\n",
    "print(\"Video processing completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
