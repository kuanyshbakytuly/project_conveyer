
yolo export model=Models/model_det_test/best.pt format=onnx opset=19 dynamic=True 


yolo val task=detect model=Models/best.onnx imgsz=640 data=/home/paperspace/datasets/Dataset/data.yaml  

yolo val task=detect model=Models/model_det_test/best.onnx imgsz=640 data=/Dataset/data.yaml

cp -r /home/paperspace/datasets/Dataset /path/to/destination/
docker run -it --gpus all \
  -v /home/paperspace/project_conveyer:/trt \
  nvcr.io/nvidia/tensorrt:25.03-py3

/usr/src/tensorrt/bin/trtexec --onnx=/models/model_det/1/model.onnx \
        --saveEngine=/models/model_det/1/model.plan \
        --minShapes=images:1x3x640x640 \
        --optShapes=images:16x3x640x640 \
        --maxShapes=images:32x3x640x640 \

trtexec \
    --onnx=Models/best_yoloseg.onnx \
    --minShapes=images:1x3x640x640 \
    --optShapes=images:10x3x640x640 \
    --maxShapes=images:20x3x640x640 \
    --saveEngine=Models/best_yoloseg.plan

polygraphy convert Models/model_det_fp32/best.onnx -o Models/model_det_fp32/model.plan \
  --trt-min-shapes images:[1,3,640,640] \
  --trt-opt-shapes images:[10,3,640,640] \
  --trt-max-shapes images:[20,3,640,640] \
  --fp16

polygraphy convert Models/model_det_test/best.onnx -o Models/model_det/1/model.plan \
  --trt-min-shapes images:[1,3,640,640] \
  --trt-opt-shapes images:[16,3,640,640] \
  --trt-max-shapes images:[32,3,640,640] \
  --fp16

polygraphy template trt-network model_trt/model_det/1/model.onnx \
    --trt-outputs mark all \
    --output config.pbtxt

polygraphy inspect model Models/model_det_test/best.engine --model-type engine

polygraphy inspect model Models/model_det_test/best.onnx --model-type onnx

sudo docker run --gpus=all -it -p8000:8000 -p8001:8001 -p8002:8002 -v $(pwd)/model_trt:/models nvcr.io/nvidia/tritonserver:25.03-py3

sudo docker run --gpus=all -it -v $(pwd)/model_trt:/models -p 8000:8000 nvcr.io/nvidia/tritonserver:25.03-py3 tritonserver --model-repository=/models

sudo docker run --gpus=all -it -v $(pwd)/tmp1/triton_repo:/models -p 8000:8000 nvcr.io/nvidia/tritonserver:24.09-py3

sudo docker run --gpus=all -it --rm -p8000:8000 -p8001:8001 -p8002:8002 -v $(pwd)/triton_repo:/models nvcr.io/nvidia/tritonserver:25.03-py3

pip install opencv-python
apt-get update
apt-get install -y libgl1
apt-get install -y libglvnd-dev
ldconfig -p | grep libGL

tritonserver --model-repository=/models
